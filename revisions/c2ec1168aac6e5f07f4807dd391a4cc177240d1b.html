
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
		<meta http-equiv="Pragma" content="no-cache" />
		<meta http-equiv="Expires" content="0" />
		<title>v1: Go Coverage Report</title>
		<script src="../index.js?ad79d67a7b27030a910cdcdaaaf1e441"></script>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">github.com/intel/kubernetes-power-manager/api/v1/cpuscalingconfiguration_types.go (100.0%)</option>
				
				<option value="file1">github.com/intel/kubernetes-power-manager/api/v1/cpuscalingprofile_types.go (33.3%)</option>
				
				<option value="file2">github.com/intel/kubernetes-power-manager/api/v1/cstates_types.go (33.3%)</option>
				
				<option value="file3">github.com/intel/kubernetes-power-manager/api/v1/powerconfig_types.go (100.0%)</option>
				
				<option value="file4">github.com/intel/kubernetes-power-manager/api/v1/powernode_types.go (100.0%)</option>
				
				<option value="file5">github.com/intel/kubernetes-power-manager/api/v1/powerpod_types.go (100.0%)</option>
				
				<option value="file6">github.com/intel/kubernetes-power-manager/api/v1/powerprofile_types.go (66.7%)</option>
				
				<option value="file7">github.com/intel/kubernetes-power-manager/api/v1/powerworkload_types.go (100.0%)</option>
				
				<option value="file8">github.com/intel/kubernetes-power-manager/api/v1/timeofday_types.go (100.0%)</option>
				
				<option value="file9">github.com/intel/kubernetes-power-manager/api/v1/timeofdaycronjob_types.go (33.3%)</option>
				
				<option value="file10">github.com/intel/kubernetes-power-manager/api/v1/uncore_types.go (33.3%)</option>
				
				<option value="file11">github.com/intel/kubernetes-power-manager/api/v1/zz_generated.deepcopy.go (49.3%)</option>
				
				<option value="file12">github.com/intel/kubernetes-power-manager/build/manager/main.go (0.0%)</option>
				
				<option value="file13">github.com/intel/kubernetes-power-manager/build/nodeagent/main.go (0.0%)</option>
				
				<option value="file14">github.com/intel/kubernetes-power-manager/cmd/main.go (0.0%)</option>
				
				<option value="file15">github.com/intel/kubernetes-power-manager/internal/controller/common.go (100.0%)</option>
				
				<option value="file16">github.com/intel/kubernetes-power-manager/internal/controller/cpuscalingconfiguration_controller.go (92.7%)</option>
				
				<option value="file17">github.com/intel/kubernetes-power-manager/internal/controller/cpuscalingprofile_controller.go (66.7%)</option>
				
				<option value="file18">github.com/intel/kubernetes-power-manager/internal/controller/cstates_controller.go (92.2%)</option>
				
				<option value="file19">github.com/intel/kubernetes-power-manager/internal/controller/powerconfig_controller.go (70.2%)</option>
				
				<option value="file20">github.com/intel/kubernetes-power-manager/internal/controller/powernode_controller.go (89.9%)</option>
				
				<option value="file21">github.com/intel/kubernetes-power-manager/internal/controller/powerpod_controller.go (90.5%)</option>
				
				<option value="file22">github.com/intel/kubernetes-power-manager/internal/controller/powerprofile_controller.go (85.6%)</option>
				
				<option value="file23">github.com/intel/kubernetes-power-manager/internal/controller/powerworkload_controller.go (84.2%)</option>
				
				<option value="file24">github.com/intel/kubernetes-power-manager/internal/controller/timeofday_controller.go (89.1%)</option>
				
				<option value="file25">github.com/intel/kubernetes-power-manager/internal/controller/timeofdaycronjob_controller.go (83.1%)</option>
				
				<option value="file26">github.com/intel/kubernetes-power-manager/internal/controller/uncore_controller.go (0.0%)</option>
				
				<option value="file27">github.com/intel/kubernetes-power-manager/internal/metrics/esmi_client.go (0.0%)</option>
				
				<option value="file28">github.com/intel/kubernetes-power-manager/internal/metrics/msr_client.go (64.7%)</option>
				
				<option value="file29">github.com/intel/kubernetes-power-manager/internal/metrics/msr_reader.go (0.0%)</option>
				
				<option value="file30">github.com/intel/kubernetes-power-manager/internal/metrics/perf_event_client.go (63.8%)</option>
				
				<option value="file31">github.com/intel/kubernetes-power-manager/internal/metrics/perf_event_reader.go (65.6%)</option>
				
				<option value="file32">github.com/intel/kubernetes-power-manager/internal/monitoring/collectors.go (75.0%)</option>
				
				<option value="file33">github.com/intel/kubernetes-power-manager/internal/monitoring/esmi_collectors.go (90.9%)</option>
				
				<option value="file34">github.com/intel/kubernetes-power-manager/internal/monitoring/msr_collectors.go (0.0%)</option>
				
				<option value="file35">github.com/intel/kubernetes-power-manager/internal/monitoring/perf_event_collectors.go (0.0%)</option>
				
				<option value="file36">github.com/intel/kubernetes-power-manager/internal/scaling/cpu_freq.go (70.0%)</option>
				
				<option value="file37">github.com/intel/kubernetes-power-manager/internal/scaling/manager.go (90.2%)</option>
				
				<option value="file38">github.com/intel/kubernetes-power-manager/internal/scaling/updater.go (0.0%)</option>
				
				<option value="file39">github.com/intel/kubernetes-power-manager/internal/scaling/worker.go (56.2%)</option>
				
				<option value="file40">github.com/intel/kubernetes-power-manager/pkg/cpuset/cpuset.go (95.7%)</option>
				
				<option value="file41">github.com/intel/kubernetes-power-manager/pkg/podresourcesclient/podresourcesclient.go (46.7%)</option>
				
				<option value="file42">github.com/intel/kubernetes-power-manager/pkg/podstate/podstate.go (100.0%)</option>
				
				<option value="file43">github.com/intel/kubernetes-power-manager/pkg/state/state.go (100.0%)</option>
				
				<option value="file44">github.com/intel/kubernetes-power-manager/pkg/testutils/utils.go (62.6%)</option>
				
				<option value="file45">github.com/intel/kubernetes-power-manager/pkg/util/util.go (67.8%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/types"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

type ConfigItem struct {
        // PowerProfile is the CPUScalingProfile that this CPUScalingConfiguration is based on
        PowerProfile string `json:"powerProfile"`

        // List of CPU IDs which should adhere to the configuration in this item
        //+kubebuilder:validation:MinItems=1
        CpuIDs []uint `json:"cpuIDs"`

        // Minimum time to elapse between two CPU sample periods
        //+kubebuilder:validation:Format=duration
        SamplePeriod metav1.Duration `json:"samplePeriod"`

        // UID of the Pod that this ConfigItem is associated with
        PodUID types.UID `json:"podUID"`
}

// CPUScalingConfigurationSpec defines the desired state of CPUScalingConfiguration
type CPUScalingConfigurationSpec struct {
        // List of configurations that should be applied on a node.
        Items []ConfigItem `json:"items,omitempty"`
}

// CPUScalingConfigurationStatus defines the observed state of CPUScalingConfiguration
type CPUScalingConfigurationStatus struct {
        StatusErrors `json:",inline,omitempty"`
}

//+kubebuilder:object:root=true
//+kubebuilder:subresource:status

// CPUScalingConfiguration is the Schema for the cpuscalingconfiguration API
type CPUScalingConfiguration struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   CPUScalingConfigurationSpec   `json:"spec,omitempty"`
        Status CPUScalingConfigurationStatus `json:"status,omitempty"`
}

//+kubebuilder:object:root=true

// CPUScalingConfigurationList contains a list of CPUScalingConfiguration
type CPUScalingConfigurationList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []CPUScalingConfiguration `json:"items"`
}

func (config *CPUScalingConfiguration) SetStatusErrors(errs *[]string) <span class="cov8" title="1">{
        config.Status.Errors = *errs
}</span>

func (config *CPUScalingConfiguration) GetStatusErrors() *[]string <span class="cov8" title="1">{
        return &amp;config.Status.Errors
}</span>

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;CPUScalingConfiguration{}, &amp;CPUScalingConfigurationList{})
}</span>
</pre>
		
		<pre class="file" id="file1" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

// CPUScalingProfileSpec defines the desired state of CPUScalingProfile
type CPUScalingProfileSpec struct {
        // Name of the CPUScalingProfile
        Name string `json:"name"`

        // Minimum time to elapse between two CPU sample periods
        //+kubebuilder:validation:Format=duration
        //+kubebuilder:default="10ms"
        SamplePeriod metav1.Duration `json:"samplePeriod,omitempty"`

        // Minimum frequency cores can run at
        Min int `json:"min,omitempty"`

        // Maximum frequency cores can run at
        Max int `json:"max,omitempty"`

        // The priority value associated with this CPUScalingProfile
        Epp string `json:"epp,omitempty"`
}

// CPUScalingProfileStatus defines the observed state of CPUScalingProfile
type CPUScalingProfileStatus struct {
        // The ID given to the CPUScalingProfile
        ID           int `json:"id,omitempty"`
        StatusErrors `json:",inline,omitempty"`
}

//+kubebuilder:object:root=true
//+kubebuilder:subresource:status

// CPUScalingProfile is the Schema for the cpuscalingprofiles API
type CPUScalingProfile struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   CPUScalingProfileSpec   `json:"spec,omitempty"`
        Status CPUScalingProfileStatus `json:"status,omitempty"`
}

//+kubebuilder:object:root=true

// CPUScalingProfileList contains a list of CPUScalingProfile
type CPUScalingProfileList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []CPUScalingProfile `json:"items"`
}

func (prfl *CPUScalingProfile) SetStatusErrors(errs *[]string) <span class="cov0" title="0">{
        prfl.Status.Errors = *errs
}</span>
func (prfl *CPUScalingProfile) GetStatusErrors() *[]string <span class="cov0" title="0">{
        return &amp;prfl.Status.Errors
}</span>

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;CPUScalingProfile{}, &amp;CPUScalingProfileList{})
}</span>
</pre>
		
		<pre class="file" id="file2" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

// CStatesSpec defines the desired state of CStates
type CStatesSpec struct {
        // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
        // Important: Run "make" to regenerate code after modifying this file

        SharedPoolCStates     map[string]bool            `json:"sharedPoolCStates,omitempty"`
        ExclusivePoolCStates  map[string]map[string]bool `json:"exclusivePoolCStates,omitempty"`
        IndividualCoreCStates map[string]map[string]bool `json:"individualCoreCStates,omitempty"`
}

// CStatesStatus defines the observed state of CStates
type CStatesStatus struct {
        StatusErrors `json:",inline,omitempty"`
}

//+kubebuilder:object:root=true
//+kubebuilder:subresource:status

// CStates is the Schema for the cstates API
type CStates struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   CStatesSpec   `json:"spec,omitempty"`
        Status CStatesStatus `json:"status,omitempty"`
}

//+kubebuilder:object:root=true

// CStatesList contains a list of CStates
type CStatesList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []CStates `json:"items"`
}

func (csts *CStates) SetStatusErrors(errs *[]string) <span class="cov0" title="0">{
        csts.Status.Errors = *errs
}</span>

func (csts *CStates) GetStatusErrors() *[]string <span class="cov0" title="0">{
        return &amp;csts.Status.Errors
}</span>

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;CStates{}, &amp;CStatesList{})
}</span>
</pre>
		
		<pre class="file" id="file3" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

// PowerConfigSpec defines the desired state of PowerConfig
type PowerConfigSpec struct {
        // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
        // Important: Run "make" to regenerate code after modifying this file

        // The label on the Nodes you the Operator will look for to deploy the Node Agent
        PowerNodeSelector map[string]string `json:"powerNodeSelector,omitempty"`

        // The PowerProfiles that will be created by the Operator
        PowerProfiles []string `json:"powerProfiles,omitempty"`

        // The CustomDevices include alternative devices that represent other resources
        CustomDevices []string `json:"customDevices,omitempty"`
}

// PowerConfigStatus defines the observed state of PowerConfig
type PowerConfigStatus struct {
        // The Nodes that the Node Agent has been deployed to
        Nodes        []string `json:"nodes,omitempty"`
        StatusErrors `json:",inline,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status

// PowerConfig is the Schema for the powerconfigs API
type PowerConfig struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   PowerConfigSpec   `json:"spec,omitempty"`
        Status PowerConfigStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// PowerConfigList contains a list of PowerConfig
type PowerConfigList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []PowerConfig `json:"items"`
}

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;PowerConfig{}, &amp;PowerConfigList{})
}</span>
</pre>
		
		<pre class="file" id="file4" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/types"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

// PowerNodeSpec defines the desired state of PowerNode
type PowerNodeSpec struct {
        // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
        // Important: Run "make" to regenerate code after modifying this file

        // The name of the node
        NodeName string `json:"nodeName,omitempty"`

        PowerProfiles []string `json:"powerProfiles,omitempty"`

        PowerWorkloads []string `json:"powerWorkloads,omitempty"`

        SharedPool string `json:"sharedPool,omitempty"`

        UnaffectedCores string `json:"unaffectedCores,omitempty"`

        ReservedPools []string `json:"reservedPools,omitempty"`

        // Information about the containers in the cluster utilizing some PowerWorkload
        PowerContainers []Container `json:"powerContainers,omitempty"`

        // The CustomDevices include alternative devices that represent other resources
        CustomDevices []string `json:"customDevices,omitempty"`

        // The PowerProfiles in the cluster that are currently being used by Pods
        //ActiveProfiles map[string]bool `json:"activeProfiles,omitempty"`

        // Information about the active PowerWorkloads in the cluster
        //ActiveWorkloads []WorkloadInfo `json:"activeWorkloads,omitempty"`

        // Shows what cores are in the Default and Shared Pools
        //SharedPool SharedPoolInfo `json:"sharedPools,omitempty"`

        // The CPUs that are not effected by any Power Profiles
        //UneffectedCpus []int `json:"uneffectedCpus,omitempty"`
}

// PowerNodeStatus defines the observed state of PowerNode
type PowerNodeStatus struct {
        // INSERT ADDITIONAL STATUS FIELD - define observed state of cluster
        // Important: Run "make" to regenerate code after modifying this file

        // The state of the Guaranteed Pods and Shared Pool in a cluster
        PowerNodeCPUState `json:"powerNodeCPUState,omitempty"`
}

type PowerNodeCPUState struct {
        // The CPUs that are currently part of the Shared pool on a Node
        SharedPool []uint `json:"sharedPool,omitempty"`

        // Pods that are requesting CPUs in the Guaranteed QoS class
        GuaranteedPods []GuaranteedPod `json:"guaranteedPods,omitempty"`
}

type GuaranteedPod struct {
        // The name of the Node the Pod is running on
        Node string `json:"node,omitempty"`

        // The name of the Pod
        Name string `json:"name,omitempty"`

        Namespace string `json:"namespace,omitempty"`

        // The UID of the Pod
        UID string `json:"uid,omitempty"`

        // The Containers that are running in the Pod
        Containers []Container `json:"containers,omitempty"`
}

type Container struct {
        // The name of the Container
        Name string `json:"name,omitempty"`

        // The ID of the Container
        Id string `json:"id,omitempty"`

        // The name of the Pod the Container is running in
        Pod string `json:"pod,omitempty"`

        // The ID of the Pod the Container is running in
        PodUID types.UID `json:"podUID,omitempty"`

        // The namespace of the Pod the Container is running in
        Namespace string `json:"namespace,omitempty"`

        // The exclusive CPUs given to this Container
        ExclusiveCPUs []uint `json:"exclusiveCpus,omitempty"`

        // The PowerProfile that the Container is utilizing
        PowerProfile string `json:"powerProfile,omitempty"`

        // The PowerWorkload that the Container is utilizing
        Workload string `json:"workload,omitempty"`
}

type WorkloadInfo struct {
        // The name of the PowerWorkload
        Name string `json:"name,omitempty"`

        // The CPUs that are utilizing the PowerWorkload
        CpuIds []uint `json:"cores,omitempty"`
}

type SharedPoolInfo struct {
        // The name or either Default or Shared pool
        Profile string `json:"name,omitempty"`

        // The cores that are a part of this Shared Pool
        CpuIds []uint `json:"sharedPoolCpuIds,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status

// PowerNode is the Schema for the powernodes API
type PowerNode struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   PowerNodeSpec   `json:"spec,omitempty"`
        Status PowerNodeStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// PowerNodeList contains a list of PowerNode
type PowerNodeList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []PowerNode `json:"items"`
}

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;PowerNode{}, &amp;PowerNodeList{})
}</span>
</pre>
		
		<pre class="file" id="file5" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

// PowerPodSpec defines the desired state of PowerPod
type PowerPodSpec struct {
        // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
        // Important: Run "make" to regenerate code after modifying this file
}

// PowerPodStatus defines the observed state of PowerPod
type PowerPodStatus struct {
        // INSERT ADDITIONAL STATUS FIELD - define observed state of cluster
        // Important: Run "make" to regenerate code after modifying this file
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status

// PowerPod is the Schema for the powerpods API
type PowerPod struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   PowerPodSpec   `json:"spec,omitempty"`
        Status PowerPodStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// PowerPodList contains a list of PowerPod
type PowerPodList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []PowerPod `json:"items"`
}

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;PowerPod{}, &amp;PowerPodList{})
}</span>
</pre>
		
		<pre class="file" id="file6" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// PowerProfileSpec defines the desired state of PowerProfile
type PowerProfileSpec struct {
        // Important: Run "make" to regenerate code after modifying this file

        // The name of the PowerProfile
        Name string `json:"name"`

        Shared bool `json:"shared,omitempty"`
        // Max frequency cores can run at
        Max int `json:"max,omitempty"`

        // Min frequency cores can run at
        Min int `json:"min,omitempty"`

        // The priority value associated with this Power Profile
        Epp string `json:"epp,omitempty"`

        // Governor to be used
        //+kubebuilder:default=powersave
        Governor string `json:"governor,omitempty"`
}

// PowerProfileStatus defines the observed state of PowerProfile
type PowerProfileStatus struct {
        // The ID given to the power profile
        ID           int `json:"id,omitempty"`
        StatusErrors `json:",inline,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status

// PowerProfile is the Schema for the powerprofiles API
type PowerProfile struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   PowerProfileSpec   `json:"spec,omitempty"`
        Status PowerProfileStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// PowerProfileList contains a list of PowerProfile
type PowerProfileList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []PowerProfile `json:"items"`
}

func (prfl *PowerProfile) SetStatusErrors(errs *[]string) <span class="cov0" title="0">{
        prfl.Status.Errors = *errs
}</span>
func (prfl *PowerProfile) GetStatusErrors() *[]string <span class="cov8" title="1">{
        return &amp;prfl.Status.Errors
}</span>

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;PowerProfile{}, &amp;PowerProfileList{})
}</span>
</pre>
		
		<pre class="file" id="file7" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

type WorkloadNode struct {
        Name string `json:"name,omitempty"`

        Containers []Container `json:"containers,omitempty"`

        CpuIds []uint `json:"cpuIds,omitempty"`
}

// PowerWorkloadSpec defines the desired state of PowerWorkload
type PowerWorkloadSpec struct {
        // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
        // Important: Run "make" to regenerate code after modifying this file

        // The name of the workload
        Name string `json:"name"`

        // AllCores determines if the Workload is to be applied to all cores (i.e. use the Default Workload)
        AllCores bool `json:"allCores,omitempty"`

        // Reserved CPUs are the CPUs that have been reserved by Kubelet for use by the Kubernetes admin process
        // This list must match the list in the user's Kubelet configuration
        ReservedCPUs []ReservedSpec `json:"reservedCPUs,omitempty"`

        // The labels signifying the nodes the user wants to use
        PowerNodeSelector map[string]string `json:"powerNodeSelector,omitempty"`

        // Holds the info on the node name and cpu ids for each node
        //Node NodeInfo `json:"nodeInfo,omitempty"`

        Node WorkloadNode `json:"workloadNodes,omitempty"`

        // PowerProfile is the Profile that this PowerWorkload is based on
        PowerProfile string `json:"powerProfile,omitempty"`
}

type ReservedSpec struct {
        Cores        []uint `json:"cores"`
        PowerProfile string `json:"powerProfile,omitempty"`
}

// PowerWorkloadStatus defines the observed state of PowerWorkload
type PowerWorkloadStatus struct {
        // The Node that this Shared PowerWorkload is associated with
        Node         string `json:"node:,omitempty"`
        StatusErrors `json:",inline,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status

// PowerWorkload is the Schema for the powerworkloads API
type PowerWorkload struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   PowerWorkloadSpec   `json:"spec,omitempty"`
        Status PowerWorkloadStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// PowerWorkloadList contains a list of PowerWorkload
type PowerWorkloadList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []PowerWorkload `json:"items"`
}

func (wrkld *PowerWorkload) SetStatusErrors(errs *[]string) <span class="cov8" title="1">{
        wrkld.Status.Errors = *errs
}</span>

func (wrkld *PowerWorkload) GetStatusErrors() *[]string <span class="cov8" title="1">{
        return &amp;wrkld.Status.Errors
}</span>

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;PowerWorkload{}, &amp;PowerWorkloadList{})
}</span>
</pre>
		
		<pre class="file" id="file8" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

type ScheduleInfo struct {
        Time string `json:"time"`

        PowerProfile *string      `json:"powerProfile,omitempty"`
        Pods         *[]PodInfo   `json:"pods,omitempty"`
        CState       *CStatesSpec `json:"cState,omitempty"`
}

// TimeOfDaySpec defines the desired state of TimeOfDay
type TimeOfDaySpec struct {
        // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
        // Important: Run "make" to regenerate code after modifying this file

        // Time Zone to use for scheduling
        TimeZone string `json:"timeZone,omitempty"`

        // Schedule for adjusting performance mode
        Schedule     []ScheduleInfo `json:"schedule"`
        ReservedCPUs *[]uint        `json:"reservedCPUs,omitempty"`
}

// TimeOfDayStatus defines the observed state of TimeOfDay
type TimeOfDayStatus struct {
        // INSERT ADDITIONAL STATUS FIELD - define observed state of cluster
        // Important: Run "make" to regenerate code after modifying this file

        // The time of the last update
        LastSchedule string `json:"lastSchedule,omitempty"`

        // The time of the next update
        NextSchedule string `json:"nextSchedule,omitempty"`

        // PowerProfile associated with Time of Day
        PowerProfile string `json:"powerProfile,omitempty"`

        StatusErrors `json:",inline,omitempty"`
}

//+kubebuilder:object:root=true
//+kubebuilder:subresource:status

// TimeOfDay is the Schema for the timeofdays API
type TimeOfDay struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   TimeOfDaySpec   `json:"spec,omitempty"`
        Status TimeOfDayStatus `json:"status,omitempty"`
}

//+kubebuilder:object:root=true

// TimeOfDayList contains a list of TimeOfDay
type TimeOfDayList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []TimeOfDay `json:"items"`
}

func (tod *TimeOfDay) SetStatusErrors(errs *[]string) <span class="cov8" title="1">{
        tod.Status.Errors = *errs
}</span>

func (tod *TimeOfDay) GetStatusErrors() *[]string <span class="cov8" title="1">{
        return &amp;tod.Status.Errors
}</span>

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;TimeOfDay{}, &amp;TimeOfDayList{})
}</span>
</pre>
		
		<pre class="file" id="file9" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        v1 "k8s.io/api/core/v1"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        //batchv1 "k8s.io/api/batch/v1"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

// TimeOfDayCronJobSpec defines the desired state of TimeOfDayCronJob
type TimeOfDayCronJobSpec struct {
        // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
        // Important: Run "make" to regenerate code after modifying this file
        Hour         int          `json:"hour"`
        Minute       int          `json:"minute"`
        Second       int          `json:"second,omitempty"`
        TimeZone     *string      `json:"timeZone"`
        Profile      *string      `json:"profile"`
        Pods         *[]PodInfo   `json:"pods,omitempty"`
        ReservedCPUs *[]uint      `json:"reservedCPUs,omitempty"`
        CState       *CStatesSpec `json:"cState,omitempty"`
}

type PodInfo struct {
        Labels metav1.LabelSelector `json:"labels"`
        Target string               `json:"target"`
}

// TimeOfDayCronJobStatus defines the observed state of TimeOfDayCronJob
type TimeOfDayCronJobStatus struct {
        Active             []v1.ObjectReference `json:"active,omitempty"`
        LastScheduleTime   *metav1.Time         `json:"lastScheduleTime,omitempty"`
        LastSuccessfulTime *metav1.Time         `json:"lastSuccessfulTime,omitempty"`

        StatusErrors `json:",inline,omitempty"`
}

//+kubebuilder:object:root=true
//+kubebuilder:subresource:status

// TimeOfDayCronJob is the Schema for the timeofdaycronjobs API
type TimeOfDayCronJob struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`
        Spec              TimeOfDayCronJobSpec   `json:"spec,omitempty"`
        Status            TimeOfDayCronJobStatus `json:"status,omitempty"`
}

//+kubebuilder:object:root=true

// TimeOfDayCronJobList contains a list of TimeOfDayCronJob
type TimeOfDayCronJobList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []TimeOfDayCronJob `json:"items"`
}

func (todcr *TimeOfDayCronJob) SetStatusErrors(errs *[]string) <span class="cov0" title="0">{
        todcr.Status.Errors = *errs
}</span>
func (todcr *TimeOfDayCronJob) GetStatusErrors() *[]string <span class="cov0" title="0">{
        return &amp;todcr.Status.Errors
}</span>

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;TimeOfDayCronJob{}, &amp;TimeOfDayCronJobList{})
}</span>
</pre>
		
		<pre class="file" id="file10" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package v1

import (
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

// UncoreSpec defines the desired state of Uncore
type UncoreSpec struct {
        // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
        // Important: Run "make" to regenerate code after modifying this file

        SysMax       *uint          `json:"sysMax,omitempty"`
        SysMin       *uint          `json:"sysMin,omitempty"`
        DieSelectors *[]DieSelector `json:"dieSelector,omitempty"`
}

type DieSelector struct {
        Package *uint `json:"package"`
        Die     *uint `json:"die,omitempty"`
        Min     *uint `json:"min"`
        Max     *uint `json:"max"`
}

// UncoreStatus defines the observed state of Uncore
type UncoreStatus struct {
        StatusErrors `json:",inline,omitempty"`
}

//+kubebuilder:object:root=true
//+kubebuilder:subresource:status

// Uncore is the Schema for the uncores API
type Uncore struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   UncoreSpec   `json:"spec,omitempty"`
        Status UncoreStatus `json:"status,omitempty"`
}

//+kubebuilder:object:root=true

// UncoreList contains a list of Uncore
type UncoreList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []Uncore `json:"items"`
}

func (ucnre *Uncore) SetStatusErrors(err *[]string) <span class="cov0" title="0">{
        ucnre.Status.Errors = *err
}</span>

func (ucnre *Uncore) GetStatusErrors() *[]string <span class="cov0" title="0">{
        return &amp;ucnre.Status.Errors
}</span>

func init() <span class="cov8" title="1">{
        SchemeBuilder.Register(&amp;Uncore{}, &amp;UncoreList{})
}</span>
</pre>
		
		<pre class="file" id="file11" style="display: none">//go:build !ignore_autogenerated

/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Code generated by controller-gen. DO NOT EDIT.

package v1

import (
        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/runtime"
)

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CPUScalingConfiguration) DeepCopyInto(out *CPUScalingConfiguration) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CPUScalingConfiguration.
func (in *CPUScalingConfiguration) DeepCopy() *CPUScalingConfiguration <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(CPUScalingConfiguration)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *CPUScalingConfiguration) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CPUScalingConfigurationList) DeepCopyInto(out *CPUScalingConfigurationList) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]CPUScalingConfiguration, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CPUScalingConfigurationList.
func (in *CPUScalingConfigurationList) DeepCopy() *CPUScalingConfigurationList <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CPUScalingConfigurationList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *CPUScalingConfigurationList) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CPUScalingConfigurationSpec) DeepCopyInto(out *CPUScalingConfigurationSpec) <span class="cov8" title="1">{
        *out = *in
        if in.Items != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]ConfigItem, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CPUScalingConfigurationSpec.
func (in *CPUScalingConfigurationSpec) DeepCopy() *CPUScalingConfigurationSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CPUScalingConfigurationSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CPUScalingConfigurationStatus) DeepCopyInto(out *CPUScalingConfigurationStatus) <span class="cov8" title="1">{
        *out = *in
        in.StatusErrors.DeepCopyInto(&amp;out.StatusErrors)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CPUScalingConfigurationStatus.
func (in *CPUScalingConfigurationStatus) DeepCopy() *CPUScalingConfigurationStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CPUScalingConfigurationStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CPUScalingProfile) DeepCopyInto(out *CPUScalingProfile) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        out.Spec = in.Spec
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CPUScalingProfile.
func (in *CPUScalingProfile) DeepCopy() *CPUScalingProfile <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CPUScalingProfile)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *CPUScalingProfile) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CPUScalingProfileList) DeepCopyInto(out *CPUScalingProfileList) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]CPUScalingProfile, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CPUScalingProfileList.
func (in *CPUScalingProfileList) DeepCopy() *CPUScalingProfileList <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CPUScalingProfileList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *CPUScalingProfileList) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CPUScalingProfileSpec) DeepCopyInto(out *CPUScalingProfileSpec) <span class="cov0" title="0">{
        *out = *in
        out.SamplePeriod = in.SamplePeriod
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CPUScalingProfileSpec.
func (in *CPUScalingProfileSpec) DeepCopy() *CPUScalingProfileSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CPUScalingProfileSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CPUScalingProfileStatus) DeepCopyInto(out *CPUScalingProfileStatus) <span class="cov0" title="0">{
        *out = *in
        in.StatusErrors.DeepCopyInto(&amp;out.StatusErrors)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CPUScalingProfileStatus.
func (in *CPUScalingProfileStatus) DeepCopy() *CPUScalingProfileStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CPUScalingProfileStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CStates) DeepCopyInto(out *CStates) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CStates.
func (in *CStates) DeepCopy() *CStates <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(CStates)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *CStates) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CStatesList) DeepCopyInto(out *CStatesList) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]CStates, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CStatesList.
func (in *CStatesList) DeepCopy() *CStatesList <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CStatesList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *CStatesList) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CStatesSpec) DeepCopyInto(out *CStatesSpec) <span class="cov8" title="1">{
        *out = *in
        if in.SharedPoolCStates != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.SharedPoolCStates, &amp;out.SharedPoolCStates
                *out = make(map[string]bool, len(*in))
                for key, val := range *in </span><span class="cov8" title="1">{
                        (*out)[key] = val
                }</span>
        }
        <span class="cov8" title="1">if in.ExclusivePoolCStates != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.ExclusivePoolCStates, &amp;out.ExclusivePoolCStates
                *out = make(map[string]map[string]bool, len(*in))
                for key, val := range *in </span><span class="cov8" title="1">{
                        var outVal map[string]bool
                        if val == nil </span><span class="cov0" title="0">{
                                (*out)[key] = nil
                        }</span> else<span class="cov8" title="1"> {
                                inVal := (*in)[key]
                                in, out := &amp;inVal, &amp;outVal
                                *out = make(map[string]bool, len(*in))
                                for key, val := range *in </span><span class="cov8" title="1">{
                                        (*out)[key] = val
                                }</span>
                        }
                        <span class="cov8" title="1">(*out)[key] = outVal</span>
                }
        }
        <span class="cov8" title="1">if in.IndividualCoreCStates != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.IndividualCoreCStates, &amp;out.IndividualCoreCStates
                *out = make(map[string]map[string]bool, len(*in))
                for key, val := range *in </span><span class="cov8" title="1">{
                        var outVal map[string]bool
                        if val == nil </span><span class="cov0" title="0">{
                                (*out)[key] = nil
                        }</span> else<span class="cov8" title="1"> {
                                inVal := (*in)[key]
                                in, out := &amp;inVal, &amp;outVal
                                *out = make(map[string]bool, len(*in))
                                for key, val := range *in </span><span class="cov8" title="1">{
                                        (*out)[key] = val
                                }</span>
                        }
                        <span class="cov8" title="1">(*out)[key] = outVal</span>
                }
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CStatesSpec.
func (in *CStatesSpec) DeepCopy() *CStatesSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CStatesSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CStatesStatus) DeepCopyInto(out *CStatesStatus) <span class="cov8" title="1">{
        *out = *in
        in.StatusErrors.DeepCopyInto(&amp;out.StatusErrors)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CStatesStatus.
func (in *CStatesStatus) DeepCopy() *CStatesStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CStatesStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *ConfigItem) DeepCopyInto(out *ConfigItem) <span class="cov8" title="1">{
        *out = *in
        if in.CpuIDs != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.CpuIDs, &amp;out.CpuIDs
                *out = make([]uint, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov8" title="1">out.SamplePeriod = in.SamplePeriod</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ConfigItem.
func (in *ConfigItem) DeepCopy() *ConfigItem <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(ConfigItem)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *Container) DeepCopyInto(out *Container) <span class="cov8" title="1">{
        *out = *in
        if in.ExclusiveCPUs != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.ExclusiveCPUs, &amp;out.ExclusiveCPUs
                *out = make([]uint, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new Container.
func (in *Container) DeepCopy() *Container <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(Container)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *DieSelector) DeepCopyInto(out *DieSelector) <span class="cov0" title="0">{
        *out = *in
        if in.Package != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Package, &amp;out.Package
                *out = new(uint)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.Die != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Die, &amp;out.Die
                *out = new(uint)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.Min != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Min, &amp;out.Min
                *out = new(uint)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.Max != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Max, &amp;out.Max
                *out = new(uint)
                **out = **in
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new DieSelector.
func (in *DieSelector) DeepCopy() *DieSelector <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(DieSelector)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *GuaranteedPod) DeepCopyInto(out *GuaranteedPod) <span class="cov0" title="0">{
        *out = *in
        if in.Containers != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Containers, &amp;out.Containers
                *out = make([]Container, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new GuaranteedPod.
func (in *GuaranteedPod) DeepCopy() *GuaranteedPod <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(GuaranteedPod)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PodInfo) DeepCopyInto(out *PodInfo) <span class="cov8" title="1">{
        *out = *in
        in.Labels.DeepCopyInto(&amp;out.Labels)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PodInfo.
func (in *PodInfo) DeepCopy() *PodInfo <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PodInfo)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerConfig) DeepCopyInto(out *PowerConfig) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerConfig.
func (in *PowerConfig) DeepCopy() *PowerConfig <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(PowerConfig)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerConfig) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerConfigList) DeepCopyInto(out *PowerConfigList) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]PowerConfig, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerConfigList.
func (in *PowerConfigList) DeepCopy() *PowerConfigList <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(PowerConfigList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerConfigList) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerConfigSpec) DeepCopyInto(out *PowerConfigSpec) <span class="cov8" title="1">{
        *out = *in
        if in.PowerNodeSelector != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.PowerNodeSelector, &amp;out.PowerNodeSelector
                *out = make(map[string]string, len(*in))
                for key, val := range *in </span><span class="cov8" title="1">{
                        (*out)[key] = val
                }</span>
        }
        <span class="cov8" title="1">if in.PowerProfiles != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.PowerProfiles, &amp;out.PowerProfiles
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov8" title="1">if in.CustomDevices != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.CustomDevices, &amp;out.CustomDevices
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerConfigSpec.
func (in *PowerConfigSpec) DeepCopy() *PowerConfigSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerConfigSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerConfigStatus) DeepCopyInto(out *PowerConfigStatus) <span class="cov8" title="1">{
        *out = *in
        if in.Nodes != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Nodes, &amp;out.Nodes
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov8" title="1">in.StatusErrors.DeepCopyInto(&amp;out.StatusErrors)</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerConfigStatus.
func (in *PowerConfigStatus) DeepCopy() *PowerConfigStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerConfigStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerNode) DeepCopyInto(out *PowerNode) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerNode.
func (in *PowerNode) DeepCopy() *PowerNode <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(PowerNode)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerNode) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerNodeCPUState) DeepCopyInto(out *PowerNodeCPUState) <span class="cov8" title="1">{
        *out = *in
        if in.SharedPool != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.SharedPool, &amp;out.SharedPool
                *out = make([]uint, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov8" title="1">if in.GuaranteedPods != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.GuaranteedPods, &amp;out.GuaranteedPods
                *out = make([]GuaranteedPod, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerNodeCPUState.
func (in *PowerNodeCPUState) DeepCopy() *PowerNodeCPUState <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerNodeCPUState)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerNodeList) DeepCopyInto(out *PowerNodeList) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]PowerNode, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerNodeList.
func (in *PowerNodeList) DeepCopy() *PowerNodeList <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(PowerNodeList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerNodeList) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerNodeSpec) DeepCopyInto(out *PowerNodeSpec) <span class="cov8" title="1">{
        *out = *in
        if in.PowerProfiles != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.PowerProfiles, &amp;out.PowerProfiles
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov8" title="1">if in.PowerWorkloads != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.PowerWorkloads, &amp;out.PowerWorkloads
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov8" title="1">if in.ReservedPools != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.ReservedPools, &amp;out.ReservedPools
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov8" title="1">if in.PowerContainers != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.PowerContainers, &amp;out.PowerContainers
                *out = make([]Container, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
        <span class="cov8" title="1">if in.CustomDevices != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.CustomDevices, &amp;out.CustomDevices
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerNodeSpec.
func (in *PowerNodeSpec) DeepCopy() *PowerNodeSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerNodeSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerNodeStatus) DeepCopyInto(out *PowerNodeStatus) <span class="cov8" title="1">{
        *out = *in
        in.PowerNodeCPUState.DeepCopyInto(&amp;out.PowerNodeCPUState)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerNodeStatus.
func (in *PowerNodeStatus) DeepCopy() *PowerNodeStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerNodeStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerPod) DeepCopyInto(out *PowerPod) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        out.Spec = in.Spec
        out.Status = in.Status
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerPod.
func (in *PowerPod) DeepCopy() *PowerPod <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerPod)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerPod) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerPodList) DeepCopyInto(out *PowerPodList) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]PowerPod, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerPodList.
func (in *PowerPodList) DeepCopy() *PowerPodList <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerPodList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerPodList) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerPodSpec) DeepCopyInto(out *PowerPodSpec) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerPodSpec.
func (in *PowerPodSpec) DeepCopy() *PowerPodSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerPodSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerPodStatus) DeepCopyInto(out *PowerPodStatus) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerPodStatus.
func (in *PowerPodStatus) DeepCopy() *PowerPodStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerPodStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerProfile) DeepCopyInto(out *PowerProfile) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        out.Spec = in.Spec
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerProfile.
func (in *PowerProfile) DeepCopy() *PowerProfile <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(PowerProfile)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerProfile) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerProfileList) DeepCopyInto(out *PowerProfileList) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]PowerProfile, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerProfileList.
func (in *PowerProfileList) DeepCopy() *PowerProfileList <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(PowerProfileList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerProfileList) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerProfileSpec) DeepCopyInto(out *PowerProfileSpec) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerProfileSpec.
func (in *PowerProfileSpec) DeepCopy() *PowerProfileSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerProfileSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerProfileStatus) DeepCopyInto(out *PowerProfileStatus) <span class="cov8" title="1">{
        *out = *in
        in.StatusErrors.DeepCopyInto(&amp;out.StatusErrors)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerProfileStatus.
func (in *PowerProfileStatus) DeepCopy() *PowerProfileStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerProfileStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerWorkload) DeepCopyInto(out *PowerWorkload) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerWorkload.
func (in *PowerWorkload) DeepCopy() *PowerWorkload <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(PowerWorkload)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerWorkload) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerWorkloadList) DeepCopyInto(out *PowerWorkloadList) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]PowerWorkload, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerWorkloadList.
func (in *PowerWorkloadList) DeepCopy() *PowerWorkloadList <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(PowerWorkloadList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PowerWorkloadList) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerWorkloadSpec) DeepCopyInto(out *PowerWorkloadSpec) <span class="cov8" title="1">{
        *out = *in
        if in.ReservedCPUs != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.ReservedCPUs, &amp;out.ReservedCPUs
                *out = make([]ReservedSpec, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
        <span class="cov8" title="1">if in.PowerNodeSelector != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.PowerNodeSelector, &amp;out.PowerNodeSelector
                *out = make(map[string]string, len(*in))
                for key, val := range *in </span><span class="cov8" title="1">{
                        (*out)[key] = val
                }</span>
        }
        <span class="cov8" title="1">in.Node.DeepCopyInto(&amp;out.Node)</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerWorkloadSpec.
func (in *PowerWorkloadSpec) DeepCopy() *PowerWorkloadSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerWorkloadSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PowerWorkloadStatus) DeepCopyInto(out *PowerWorkloadStatus) <span class="cov8" title="1">{
        *out = *in
        in.StatusErrors.DeepCopyInto(&amp;out.StatusErrors)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PowerWorkloadStatus.
func (in *PowerWorkloadStatus) DeepCopy() *PowerWorkloadStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PowerWorkloadStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *ReservedSpec) DeepCopyInto(out *ReservedSpec) <span class="cov8" title="1">{
        *out = *in
        if in.Cores != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Cores, &amp;out.Cores
                *out = make([]uint, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ReservedSpec.
func (in *ReservedSpec) DeepCopy() *ReservedSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(ReservedSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *ScheduleInfo) DeepCopyInto(out *ScheduleInfo) <span class="cov8" title="1">{
        *out = *in
        if in.PowerProfile != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.PowerProfile, &amp;out.PowerProfile
                *out = new(string)
                **out = **in
        }</span>
        <span class="cov8" title="1">if in.Pods != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Pods, &amp;out.Pods
                *out = new([]PodInfo)
                if **in != nil </span><span class="cov8" title="1">{
                        in, out := *in, *out
                        *out = make([]PodInfo, len(*in))
                        for i := range *in </span><span class="cov8" title="1">{
                                (*in)[i].DeepCopyInto(&amp;(*out)[i])
                        }</span>
                }
        }
        <span class="cov8" title="1">if in.CState != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.CState, &amp;out.CState
                *out = new(CStatesSpec)
                (*in).DeepCopyInto(*out)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ScheduleInfo.
func (in *ScheduleInfo) DeepCopy() *ScheduleInfo <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(ScheduleInfo)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *SharedPoolInfo) DeepCopyInto(out *SharedPoolInfo) <span class="cov0" title="0">{
        *out = *in
        if in.CpuIds != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.CpuIds, &amp;out.CpuIds
                *out = make([]uint, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new SharedPoolInfo.
func (in *SharedPoolInfo) DeepCopy() *SharedPoolInfo <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(SharedPoolInfo)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *StatusErrors) DeepCopyInto(out *StatusErrors) <span class="cov8" title="1">{
        *out = *in
        if in.Errors != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Errors, &amp;out.Errors
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new StatusErrors.
func (in *StatusErrors) DeepCopy() *StatusErrors <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(StatusErrors)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimeOfDay) DeepCopyInto(out *TimeOfDay) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimeOfDay.
func (in *TimeOfDay) DeepCopy() *TimeOfDay <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(TimeOfDay)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *TimeOfDay) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimeOfDayCronJob) DeepCopyInto(out *TimeOfDayCronJob) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimeOfDayCronJob.
func (in *TimeOfDayCronJob) DeepCopy() *TimeOfDayCronJob <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(TimeOfDayCronJob)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *TimeOfDayCronJob) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimeOfDayCronJobList) DeepCopyInto(out *TimeOfDayCronJobList) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]TimeOfDayCronJob, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimeOfDayCronJobList.
func (in *TimeOfDayCronJobList) DeepCopy() *TimeOfDayCronJobList <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(TimeOfDayCronJobList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *TimeOfDayCronJobList) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimeOfDayCronJobSpec) DeepCopyInto(out *TimeOfDayCronJobSpec) <span class="cov8" title="1">{
        *out = *in
        if in.TimeZone != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.TimeZone, &amp;out.TimeZone
                *out = new(string)
                **out = **in
        }</span>
        <span class="cov8" title="1">if in.Profile != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Profile, &amp;out.Profile
                *out = new(string)
                **out = **in
        }</span>
        <span class="cov8" title="1">if in.Pods != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Pods, &amp;out.Pods
                *out = new([]PodInfo)
                if **in != nil </span><span class="cov8" title="1">{
                        in, out := *in, *out
                        *out = make([]PodInfo, len(*in))
                        for i := range *in </span><span class="cov8" title="1">{
                                (*in)[i].DeepCopyInto(&amp;(*out)[i])
                        }</span>
                }
        }
        <span class="cov8" title="1">if in.ReservedCPUs != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.ReservedCPUs, &amp;out.ReservedCPUs
                *out = new([]uint)
                if **in != nil </span><span class="cov8" title="1">{
                        in, out := *in, *out
                        *out = make([]uint, len(*in))
                        copy(*out, *in)
                }</span>
        }
        <span class="cov8" title="1">if in.CState != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.CState, &amp;out.CState
                *out = new(CStatesSpec)
                (*in).DeepCopyInto(*out)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimeOfDayCronJobSpec.
func (in *TimeOfDayCronJobSpec) DeepCopy() *TimeOfDayCronJobSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(TimeOfDayCronJobSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimeOfDayCronJobStatus) DeepCopyInto(out *TimeOfDayCronJobStatus) <span class="cov8" title="1">{
        *out = *in
        if in.Active != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Active, &amp;out.Active
                *out = make([]corev1.ObjectReference, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov8" title="1">if in.LastScheduleTime != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.LastScheduleTime, &amp;out.LastScheduleTime
                *out = (*in).DeepCopy()
        }</span>
        <span class="cov8" title="1">if in.LastSuccessfulTime != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.LastSuccessfulTime, &amp;out.LastSuccessfulTime
                *out = (*in).DeepCopy()
        }</span>
        <span class="cov8" title="1">in.StatusErrors.DeepCopyInto(&amp;out.StatusErrors)</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimeOfDayCronJobStatus.
func (in *TimeOfDayCronJobStatus) DeepCopy() *TimeOfDayCronJobStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(TimeOfDayCronJobStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimeOfDayList) DeepCopyInto(out *TimeOfDayList) <span class="cov8" title="1">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]TimeOfDay, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimeOfDayList.
func (in *TimeOfDayList) DeepCopy() *TimeOfDayList <span class="cov8" title="1">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">out := new(TimeOfDayList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *TimeOfDayList) DeepCopyObject() runtime.Object <span class="cov8" title="1">{
        if c := in.DeepCopy(); c != nil </span><span class="cov8" title="1">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimeOfDaySpec) DeepCopyInto(out *TimeOfDaySpec) <span class="cov8" title="1">{
        *out = *in
        if in.Schedule != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Schedule, &amp;out.Schedule
                *out = make([]ScheduleInfo, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
        <span class="cov8" title="1">if in.ReservedCPUs != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.ReservedCPUs, &amp;out.ReservedCPUs
                *out = new([]uint)
                if **in != nil </span><span class="cov8" title="1">{
                        in, out := *in, *out
                        *out = make([]uint, len(*in))
                        copy(*out, *in)
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimeOfDaySpec.
func (in *TimeOfDaySpec) DeepCopy() *TimeOfDaySpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(TimeOfDaySpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimeOfDayStatus) DeepCopyInto(out *TimeOfDayStatus) <span class="cov8" title="1">{
        *out = *in
        in.StatusErrors.DeepCopyInto(&amp;out.StatusErrors)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimeOfDayStatus.
func (in *TimeOfDayStatus) DeepCopy() *TimeOfDayStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(TimeOfDayStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *Uncore) DeepCopyInto(out *Uncore) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new Uncore.
func (in *Uncore) DeepCopy() *Uncore <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(Uncore)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *Uncore) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *UncoreList) DeepCopyInto(out *UncoreList) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]Uncore, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new UncoreList.
func (in *UncoreList) DeepCopy() *UncoreList <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(UncoreList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *UncoreList) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *UncoreSpec) DeepCopyInto(out *UncoreSpec) <span class="cov0" title="0">{
        *out = *in
        if in.SysMax != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.SysMax, &amp;out.SysMax
                *out = new(uint)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.SysMin != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.SysMin, &amp;out.SysMin
                *out = new(uint)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.DieSelectors != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.DieSelectors, &amp;out.DieSelectors
                *out = new([]DieSelector)
                if **in != nil </span><span class="cov0" title="0">{
                        in, out := *in, *out
                        *out = make([]DieSelector, len(*in))
                        for i := range *in </span><span class="cov0" title="0">{
                                (*in)[i].DeepCopyInto(&amp;(*out)[i])
                        }</span>
                }
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new UncoreSpec.
func (in *UncoreSpec) DeepCopy() *UncoreSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(UncoreSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *UncoreStatus) DeepCopyInto(out *UncoreStatus) <span class="cov0" title="0">{
        *out = *in
        in.StatusErrors.DeepCopyInto(&amp;out.StatusErrors)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new UncoreStatus.
func (in *UncoreStatus) DeepCopy() *UncoreStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(UncoreStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *WorkloadInfo) DeepCopyInto(out *WorkloadInfo) <span class="cov0" title="0">{
        *out = *in
        if in.CpuIds != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.CpuIds, &amp;out.CpuIds
                *out = make([]uint, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new WorkloadInfo.
func (in *WorkloadInfo) DeepCopy() *WorkloadInfo <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(WorkloadInfo)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *WorkloadNode) DeepCopyInto(out *WorkloadNode) <span class="cov8" title="1">{
        *out = *in
        if in.Containers != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.Containers, &amp;out.Containers
                *out = make([]Container, len(*in))
                for i := range *in </span><span class="cov8" title="1">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
        <span class="cov8" title="1">if in.CpuIds != nil </span><span class="cov8" title="1">{
                in, out := &amp;in.CpuIds, &amp;out.CpuIds
                *out = make([]uint, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new WorkloadNode.
func (in *WorkloadNode) DeepCopy() *WorkloadNode <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(WorkloadNode)
        in.DeepCopyInto(out)
        return out</span>
}
</pre>
		
		<pre class="file" id="file12" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
        "crypto/tls"
        "flag"
        "os"
        "time"

        // Import all Kubernetes client auth plugins (e.g. Azure, GCP, OIDC, etc.)
        // to ensure that exec-entrypoint and run can make use of them.
        _ "k8s.io/client-go/plugin/pkg/client/auth"

        "go.uber.org/zap/zapcore"
        "k8s.io/apimachinery/pkg/runtime"
        utilruntime "k8s.io/apimachinery/pkg/util/runtime"
        clientgoscheme "k8s.io/client-go/kubernetes/scheme"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/healthz"
        "sigs.k8s.io/controller-runtime/pkg/log/zap"
        metricsserver "sigs.k8s.io/controller-runtime/pkg/metrics/server"
        "sigs.k8s.io/controller-runtime/pkg/webhook"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"

        "github.com/intel/kubernetes-power-manager/internal/controller"
        "github.com/intel/kubernetes-power-manager/pkg/state"
        // +kubebuilder:scaffold:imports
)

var (
        scheme   = runtime.NewScheme()
        setupLog = ctrl.Log.WithName("setup")
)

func init() <span class="cov0" title="0">{
        utilruntime.Must(clientgoscheme.AddToScheme(scheme))

        utilruntime.Must(powerv1.AddToScheme(scheme))
        // +kubebuilder:scaffold:scheme
}</span>

func main() <span class="cov0" title="0">{
        var metricsAddr string
        var enableLeaderElection bool
        var probeAddr string
        var secureMetrics bool
        var enableHTTP2 bool
        flag.StringVar(&amp;metricsAddr, "metrics-bind-address", ":8080", "The address the metric endpoint binds to.")
        flag.StringVar(&amp;probeAddr, "health-probe-bind-address", ":8081", "The address the probe endpoint binds to.")
        flag.BoolVar(&amp;enableLeaderElection, "leader-elect", false,
                "Enable leader election for controller manager. "+
                        "Enabling this will ensure there is only one active controller manager.")
        flag.BoolVar(&amp;secureMetrics, "metrics-secure", false,
                "If set the metrics endpoint is served securely")
        flag.BoolVar(&amp;enableHTTP2, "enable-http2", false,
                "If set, HTTP/2 will be enabled for the metrics and webhook servers")

        logOpts := zap.Options{}
        logOpts.BindFlags(flag.CommandLine)
        flag.Parse()

        ctrl.SetLogger(zap.New(
                zap.UseDevMode(true),
                func(opts *zap.Options) </span><span class="cov0" title="0">{
                        opts.TimeEncoder = zapcore.ISO8601TimeEncoder
                }</span>,
                zap.UseFlagOptions(&amp;logOpts),
        ),
        )

        // if the enable-http2 flag is false (the default), http/2 should be disabled
        // due to its vulnerabilities. More specifically, disabling http/2 will
        // prevent from being vulnerable to the HTTP/2 Stream Cancellation and
        // Rapid Reset CVEs. For more information see:
        // - https://github.com/advisories/GHSA-qppj-fm5r-hxr3
        // - https://github.com/advisories/GHSA-4374-p667-p6c8
        <span class="cov0" title="0">disableHTTP2 := func(c *tls.Config) </span><span class="cov0" title="0">{
                setupLog.Info("disabling http/2")
                c.NextProtos = []string{"http/1.1"}
        }</span>

        <span class="cov0" title="0">tlsOpts := []func(*tls.Config){}
        if !enableHTTP2 </span><span class="cov0" title="0">{
                tlsOpts = append(tlsOpts, disableHTTP2)
        }</span>

        <span class="cov0" title="0">webhookServer := webhook.NewServer(webhook.Options{
                TLSOpts: tlsOpts,
        })
        renewDeadline := time.Second * time.Duration(20)
        leaseDuration := time.Second * time.Duration(30)
        mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{
                Scheme: scheme,
                Metrics: metricsserver.Options{
                        BindAddress:   metricsAddr,
                        SecureServing: secureMetrics,
                        TLSOpts:       tlsOpts,
                },
                WebhookServer:          webhookServer,
                HealthProbeBindAddress: probeAddr,
                LeaderElection:         enableLeaderElection,
                LeaderElectionID:       "power-operator-6846766c",
                RenewDeadline:          &amp;renewDeadline,
                LeaseDuration:          &amp;leaseDuration,
        })
        if err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to start manager")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">state := state.NewPowerNodeData()

        if err = (&amp;controller.PowerConfigReconciler{
                Client: mgr.GetClient(),
                Log:    ctrl.Log.WithName("controllers").WithName("PowerConfig"),
                Scheme: mgr.GetScheme(),
                State:  state,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "PowerConfig")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.CPUScalingProfileReconciler{
                Client: mgr.GetClient(),
                Log:    ctrl.Log.WithName("controllers").WithName("CPUScalingProfile"),
                Scheme: mgr.GetScheme(),
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "CPUScalingProfile")
                os.Exit(1)
        }</span>
        // +kubebuilder:scaffold:builder

        <span class="cov0" title="0">if err := mgr.AddHealthzCheck("healthz", healthz.Ping); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to set up health check")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err := mgr.AddReadyzCheck("readyz", healthz.Ping); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to set up ready check")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">setupLog.Info("starting manager")
        if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "problem running manager")
                os.Exit(1)
        }</span>
}
</pre>
		
		<pre class="file" id="file13" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
        "crypto/tls"
        "flag"
        "fmt"
        "os"

        // Import all Kubernetes client auth plugins (e.g. Azure, GCP, OIDC, etc.)
        // to ensure that exec-entrypoint and run can make use of them.
        _ "k8s.io/client-go/plugin/pkg/client/auth"

        "go.uber.org/zap/zapcore"
        "k8s.io/apimachinery/pkg/runtime"
        utilruntime "k8s.io/apimachinery/pkg/util/runtime"
        clientgoscheme "k8s.io/client-go/kubernetes/scheme"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/healthz"
        "sigs.k8s.io/controller-runtime/pkg/log/zap"
        metricsserver "sigs.k8s.io/controller-runtime/pkg/metrics/server"
        "sigs.k8s.io/controller-runtime/pkg/webhook"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/kubernetes-power-manager/internal/metrics"
        "github.com/intel/kubernetes-power-manager/internal/monitoring"
        "github.com/intel/kubernetes-power-manager/pkg/podresourcesclient"

        "github.com/intel/power-optimization-library/pkg/power"
        corev1 "k8s.io/api/core/v1"

        "github.com/intel/kubernetes-power-manager/internal/controller"
        "github.com/intel/kubernetes-power-manager/internal/scaling"
        "github.com/intel/kubernetes-power-manager/pkg/podstate"
        // +kubebuilder:scaffold:imports
)

var (
        scheme   = runtime.NewScheme()
        setupLog = ctrl.Log.WithName("setup")
)

func init() <span class="cov0" title="0">{
        utilruntime.Must(clientgoscheme.AddToScheme(scheme))

        utilruntime.Must(powerv1.AddToScheme(scheme))
        // +kubebuilder:scaffold:scheme
}</span>

func main() <span class="cov0" title="0">{
        var metricsAddr string
        var enableLeaderElection bool
        var probeAddr string
        var secureMetrics bool
        var enableHTTP2 bool
        flag.StringVar(&amp;metricsAddr, "metrics-bind-address", ":10001", "The address the metric endpoint binds to.")
        flag.StringVar(&amp;probeAddr, "health-probe-bind-address", ":10002", "The address the probe endpoint binds to.")
        flag.BoolVar(&amp;enableLeaderElection, "leader-elect", false,
                "Enable leader election for controller manager. "+
                        "Enabling this will ensure there is only one active controller manager.")
        flag.BoolVar(&amp;secureMetrics, "metrics-secure", false,
                "If set the metrics endpoint is served securely")
        flag.BoolVar(&amp;enableHTTP2, "enable-http2", false,
                "If set, HTTP/2 will be enabled for the metrics and webhook servers")
        logOpts := zap.Options{}
        logOpts.BindFlags(flag.CommandLine)
        flag.Parse()

        ctrl.SetLogger(zap.New(
                zap.UseDevMode(true),
                func(o *zap.Options) </span><span class="cov0" title="0">{
                        o.TimeEncoder = zapcore.ISO8601TimeEncoder
                }</span>,
                zap.UseFlagOptions(&amp;logOpts),
        ),
        )

        // if the enable-http2 flag is false (the default), http/2 should be disabled
        // due to its vulnerabilities. More specifically, disabling http/2 will
        // prevent from being vulnerable to the HTTP/2 Stream Cancellation and
        // Rapid Reset CVEs. For more information see:
        // - https://github.com/advisories/GHSA-qppj-fm5r-hxr3
        // - https://github.com/advisories/GHSA-4374-p667-p6c8
        <span class="cov0" title="0">disableHTTP2 := func(c *tls.Config) </span><span class="cov0" title="0">{
                setupLog.Info("disabling http/2")
                c.NextProtos = []string{"http/1.1"}
        }</span>

        <span class="cov0" title="0">tlsOpts := []func(*tls.Config){}
        if !enableHTTP2 </span><span class="cov0" title="0">{
                tlsOpts = append(tlsOpts, disableHTTP2)
        }</span>

        <span class="cov0" title="0">webhookServer := webhook.NewServer(webhook.Options{
                TLSOpts: tlsOpts,
        })

        mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{
                Scheme: scheme,
                Metrics: metricsserver.Options{
                        BindAddress:   metricsAddr,
                        SecureServing: secureMetrics,
                        TLSOpts:       tlsOpts,
                },
                WebhookServer:          webhookServer,
                HealthProbeBindAddress: probeAddr,
                LeaderElection:         enableLeaderElection,
                LeaderElectionID:       "f3490581.intel.com",
                // LeaderElectionReleaseOnCancel defines if the leader should step down voluntarily
                // when the Manager ends. This requires the binary to immediately end when the
                // Manager is stopped, otherwise, this setting is unsafe. Setting this significantly
                // speeds up voluntary leader transitions as the new leader don't have to wait
                // LeaseDuration time first.
                //
                // In the default scaffold provided, the program ends immediately after
                // the manager stops, so would be fine to enable this option. However,
                // if you are doing or is intended to do any operation such as perform cleanups
                // after the manager stops then its usage might be unsafe.
                // LeaderElectionReleaseOnCancel: true,
        })
        if err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to start manager")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">power.SetLogger(ctrl.Log.WithName("powerLibrary"))
        nodeName := os.Getenv("NODE_NAME")
        powerLibrary, err := power.CreateInstance(nodeName)
        if powerLibrary == nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create Power Library instance")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">for id, feature := range powerLibrary.GetFeaturesInfo() </span><span class="cov0" title="0">{
                setupLog.Info(
                        "feature status",
                        "feature", feature.Name(),
                        "driver", feature.Driver(),
                        "error", feature.FeatureError(),
                        "available", power.IsFeatureSupported(id))
                if id == power.FrequencyScalingFeature </span><span class="cov0" title="0">{
                        govs := power.GetAvailableGovernors()
                        setupLog.Info(fmt.Sprintf("available governors: %v", govs))
                }</span>
        }

        <span class="cov0" title="0">powerNodeState, err := podstate.NewState()
        if err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create internal state")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">podResourcesClient, err := podresourcesclient.NewDualSocketPodClient()

        if err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create internal client")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">perfEventClient := metrics.NewPerfEventClient(
                ctrl.Log.WithName("clients").WithName("PerfEventClient"),
                powerLibrary,
        )
        defer perfEventClient.Close()

        msrClient := metrics.NewMSRClient(
                ctrl.Log.WithName("clients").WithName("MSRClient"),
                powerLibrary,
        )
        defer msrClient.Close()

        esmiClient, esmiErr := metrics.NewESMIClient(
                ctrl.Log.WithName("clients").WithName("ESMIClient"),
        )

        logger := ctrl.Log.WithName(monitoring.LogTopName)
        monitoring.RegisterPerfEventCollectors(perfEventClient, powerLibrary, logger)
        monitoring.RegisterMSRCollectors(msrClient, powerLibrary, logger)
        if esmiErr == nil </span><span class="cov0" title="0">{
                monitoring.RegisterESMICollectors(esmiClient, powerLibrary, logger)
        }</span>

        <span class="cov0" title="0">cpuScalingMgr := scaling.NewCPUScalingManager(&amp;powerLibrary)
        if err = mgr.Add(cpuScalingMgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to register runnable", "runnable", "CPUScalingManager")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">if err = (&amp;controller.PowerProfileReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("PowerProfile"),
                Scheme:       mgr.GetScheme(),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "PowerProfile")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.PowerWorkloadReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("PowerWorkload"),
                Scheme:       mgr.GetScheme(),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "PowerWorkload")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.PowerNodeReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("PowerNode"),
                Scheme:       mgr.GetScheme(),
                State:        powerNodeState,
                OrphanedPods: make(map[string]corev1.Pod),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "PowerNode")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.PowerPodReconciler{
                Client:             mgr.GetClient(),
                Log:                ctrl.Log.WithName("controllers").WithName("PowerPod"),
                Scheme:             mgr.GetScheme(),
                State:              powerNodeState,
                PodResourcesClient: *podResourcesClient,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "PowerPod")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.CStatesReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("CState"),
                Scheme:       mgr.GetScheme(),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "CStates")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.TimeOfDayReconciler{
                Client: mgr.GetClient(),
                Log:    ctrl.Log.WithName("controllers").WithName("TimeOfDay"),
                Scheme: mgr.GetScheme(),
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "TimeOfDay")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.TimeOfDayCronJobReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("TimeOfDayCronJob"),
                Scheme:       mgr.GetScheme(),
                State:        powerNodeState,
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "TimeOfDayCronJob")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.UncoreReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("Uncore"),
                Scheme:       mgr.GetScheme(),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "Uncore")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.CPUScalingConfigurationReconciler{
                Client:            mgr.GetClient(),
                Log:               ctrl.Log.WithName("controllers").WithName("CPUScalingConfiguration"),
                Scheme:            mgr.GetScheme(),
                PowerLibrary:      powerLibrary,
                CPUScalingManager: cpuScalingMgr,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "CPUScalingConfiguration")
                os.Exit(1)
        }</span>
        // +kubebuilder:scaffold:builder

        <span class="cov0" title="0">if err := mgr.AddHealthzCheck("healthz", healthz.Ping); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to set up health check")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err := mgr.AddReadyzCheck("readyz", healthz.Ping); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to set up ready check")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">setupLog.Info("starting manager")
        if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "problem running manager")
                os.Exit(1)
        }</span>
}
</pre>
		
		<pre class="file" id="file14" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
        "crypto/tls"
        "flag"
        "fmt"
        "os"

        // Import all Kubernetes client auth plugins (e.g. Azure, GCP, OIDC, etc.)
        // to ensure that exec-entrypoint and run can make use of them.
        _ "k8s.io/client-go/plugin/pkg/client/auth"

        "go.uber.org/zap/zapcore"
        "k8s.io/apimachinery/pkg/runtime"
        utilruntime "k8s.io/apimachinery/pkg/util/runtime"
        clientgoscheme "k8s.io/client-go/kubernetes/scheme"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/healthz"
        "sigs.k8s.io/controller-runtime/pkg/log/zap"
        metricsserver "sigs.k8s.io/controller-runtime/pkg/metrics/server"
        "sigs.k8s.io/controller-runtime/pkg/webhook"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/kubernetes-power-manager/internal/metrics"
        "github.com/intel/kubernetes-power-manager/internal/monitoring"
        "github.com/intel/kubernetes-power-manager/pkg/podresourcesclient"

        "github.com/intel/power-optimization-library/pkg/power"
        corev1 "k8s.io/api/core/v1"

        "github.com/intel/kubernetes-power-manager/internal/controller"
        "github.com/intel/kubernetes-power-manager/internal/scaling"
        "github.com/intel/kubernetes-power-manager/pkg/podstate"
        // +kubebuilder:scaffold:imports
)

var (
        scheme   = runtime.NewScheme()
        setupLog = ctrl.Log.WithName("setup")
)

func init() <span class="cov0" title="0">{
        utilruntime.Must(clientgoscheme.AddToScheme(scheme))

        utilruntime.Must(powerv1.AddToScheme(scheme))
        // +kubebuilder:scaffold:scheme
}</span>

func main() <span class="cov0" title="0">{
        var metricsAddr string
        var enableLeaderElection bool
        var probeAddr string
        var secureMetrics bool
        var enableHTTP2 bool
        flag.StringVar(&amp;metricsAddr, "metrics-bind-address", ":10001", "The address the metric endpoint binds to.")
        flag.StringVar(&amp;probeAddr, "health-probe-bind-address", ":10002", "The address the probe endpoint binds to.")
        flag.BoolVar(&amp;enableLeaderElection, "leader-elect", false,
                "Enable leader election for controller manager. "+
                        "Enabling this will ensure there is only one active controller manager.")
        flag.BoolVar(&amp;secureMetrics, "metrics-secure", false,
                "If set the metrics endpoint is served securely")
        flag.BoolVar(&amp;enableHTTP2, "enable-http2", false,
                "If set, HTTP/2 will be enabled for the metrics and webhook servers")
        logOpts := zap.Options{}
        logOpts.BindFlags(flag.CommandLine)
        flag.Parse()

        ctrl.SetLogger(zap.New(
                zap.UseDevMode(true),
                func(o *zap.Options) </span><span class="cov0" title="0">{
                        o.TimeEncoder = zapcore.ISO8601TimeEncoder
                }</span>,
                zap.UseFlagOptions(&amp;logOpts),
        ),
        )

        // if the enable-http2 flag is false (the default), http/2 should be disabled
        // due to its vulnerabilities. More specifically, disabling http/2 will
        // prevent from being vulnerable to the HTTP/2 Stream Cancellation and
        // Rapid Reset CVEs. For more information see:
        // - https://github.com/advisories/GHSA-qppj-fm5r-hxr3
        // - https://github.com/advisories/GHSA-4374-p667-p6c8
        <span class="cov0" title="0">disableHTTP2 := func(c *tls.Config) </span><span class="cov0" title="0">{
                setupLog.Info("disabling http/2")
                c.NextProtos = []string{"http/1.1"}
        }</span>

        <span class="cov0" title="0">tlsOpts := []func(*tls.Config){}
        if !enableHTTP2 </span><span class="cov0" title="0">{
                tlsOpts = append(tlsOpts, disableHTTP2)
        }</span>

        <span class="cov0" title="0">webhookServer := webhook.NewServer(webhook.Options{
                TLSOpts: tlsOpts,
        })

        mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{
                Scheme: scheme,
                Metrics: metricsserver.Options{
                        BindAddress:   metricsAddr,
                        SecureServing: secureMetrics,
                        TLSOpts:       tlsOpts,
                },
                WebhookServer:          webhookServer,
                HealthProbeBindAddress: probeAddr,
                LeaderElection:         enableLeaderElection,
                LeaderElectionID:       "f3490581.intel.com",
                // LeaderElectionReleaseOnCancel defines if the leader should step down voluntarily
                // when the Manager ends. This requires the binary to immediately end when the
                // Manager is stopped, otherwise, this setting is unsafe. Setting this significantly
                // speeds up voluntary leader transitions as the new leader don't have to wait
                // LeaseDuration time first.
                //
                // In the default scaffold provided, the program ends immediately after
                // the manager stops, so would be fine to enable this option. However,
                // if you are doing or is intended to do any operation such as perform cleanups
                // after the manager stops then its usage might be unsafe.
                // LeaderElectionReleaseOnCancel: true,
        })
        if err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to start manager")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">power.SetLogger(ctrl.Log.WithName("powerLibrary"))
        nodeName := os.Getenv("NODE_NAME")
        powerLibrary, err := power.CreateInstance(nodeName)
        if powerLibrary == nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create Power Library instance")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">for id, feature := range powerLibrary.GetFeaturesInfo() </span><span class="cov0" title="0">{
                setupLog.Info(
                        "feature status",
                        "feature", feature.Name(),
                        "driver", feature.Driver(),
                        "error", feature.FeatureError(),
                        "available", power.IsFeatureSupported(id))
                if id == power.FrequencyScalingFeature </span><span class="cov0" title="0">{
                        govs := power.GetAvailableGovernors()
                        setupLog.Info(fmt.Sprintf("available governors: %v", govs))
                }</span>
        }

        <span class="cov0" title="0">powerNodeState, err := podstate.NewState()
        if err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create internal state")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">podResourcesClient, err := podresourcesclient.NewDualSocketPodClient()

        if err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create internal client")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">perfEventClient := metrics.NewPerfEventClient(
                ctrl.Log.WithName("clients").WithName("PerfEventClient"),
                powerLibrary,
        )
        defer perfEventClient.Close()

        msrClient := metrics.NewMSRClient(
                ctrl.Log.WithName("clients").WithName("MSRClient"),
                powerLibrary,
        )
        defer msrClient.Close()

        esmiClient, esmiErr := metrics.NewESMIClient(
                ctrl.Log.WithName("clients").WithName("ESMIClient"),
        )

        logger := ctrl.Log.WithName(monitoring.LogTopName)
        monitoring.RegisterPerfEventCollectors(perfEventClient, powerLibrary, logger)
        monitoring.RegisterMSRCollectors(msrClient, powerLibrary, logger)
        if esmiErr == nil </span><span class="cov0" title="0">{
                monitoring.RegisterESMICollectors(esmiClient, powerLibrary, logger)
        }</span>

        <span class="cov0" title="0">cpuScalingMgr := scaling.NewCPUScalingManager(&amp;powerLibrary)
        if err = mgr.Add(cpuScalingMgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to register runnable", "runnable", "CPUScalingManager")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">if err = (&amp;controller.PowerProfileReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("PowerProfile"),
                Scheme:       mgr.GetScheme(),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "PowerProfile")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.PowerWorkloadReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("PowerWorkload"),
                Scheme:       mgr.GetScheme(),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "PowerWorkload")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.PowerNodeReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("PowerNode"),
                Scheme:       mgr.GetScheme(),
                State:        powerNodeState,
                OrphanedPods: make(map[string]corev1.Pod),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "PowerNode")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.PowerPodReconciler{
                Client:             mgr.GetClient(),
                Log:                ctrl.Log.WithName("controllers").WithName("PowerPod"),
                Scheme:             mgr.GetScheme(),
                State:              powerNodeState,
                PodResourcesClient: *podResourcesClient,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "PowerPod")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.CStatesReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("CState"),
                Scheme:       mgr.GetScheme(),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "CStates")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.TimeOfDayReconciler{
                Client: mgr.GetClient(),
                Log:    ctrl.Log.WithName("controllers").WithName("TimeOfDay"),
                Scheme: mgr.GetScheme(),
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "TimeOfDay")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.TimeOfDayCronJobReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("TimeOfDayCronJob"),
                Scheme:       mgr.GetScheme(),
                State:        powerNodeState,
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "TimeOfDayCronJob")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.UncoreReconciler{
                Client:       mgr.GetClient(),
                Log:          ctrl.Log.WithName("controllers").WithName("Uncore"),
                Scheme:       mgr.GetScheme(),
                PowerLibrary: powerLibrary,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "Uncore")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err = (&amp;controller.CPUScalingConfigurationReconciler{
                Client:            mgr.GetClient(),
                Log:               ctrl.Log.WithName("controllers").WithName("CPUScalingConfiguration"),
                Scheme:            mgr.GetScheme(),
                PowerLibrary:      powerLibrary,
                CPUScalingManager: cpuScalingMgr,
        }).SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to create controller", "controller", "CPUScalingConfiguration")
                os.Exit(1)
        }</span>
        // +kubebuilder:scaffold:builder

        <span class="cov0" title="0">if err := mgr.AddHealthzCheck("healthz", healthz.Ping); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to set up health check")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err := mgr.AddReadyzCheck("readyz", healthz.Ping); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "unable to set up ready check")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">setupLog.Info("starting manager")
        if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil </span><span class="cov0" title="0">{
                setupLog.Error(err, "problem running manager")
                os.Exit(1)
        }</span>
}
</pre>
		
		<pre class="file" id="file15" style="display: none">/*
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/
package controller

import (
        "context"
        "reflect"

        "github.com/go-logr/logr"
        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/kubernetes-power-manager/pkg/util"
        "sigs.k8s.io/controller-runtime/pkg/client"
)

// write errors to the status filed, pass nil to clear errors, will only do update resource is valid and not being deleted
// if object already has the correct errors it will not be updated in the API
func writeUpdatedStatusErrsIfRequired(ctx context.Context, statusWriter client.SubResourceWriter, object powerv1.PowerCRWithStatusErrors, objectErrors error) error <span class="cov8" title="1">{
        var err error
        // if invalid or marked for deletion don't do anything
        if object.GetUID() == "" || object.GetDeletionTimestamp() != nil </span><span class="cov8" title="1">{
                return err
        }</span>
        <span class="cov8" title="1">errList := util.UnpackErrsToStrings(objectErrors)
        // no updates are needed
        if reflect.DeepEqual(*errList, *object.GetStatusErrors()) </span><span class="cov8" title="1">{
                return err
        }</span>
        <span class="cov8" title="1">object.SetStatusErrors(errList)
        err = statusWriter.Update(ctx, object)
        if err != nil </span><span class="cov8" title="1">{
                logr.FromContextOrDiscard(ctx).Error(err, "failed to write status update")
        }</span>
        <span class="cov8" title="1">return err</span>
}
</pre>
		
		<pre class="file" id="file16" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        "fmt"
        "os"
        "slices"
        "time"

        "github.com/go-logr/logr"
        "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/runtime"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/predicate"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/kubernetes-power-manager/internal/scaling"
        "github.com/intel/power-optimization-library/pkg/power"
)

// CPUScalingConfigurationReconciler reconciles a CPUScalingConfiguration object
type CPUScalingConfigurationReconciler struct {
        client.Client
        Log               logr.Logger
        Scheme            *runtime.Scheme
        PowerLibrary      power.Host
        CPUScalingManager scaling.CPUScalingManager
}

var (
        minSamplePeriod = time.Duration(10 * time.Millisecond)
        maxSamplePeriod = time.Duration(1 * time.Second)
)

//+kubebuilder:rbac:groups=power.intel.com,resources=cpuscalingconfigurations,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups=power.intel.com,resources=cpuscalingconfigurations/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=power.intel.com,resources=cpuscalingconfigurations/finalizers,verbs=update

// Reconcile is part of the main kubernetes reconciliation loop which aims to
// move the current state of the cluster closer to the desired state.
// For more details, check Reconcile and its Result here:
// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.17.3/pkg/reconcile
func (r *CPUScalingConfigurationReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        var err error
        nodeName := os.Getenv("NODE_NAME")

        // check if this config belongs to the current node
        if req.Name != nodeName </span><span class="cov0" title="0">{
                return ctrl.Result{}, nil
        }</span>

        <span class="cov8" title="1">logger := r.Log.WithValues("cpuscalingconfiguration", req.NamespacedName)
        if req.Namespace != IntelPowerNamespace </span><span class="cov8" title="1">{
                err := fmt.Errorf("incorrect namespace")
                logger.Error(err, "resource is not in the power-manager namespace, ignoring")
                // NOTE: Returning error is not the correct way to refuse reconciliation as
                // it will not prevent requeueing. But it is used regardless because
                // it allows testing this specific condition.
                return ctrl.Result{}, err
        }</span>

        <span class="cov8" title="1">config := &amp;powerv1.CPUScalingConfiguration{}
        defer func() </span><span class="cov8" title="1">{ _ = writeUpdatedStatusErrsIfRequired(ctx, r.Status(), config, err) }</span>()

        <span class="cov8" title="1">err = r.Client.Get(context.TODO(), req.NamespacedName, config)
        logger.V(5).Info("retrieving the cpu scaling configuration instance")
        if err != nil </span><span class="cov8" title="1">{
                if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                        r.CPUScalingManager.UpdateConfig([]scaling.CPUScalingOpts{})

                        return ctrl.Result{}, nil
                }</span>

                <span class="cov0" title="0">logger.Error(err, "could not retrieve the cpu scaling configuration instance")
                return ctrl.Result{}, err</span>
        }

        // validate values
        <span class="cov8" title="1">err = r.validateCPUIDs(config.Spec.Items)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "error validating cpu ids")
                return ctrl.Result{}, nil
        }</span>
        <span class="cov8" title="1">err = r.validateSamplePeriods(config.Spec.Items)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "error validating sample periods")
                return ctrl.Result{}, nil
        }</span>

        <span class="cov8" title="1">r.CPUScalingManager.UpdateConfig(
                r.parseConfig(config.Spec.Items),
        )

        return ctrl.Result{}, nil</span>
}

func (r *CPUScalingConfigurationReconciler) validateCPUIDs(configItems []powerv1.ConfigItem) error <span class="cov8" title="1">{
        nodeName := os.Getenv("NODE_NAME")
        availableCPUs := r.PowerLibrary.GetAllCpus().IDs()
        affectedCPUs := []uint{}

        for _, item := range configItems </span><span class="cov8" title="1">{
                for _, cpuID := range item.CpuIDs </span><span class="cov8" title="1">{
                        if !slices.Contains(availableCPUs, cpuID) </span><span class="cov8" title="1">{
                                return fmt.Errorf("cpu with id %d is not available on node %s", cpuID, nodeName)
                        }</span>
                        <span class="cov8" title="1">if slices.Contains(affectedCPUs, cpuID) </span><span class="cov8" title="1">{
                                return fmt.Errorf("cpu with id %d is specified more than once on node %s", cpuID, nodeName)
                        }</span>
                        <span class="cov8" title="1">affectedCPUs = append(affectedCPUs, cpuID)</span>
                }
        }

        <span class="cov8" title="1">return nil</span>
}

func (r *CPUScalingConfigurationReconciler) validateSamplePeriods(configItems []powerv1.ConfigItem) error <span class="cov8" title="1">{
        for _, item := range configItems </span><span class="cov8" title="1">{
                samplePeriod := item.SamplePeriod.Duration
                if samplePeriod &lt; minSamplePeriod </span><span class="cov8" title="1">{
                        return fmt.Errorf("sample period %s is below minimum limit %s", samplePeriod, minSamplePeriod)
                }</span>
                <span class="cov8" title="1">if samplePeriod &gt; maxSamplePeriod </span><span class="cov8" title="1">{
                        return fmt.Errorf("sample period %s is above maximum limit %s", samplePeriod, maxSamplePeriod)
                }</span>
        }

        <span class="cov8" title="1">return nil</span>
}

func (r *CPUScalingConfigurationReconciler) parseConfig(configItems []powerv1.ConfigItem) []scaling.CPUScalingOpts <span class="cov8" title="1">{
        optsList := make([]scaling.CPUScalingOpts, 0)

        for _, item := range configItems </span><span class="cov8" title="1">{
                for _, cpuID := range item.CpuIDs </span><span class="cov8" title="1">{
                        opts := scaling.CPUScalingOpts{
                                CPUID:        cpuID,
                                SamplePeriod: item.SamplePeriod.Duration,
                        }
                        optsList = append(optsList, opts)
                }</span>
        }

        <span class="cov8" title="1">return optsList</span>
}

// SetupWithManager sets up the controller with the Manager.
func (r *CPUScalingConfigurationReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov0" title="0">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.CPUScalingConfiguration{}).
                WithEventFilter(predicate.GenerationChangedPredicate{}).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file17" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"

        "github.com/go-logr/logr"
        "k8s.io/apimachinery/pkg/runtime"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/log"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
)

// CPUScalingProfileReconciler reconciles a CPUScalingProfile object
type CPUScalingProfileReconciler struct {
        client.Client
        Log    logr.Logger
        Scheme *runtime.Scheme
}

//+kubebuilder:rbac:groups=power.intel.com,resources=cpuscalingprofiles,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups=power.intel.com,resources=cpuscalingprofiles/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=power.intel.com,resources=cpuscalingprofiles/finalizers,verbs=update

// Reconcile is part of the main kubernetes reconciliation loop which aims to
// move the current state of the cluster closer to the desired state.
// TODO(user): Modify the Reconcile function to compare the state specified by
// the CPUScalingProfile object against the actual cluster state, and then
// perform operations to make the cluster state reflect the state specified by
// the user.
//
// For more details, check Reconcile and its Result here:
// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.17.3/pkg/reconcile
func (r *CPUScalingProfileReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        _ = log.FromContext(ctx)

        // TODO(user): your logic here

        return ctrl.Result{}, nil
}</span>

// SetupWithManager sets up the controller with the Manager.
func (r *CPUScalingProfileReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov0" title="0">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.CPUScalingProfile{}).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file18" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        e "errors"
        "fmt"
        "os"
        "strconv"
        "time"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/power-optimization-library/pkg/power"

        "github.com/go-logr/logr"
        "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/runtime"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/predicate"
)

// CStatesReconciler reconciles a CStates object
type CStatesReconciler struct {
        client.Client
        Log          logr.Logger
        Scheme       *runtime.Scheme
        PowerLibrary power.Host
}

//+kubebuilder:rbac:groups=power.intel.com,resources=cstates,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups=power.intel.com,resources=cstates/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=security.openshift.io,resources=securitycontextconstraints,resourceNames=privileged,verbs=use

// Reconcile is part of the main kubernetes reconciliation loop which aims to
// move the current state of the cluster closer to the desired state.
//
// For more details, check Reconcile and its Result here:
// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.6.4/pkg/reconcile
func (r *CStatesReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        var err error
        logger := r.Log.WithValues("cStates", req.NamespacedName)
        if req.Namespace != IntelPowerNamespace </span><span class="cov0" title="0">{
                err = fmt.Errorf("incorrect namespace")
                logger.Error(err, "resource is not in the power-manager namespace, ignoring")
                return ctrl.Result{Requeue: false}, err
        }</span>
        <span class="cov8" title="1">nodeName := os.Getenv("NODE_NAME")
        logger.Info("reconciling C-States")

        cStatesCRD := &amp;powerv1.CStates{}
        cStatesConfigRetrieveError := r.Client.Get(ctx, req.NamespacedName, cStatesCRD)
        if cStatesConfigRetrieveError != nil &amp;&amp; !errors.IsNotFound(cStatesConfigRetrieveError) </span><span class="cov0" title="0">{
                // if it's not found error we want to reset everything on the node which will happen anyway
                return ctrl.Result{}, cStatesConfigRetrieveError
        }</span>

        <span class="cov8" title="1">logger.V(3).Info("checking if the node exists in any C-States defined CRD...")
        err = r.verifyNodeExistsInCRD(ctx, cStatesCRD, &amp;logger)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "node &amp; CRD validation failed")
                _ = writeUpdatedStatusErrsIfRequired(ctx, r.Status(), cStatesCRD, err)
                return ctrl.Result{RequeueAfter: 30 * time.Second}, err
        }</span>
        // don't do anything else if we're not running on the node specified in the CRD Name
        <span class="cov8" title="1">logger.V(4).Info("checking if request is intended for this node")
        if req.Name != nodeName </span><span class="cov8" title="1">{
                return ctrl.Result{}, nil
        }</span>
        <span class="cov8" title="1">defer func() </span><span class="cov8" title="1">{ _ = writeUpdatedStatusErrsIfRequired(ctx, r.Status(), cStatesCRD, err) }</span>()

        <span class="cov8" title="1">logger.V(4).Info("checking to verify that C-States exist")
        err = r.verifyCSStatesExist(&amp;cStatesCRD.Spec, &amp;logger)
        if err != nil </span><span class="cov8" title="1">{
                logger.Info("the C-States validation failed", "error", err.Error())
                return ctrl.Result{}, err
        }</span>
        <span class="cov8" title="1">logger.V(4).Info("C-States validation successful")

        // prepare system by resetting configuration
        logger.V(4).Info("resetting C-States configuration")
        err = r.restoreCStates(ctx, &amp;logger)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "failed to restore C-States", "error", err.Error())
                return ctrl.Result{}, err
        }</span>
        <span class="cov8" title="1">logger.V(4).Info("C-States configuration successful")

        logger.V(4).Info("applying C-States to the CRD Spec")
        err = r.applyCStates(&amp;cStatesCRD.Spec, &amp;logger)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "setting C-States was partially successful")
                return ctrl.Result{Requeue: false}, err
        }</span>

        <span class="cov8" title="1">logger.Info("successfully applied all C-States config")
        return ctrl.Result{}, nil</span>
}

// SetupWithManager sets up the controller with the Manager.
func (r *CStatesReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov8" title="1">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.CStates{}).
                WithEventFilter(predicate.GenerationChangedPredicate{}).
                Complete(r)
}</span>

func (r *CStatesReconciler) verifyNodeExistsInCRD(ctx context.Context, cStatesCRD *powerv1.CStates, logger *logr.Logger) error <span class="cov8" title="1">{
        nodes := &amp;powerv1.PowerNodeList{}
        logger.V(5).Info("retrieving all nodes listed and checking names match CRDs")
        err := r.Client.List(ctx, nodes)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "failed to retrieve list of nodes")
                return err
        }</span>

        <span class="cov8" title="1">exists := false
        logger.V(5).Info("the C-States CRD names must match at least one node in the power node list and if true set the bool")
        for _, item := range nodes.Items </span><span class="cov8" title="1">{
                if item.Name == cStatesCRD.Name </span><span class="cov8" title="1">{
                        exists = true
                        break</span>
                }
        }
        <span class="cov8" title="1">if !exists </span><span class="cov8" title="1">{
                return errors.NewBadRequest("the C-States CRD name must match name of one of the power nodes")
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (r *CStatesReconciler) verifyCSStatesExist(cStatesSpec *powerv1.CStatesSpec, logger *logr.Logger) error <span class="cov8" title="1">{
        var errs = make([]error, 0)
        logger.V(5).Info("checking the power library to confirm that C-States are in the shared pool")
        errs = append(errs, r.PowerLibrary.ValidateCStates(cStatesSpec.SharedPoolCStates))

        for poolName, poolCStateList := range cStatesSpec.ExclusivePoolCStates </span><span class="cov8" title="1">{
                logger.V(5).Info("checking the power library to confirm that C-States are in the exclusive pool", "name", poolName)
                errs = append(errs, r.PowerLibrary.ValidateCStates(poolCStateList))
        }</span>
        <span class="cov8" title="1">for coreID, coreCStates := range cStatesSpec.IndividualCoreCStates </span><span class="cov8" title="1">{
                logger.V(5).Info("checking the power library to confirm that C-States are on individual cores", "coreID", coreID)
                errs = append(errs, r.PowerLibrary.ValidateCStates(coreCStates))
        }</span>
        <span class="cov8" title="1">return e.Join(errs...)</span>
}

func (r *CStatesReconciler) applyCStates(cStatesSpec *powerv1.CStatesSpec, logger *logr.Logger) error <span class="cov8" title="1">{
        var errs = make([]error, 0)
        // if the CRD is empty or we're handling a delete event this function will do nothing
        logger.V(5).Info("checking if the CRD is empty or we received a delete event")
        for core, cStatesMap := range cStatesSpec.IndividualCoreCStates </span><span class="cov8" title="1">{
                coreID, err := strconv.Atoi(core)
                if err != nil </span><span class="cov8" title="1">{
                        errs = append(errs, fmt.Errorf("%s must be an integer core ID", core))
                        continue</span>
                }
                <span class="cov8" title="1">logger.V(5).Info("applying C-States to cores", "coreID", coreID)
                coreObj := r.PowerLibrary.GetAllCpus().ByID(uint(coreID))
                if coreObj == nil </span><span class="cov8" title="1">{
                        // instead of erroring out, add the error to the list of errors and continue
                        errs = append(errs, fmt.Errorf("invalid core id ID: %d", coreID))
                        continue</span>
                }
                <span class="cov8" title="1">errs = append(errs, coreObj.SetCStates(cStatesMap))</span>
        }
        // exclusive pools
        <span class="cov8" title="1">for poolName, cStatesMap := range cStatesSpec.ExclusivePoolCStates </span><span class="cov8" title="1">{
                pool := r.PowerLibrary.GetExclusivePool(poolName)
                if pool == nil </span><span class="cov0" title="0">{
                        errs = append(errs, fmt.Errorf("pool with name %s does not exist", poolName))
                        continue</span>
                }
                <span class="cov8" title="1">errs = append(errs, pool.SetCStates(cStatesMap))

                logger.V(5).Info("applying C-States to exclusive pools", "name", poolName)</span>
        }
        // shared pool
        <span class="cov8" title="1">errs = append(errs, r.PowerLibrary.GetSharedPool().SetCStates(cStatesSpec.SharedPoolCStates))

        logger.V(5).Info("finished applying C-States to the shared pool")

        return e.Join(errs...)</span>
}

func (r *CStatesReconciler) restoreCStates(ctx context.Context, logger *logr.Logger) error <span class="cov8" title="1">{
        var errs = make([]error, 0)

        logger.V(5).Info("resetting to default state for the shared pool")
        errs = append(errs, r.PowerLibrary.GetSharedPool().SetCStates(nil))

        for _, pool := range *r.PowerLibrary.GetAllExclusivePools() </span><span class="cov8" title="1">{
                logger.V(5).Info("resetting C-States on pool", "name", pool.Name())
                errs = append(errs, pool.SetCStates(nil))
        }</span>

        <span class="cov8" title="1">logger.V(5).Info("resetting C-States on each core")
        allCPUs := *r.PowerLibrary.GetAllCpus()
        for _, core := range allCPUs </span><span class="cov8" title="1">{
                errs = append(errs, core.SetCStates(nil))
        }</span>
        <span class="cov8" title="1">return e.Join(errs...)</span>
}
</pre>
		
		<pre class="file" id="file19" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        "fmt"
        "os"
        "reflect"
        "strings"
        "time"

        "github.com/go-logr/logr"
        "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/runtime"
        "k8s.io/client-go/kubernetes/scheme"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        appsv1 "k8s.io/api/apps/v1"
        corev1 "k8s.io/api/core/v1"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"

        "github.com/intel/kubernetes-power-manager/pkg/state"
        "github.com/intel/kubernetes-power-manager/pkg/util"
)

const (
        ExtendedResourcePrefix = "power.intel.com/"
        NodeAgentDSName        = "power-node-agent"
        IntelPowerNamespace    = "power-manager"
)

var NodeAgentDaemonSetPath = "/power-manifests/power-node-agent-ds.yaml"

// PowerConfigReconciler reconciles a PowerConfig object
type PowerConfigReconciler struct {
        client.Client
        Log    logr.Logger
        Scheme *runtime.Scheme
        State  *state.PowerNodeData
}

// +kubebuilder:rbac:groups=power.intel.com,resources=powerconfigs,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=power.intel.com,resources=powerconfigs/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=security.openshift.io,resources=securitycontextconstraints,resourceNames=privileged,verbs=use

func (r *PowerConfigReconciler) Reconcile(c context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        _ = context.Background()
        logger := r.Log.WithValues("powerconfig", req.NamespacedName)

        if req.Namespace != IntelPowerNamespace </span><span class="cov0" title="0">{
                err := fmt.Errorf("incorrect namespace")
                logger.Error(err, "resource is not in the power-manager namespace, ignoring")
                return ctrl.Result{Requeue: false}, err
        }</span>

        <span class="cov8" title="1">configs := &amp;powerv1.PowerConfigList{}
        logger.V(5).Info("retrieving the power config list")
        err := r.Client.List(c, configs)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "error retrieving the power config list")
                return ctrl.Result{}, err
        }</span>

        <span class="cov8" title="1">config := &amp;powerv1.PowerConfig{}
        logger.V(5).Info("retrieving the power config")
        err = r.Client.Get(c, req.NamespacedName, config)
        if err != nil </span><span class="cov8" title="1">{
                logger.V(5).Info("failed retrieving the power config, checking if exists")
                if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                        // Power config was deleted, if the number of power configs is &gt; 0, don't delete the power profiles
                        if len(configs.Items) == 0 </span><span class="cov8" title="1">{
                                powerProfiles := &amp;powerv1.PowerProfileList{}
                                err = r.Client.List(c, powerProfiles)
                                logger.V(5).Info("retrieving all power profiles in the cluster")
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "error retrieving the power profiles")
                                        return ctrl.Result{}, err
                                }</span>

                                <span class="cov8" title="1">for _, profile := range powerProfiles.Items </span><span class="cov8" title="1">{
                                        err = r.Client.Delete(c, &amp;profile)
                                        logger.V(5).Info(fmt.Sprintf("deleting power profile %s", profile.Name))
                                        if err != nil </span><span class="cov0" title="0">{
                                                logger.Error(err, fmt.Sprintf("error deleting power profile '%s' from cluster", profile.Name))
                                                return ctrl.Result{}, err
                                        }</span>
                                }

                                // Make sure all power workloads have been removed
                                <span class="cov8" title="1">powerWorkloads := &amp;powerv1.PowerWorkloadList{}
                                err = r.Client.List(c, powerWorkloads)
                                logger.V(5).Info("retrieving all power workloads in the cluster")
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "error retrieving the power workloads")
                                        return ctrl.Result{}, err
                                }</span>

                                <span class="cov8" title="1">for _, workload := range powerWorkloads.Items </span><span class="cov8" title="1">{
                                        logger.V(5).Info(fmt.Sprintf("deleting power workload %s", workload.Name))
                                        err = r.Client.Delete(c, &amp;workload)
                                        if err != nil </span><span class="cov0" title="0">{
                                                logger.Error(err, fmt.Sprintf("error deleting power workload '%s' from cluster", workload.Name))
                                                return ctrl.Result{}, err
                                        }</span>
                                }

                                <span class="cov8" title="1">powerNodes := &amp;powerv1.PowerNodeList{}
                                err = r.Client.List(c, powerNodes)
                                logger.V(5).Info("retrieving all power nodes in the cluster")
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "error retrieving power nodes")
                                        return ctrl.Result{}, err
                                }</span>

                                <span class="cov8" title="1">for _, node := range powerNodes.Items </span><span class="cov8" title="1">{
                                        logger.V(5).Info(fmt.Sprintf("deleting power nodes %s", node.Name))
                                        err = r.Client.Delete(c, &amp;node)
                                        if err != nil </span><span class="cov0" title="0">{
                                                logger.Error(err, fmt.Sprintf("error deleting power node '%s' from cluster", node.Name))
                                                return ctrl.Result{}, err
                                        }</span>
                                }

                                <span class="cov8" title="1">daemonSet := &amp;appsv1.DaemonSet{}
                                logger.V(5).Info("retrieving the power node-agent daemonSet")
                                err = r.Client.Get(c, client.ObjectKey{
                                        Name:      NodeAgentDSName,
                                        Namespace: IntelPowerNamespace,
                                }, daemonSet)
                                if err != nil </span><span class="cov0" title="0">{
                                        if !errors.IsNotFound(err) </span><span class="cov0" title="0">{
                                                logger.Error(err, "error retrieving the power node-agent daemonSet")
                                                return ctrl.Result{}, err
                                        }</span>
                                } else<span class="cov8" title="1"> {
                                        err = r.Client.Delete(c, daemonSet)
                                        if err != nil </span><span class="cov0" title="0">{
                                                logger.Error(err, "error deleting the power node-agent daemonset")
                                                return ctrl.Result{}, err
                                        }</span>
                                }
                        }

                        <span class="cov8" title="1">return ctrl.Result{}, nil</span>
                }

                <span class="cov0" title="0">logger.Error(err, "error retrieving the power config")
                return ctrl.Result{}, err</span>
        }

        <span class="cov8" title="1">if len(configs.Items) &gt; 1 </span><span class="cov8" title="1">{
                logger.V(5).Info("checking to make sure there is only one power config")
                moreThanOneConfigError := errors.NewServiceUnavailable("cannot have more than one power config")
                logger.Error(moreThanOneConfigError, "error reconciling the power config")

                err = r.Client.Delete(c, config)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "error deleting the power config")
                        return ctrl.Result{}, err
                }</span>

                <span class="cov8" title="1">return ctrl.Result{}, nil</span>
        }

        // Create power node-agent daemonSet
        <span class="cov8" title="1">logger.V(5).Info("creating the power node-agent daemonSet")
        err = r.createDaemonSetIfNotPresent(c, config, NodeAgentDaemonSetPath, &amp;logger)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "error creating the power node-agent")
                return ctrl.Result{}, err
        }</span>

        <span class="cov8" title="1">labelledNodeList := &amp;corev1.NodeList{}
        listOption := config.Spec.PowerNodeSelector

        // Searching for Custom Devices in PowerConfig
        customDevices := config.Spec.CustomDevices
        if len(customDevices) &gt; 0 </span><span class="cov8" title="1">{
                logger.V(5).Info("the behaviour of the power node agent will be affected by the following devices.",
                        "Custom Devices", customDevices)
        }</span>

        <span class="cov8" title="1">logger.V(5).Info("confirming desired nodes match the power node selector")
        err = r.Client.List(c, labelledNodeList, client.MatchingLabels(listOption))
        if err != nil </span><span class="cov0" title="0">{
                logger.Info("failed to list nodes with power node selector", listOption)
                return ctrl.Result{}, err
        }</span>

        <span class="cov8" title="1">for _, node := range labelledNodeList.Items </span><span class="cov8" title="1">{
                logger.V(5).Info("updating the node name")
                r.State.UpdatePowerNodeData(node.Name)

                powerNode := &amp;powerv1.PowerNode{}
                err = r.Client.Get(c, client.ObjectKey{
                        Namespace: IntelPowerNamespace,
                        Name:      node.Name,
                }, powerNode)

                logger.V(5).Info(fmt.Sprintf("creating the power node CRD %s", node.Name))
                if err != nil </span><span class="cov8" title="1">{
                        if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                                powerNode = &amp;powerv1.PowerNode{
                                        ObjectMeta: metav1.ObjectMeta{
                                                Namespace: IntelPowerNamespace,
                                                Name:      node.Name,
                                        },
                                }

                                powerNodeSpec := &amp;powerv1.PowerNodeSpec{
                                        NodeName:      node.Name,
                                        CustomDevices: customDevices,
                                }

                                powerNode.Spec = *powerNodeSpec
                                err = r.Client.Create(c, powerNode)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "error creating the power node CRD")
                                        return ctrl.Result{}, err
                                }</span>
                        } else<span class="cov0" title="0"> {
                                return ctrl.Result{}, err
                        }</span>
                }

                <span class="cov8" title="1">patch := client.MergeFrom(powerNode.DeepCopy())
                powerNode.Spec.CustomDevices = customDevices
                err = r.Client.Patch(c, powerNode, patch)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "failed to update power node with custom devices.")
                        return ctrl.Result{}, err
                }</span>
        }

        <span class="cov8" title="1">patch := client.MergeFrom(config.DeepCopy())
        config.Status.Nodes = r.State.PowerNodeList
        config.Spec.CustomDevices = customDevices
        err = r.Client.Status().Patch(c, config, patch)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "failed to update the power config")
                return ctrl.Result{}, err
        }</span>

        // Create the power profiles that were requested in the power config if it doesn't exist
        // Delete any power profiles that are not being requested but exist
        <span class="cov8" title="1">for _, profile := range config.Spec.PowerProfiles </span><span class="cov8" title="1">{
                logger.V(5).Info(fmt.Sprintf("checking if the power profile exists %s", profile))
                profileFromCluster := &amp;powerv1.PowerProfile{}
                err = r.Client.Get(c, client.ObjectKey{
                        Name:      profile,
                        Namespace: IntelPowerNamespace,
                }, profileFromCluster)
                if err != nil </span><span class="cov8" title="1">{
                        if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                                // Power profile does not exist, so we need to create it
                                logger.V(5).Info(fmt.Sprintf("creating power profile %s", profile))
                                epp := strings.Replace(profile, "-", "_", 1)
                                powerProfileSpec := &amp;powerv1.PowerProfileSpec{
                                        Name: profile,
                                        Epp:  epp,
                                }
                                powerProfile := &amp;powerv1.PowerProfile{
                                        ObjectMeta: metav1.ObjectMeta{
                                                Namespace: IntelPowerNamespace,
                                                Name:      profile,
                                        },
                                }
                                powerProfile.Spec = *powerProfileSpec
                                err = r.Client.Create(c, powerProfile)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, fmt.Sprintf("error creating power profile '%s'", profile))
                                        return ctrl.Result{}, err
                                }</span>
                        } else<span class="cov0" title="0"> {
                                logger.Error(err, fmt.Sprintf("error retrieving power profile '%s'", profile))
                                return ctrl.Result{}, err
                        }</span>
                }

                // If the power profile/workload was successfull retrieved, we don't need to do anything
        }

        <span class="cov8" title="1">powerProfiles := &amp;powerv1.PowerProfileList{}
        logger.V(5).Info("retrieving the list of power profiles")
        err = r.Client.List(c, powerProfiles)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "error retrieving the power profile list")
                return ctrl.Result{}, err
        }</span>

        // Check power profiles for any that are no longer requested; only check base profiles
        <span class="cov8" title="1">for _, profile := range powerProfiles.Items </span><span class="cov8" title="1">{
                logger.V(5).Info("checking if the power profile exists and is not requested")
                convertedName := strings.Replace(profile.Spec.Name, "-", "_", 1)
                if _, exists := profilePercentages[convertedName]; exists </span><span class="cov8" title="1">{
                        if !util.StringInStringList(profile.Spec.Name, config.Spec.PowerProfiles) </span><span class="cov8" title="1">{
                                err = r.Client.Delete(c, &amp;profile)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, fmt.Sprintf("error deleting power profile '%s'", profile.Spec.Name))
                                        return ctrl.Result{}, err
                                }</span>
                        }
                }
        }

        <span class="cov8" title="1">return ctrl.Result{RequeueAfter: time.Second * 5}, nil</span>
}

func (r *PowerConfigReconciler) createDaemonSetIfNotPresent(c context.Context, powerConfig *powerv1.PowerConfig, path string, logger *logr.Logger) error <span class="cov8" title="1">{
        logger.V(5).Info("creating the daemonSet")

        daemonSet := &amp;appsv1.DaemonSet{}
        var err error

        err = r.Client.Get(c, client.ObjectKey{
                Name:      NodeAgentDSName,
                Namespace: IntelPowerNamespace,
        }, daemonSet)
        if err != nil </span><span class="cov8" title="1">{
                if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                        daemonSet, err = createDaemonSetFromManifest(path)
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "error creating the daemonSet")
                                return err
                        }</span>
                        <span class="cov8" title="1">if len(powerConfig.Spec.PowerNodeSelector) != 0 </span><span class="cov8" title="1">{
                                daemonSet.Spec.Template.Spec.NodeSelector = powerConfig.Spec.PowerNodeSelector
                        }</span>
                        <span class="cov8" title="1">err = r.Client.Create(c, daemonSet)
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "error creating the daemonSet")
                                return err
                        }</span>
                        <span class="cov8" title="1">logger.V(5).Info("new power node-agent daemonSet created")
                        return nil</span>
                }
        }

        // If the daemonSet already exists and is different than the selected nodes, update it
        <span class="cov8" title="1">if !reflect.DeepEqual(daemonSet.Spec.Template.Spec.NodeSelector, powerConfig.Spec.PowerNodeSelector) </span><span class="cov0" title="0">{
                logger.V(5).Info("updating the existing daemonSet")
                daemonSet.Spec.Template.Spec.NodeSelector = powerConfig.Spec.PowerNodeSelector
                err = r.Client.Update(c, daemonSet)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "error updating the power node-agent daemonSet")
                        return err
                }</span>
        }

        <span class="cov8" title="1">return nil</span>
}

func createDaemonSetFromManifest(path string) (*appsv1.DaemonSet, error) <span class="cov8" title="1">{
        yamlFile, err := os.ReadFile(path)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">decode := scheme.Codecs.UniversalDeserializer().Decode
        obj, _, err := decode(yamlFile, nil, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">nodeAgentDaemonSet := obj.(*appsv1.DaemonSet)
        return nodeAgentDaemonSet, nil</span>
}

func (r *PowerConfigReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov8" title="1">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.PowerConfig{}).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file20" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        "fmt"
        "os"
        "sort"
        "strconv"
        "strings"
        "time"

        "github.com/go-logr/logr"
        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/runtime"
        "k8s.io/apimachinery/pkg/types"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/predicate"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/kubernetes-power-manager/pkg/podstate"
        "github.com/intel/power-optimization-library/pkg/power"
)

const queuetime = time.Second * 5

// PowerNodeReconciler reconciles a PowerNode object
type PowerNodeReconciler struct {
        client.Client
        Log          logr.Logger
        Scheme       *runtime.Scheme
        State        *podstate.State
        OrphanedPods map[string]corev1.Pod
        PowerLibrary power.Host
}

// +kubebuilder:rbac:groups=power.intel.com,resources=powernodes,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=power.intel.com,resources=powernodes/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=security.openshift.io,resources=securitycontextconstraints,resourceNames=privileged,verbs=use

func (r *PowerNodeReconciler) Reconcile(c context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        _ = context.Background()

        logger := r.Log.WithValues("powernode", req.NamespacedName)
        logger.V(5).Info("checking if power node and node name match")
        nodeName := os.Getenv("NODE_NAME")
        if nodeName != req.NamespacedName.Name </span><span class="cov0" title="0">{
                // power node is not on this node
                return ctrl.Result{}, nil
        }</span>

        <span class="cov8" title="1">powerProfileStrings := make([]string, 0)
        powerWorkloadStrings := make([]string, 0)
        powerContainers := make([]powerv1.Container, 0)

        powerNode := &amp;powerv1.PowerNode{}
        logger.V(5).Info("retrieving the power node instance")
        err := r.Client.Get(context.TODO(), req.NamespacedName, powerNode)
        if err != nil </span><span class="cov8" title="1">{
                if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                        logger.V(5).Info("power node not found, requeueing")
                        return ctrl.Result{RequeueAfter: queuetime}, nil
                }</span>
                <span class="cov8" title="1">return ctrl.Result{RequeueAfter: queuetime}, err</span>
        }

        <span class="cov8" title="1">if len(powerNode.Spec.CustomDevices) &gt; 0 </span><span class="cov8" title="1">{
                logger.V(5).Info("the power node contains the following custom devices.", "Custom Devices", powerNode.Spec.CustomDevices)
        }</span>

        <span class="cov8" title="1">powerProfiles := &amp;powerv1.PowerProfileList{}
        logger.V(5).Info("retrieving the power profile list")
        err = r.Client.List(context.TODO(), powerProfiles)
        if err != nil </span><span class="cov8" title="1">{
                if errors.IsNotFound(err) </span><span class="cov0" title="0">{
                        return ctrl.Result{RequeueAfter: queuetime}, nil
                }</span>

                <span class="cov8" title="1">return ctrl.Result{RequeueAfter: queuetime}, err</span>
        }

        <span class="cov8" title="1">for _, profile := range powerProfiles.Items </span><span class="cov8" title="1">{
                logger.V(5).Info("retrieving profile information from the power library")
                pool := r.PowerLibrary.GetExclusivePool(profile.Spec.Name)
                if pool == nil </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">profileFromLibrary := pool.GetPowerProfile()
                if profileFromLibrary == nil </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov8" title="1">profileString := fmt.Sprintf("%s: %v || %v || %s", profileFromLibrary.Name(), profileFromLibrary.MaxFreq(), profileFromLibrary.MinFreq(), profileFromLibrary.Epp())
                powerProfileStrings = append(powerProfileStrings, profileString)</span>
        }

        <span class="cov8" title="1">powerWorkloads := &amp;powerv1.PowerWorkloadList{}
        logger.V(5).Info("retrieving the power workload list")
        err = r.Client.List(context.TODO(), powerWorkloads)
        if err != nil </span><span class="cov0" title="0">{
                if errors.IsNotFound(err) </span><span class="cov0" title="0">{
                        return ctrl.Result{RequeueAfter: queuetime}, nil
                }</span>

                <span class="cov0" title="0">return ctrl.Result{RequeueAfter: queuetime}, err</span>
        }

        <span class="cov8" title="1">for _, workload := range powerWorkloads.Items </span><span class="cov8" title="1">{
                logger.V(5).Info("checking if the workload is shared or on the wrong node")
                if workload.Spec.AllCores || workload.Spec.Node.Name != nodeName </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">poolFromLibrary := r.PowerLibrary.GetExclusivePool(workload.Spec.PowerProfile)
                logger.V(5).Info("retrieving the workload information from the power library")
                if poolFromLibrary == nil </span><span class="cov8" title="1">{
                        continue</span>
                }
                // checks for pods that aren't in the pool they should be
                <span class="cov8" title="1">if r.PowerLibrary.GetSharedPool().GetPowerProfile() != nil </span><span class="cov8" title="1">{
                        for _, guaranteedPod := range r.State.GuaranteedPods </span><span class="cov8" title="1">{
                                if err = r.itterPods(nodeName, workload, poolFromLibrary, guaranteedPod, logger); err != nil </span><span class="cov8" title="1">{
                                        // erroring out here risks a loop but in that scenario something is seriously wrong with k8s
                                        // or the managers' internal state
                                        return ctrl.Result{RequeueAfter: queuetime}, err
                                }</span>
                        }
                }
                <span class="cov8" title="1">logger.V(5).Info("retrieving the power profile information for workload")
                cores := prettifyCoreList(poolFromLibrary.Cpus().IDs())
                profile := poolFromLibrary.GetPowerProfile()
                workloadString := fmt.Sprintf("%s: %s || %s", poolFromLibrary.Name(), profile.Name(), cores)
                powerWorkloadStrings = append(powerWorkloadStrings, workloadString)

                for _, container := range workload.Spec.Node.Containers </span><span class="cov8" title="1">{
                        logger.V(5).Info("configuring the power container information")
                        container.Workload = workload.Name
                        powerContainers = append(powerContainers, container)
                }</span>
        }

        <span class="cov8" title="1">logger.V(5).Info("setting the power node spec - profiles, workloads, containers")
        powerNode.Spec.PowerProfiles = powerProfileStrings
        powerNode.Spec.PowerWorkloads = powerWorkloadStrings
        powerNode.Spec.PowerContainers = powerContainers

        logger.V(5).Info("setting the shared pool, shared cores, shared profiles and reserved system CPUs")
        sharedPool := r.PowerLibrary.GetSharedPool()
        sharedCores := sharedPool.Cpus().IDs()
        sharedProfile := sharedPool.GetPowerProfile()
        reservedSystemCpus := r.PowerLibrary.GetReservedPool().Cpus().IDs()

        logger.V(5).Info("configurating the cores to the shared pool")
        powerNode.Spec.PowerContainers = powerContainers
        if len(sharedCores) &gt; 0 &amp;&amp; sharedProfile != nil </span><span class="cov8" title="1">{
                cores := prettifyCoreList(sharedCores)
                powerNode.Spec.SharedPool = fmt.Sprintf("%s || %v || %v || %s", sharedProfile.Name(), sharedProfile.MaxFreq(), sharedProfile.MinFreq(), cores)
        }</span> else<span class="cov8" title="1"> {
                powerNode.Spec.SharedPool = ""
        }</span>
        // look for any special reserved pools
        <span class="cov8" title="1">pools := r.PowerLibrary.GetAllExclusivePools()
        powerNode.Spec.ReservedPools = []string{}
        for _, pool := range *pools </span><span class="cov8" title="1">{
                if strings.Contains(pool.Name(), nodeName+"-reserved-") </span><span class="cov0" title="0">{
                        cores := prettifyCoreList(pool.Cpus().IDs())
                        powerNode.Spec.ReservedPools = append(powerNode.Spec.ReservedPools, fmt.Sprintf("%v || %v || %s", pool.GetPowerProfile().MaxFreq(), pool.GetPowerProfile().MinFreq(), cores))
                }</span>
        }
        <span class="cov8" title="1">logger.V(5).Info("configurating the cores to the reserved pool")
        cores := prettifyCoreList(reservedSystemCpus)
        powerNode.Spec.UnaffectedCores = cores
        err = r.Client.Update(context.TODO(), powerNode)
        if err != nil </span><span class="cov8" title="1">{
                return ctrl.Result{RequeueAfter: queuetime}, err
        }</span>

        <span class="cov8" title="1">return ctrl.Result{RequeueAfter: queuetime}, nil</span>
}

func prettifyCoreList(cores []uint) string <span class="cov8" title="1">{
        prettified := ""
        sort.Slice(cores, func(i, j int) bool </span><span class="cov8" title="1">{ return cores[i] &lt; cores[j] }</span>)
        <span class="cov8" title="1">for i := 0; i &lt; len(cores); i++ </span><span class="cov8" title="1">{
                start := i
                end := i

                for end &lt; len(cores)-1 </span><span class="cov8" title="1">{
                        if cores[end+1]-cores[end] == 1 </span><span class="cov8" title="1">{
                                end++
                        }</span> else<span class="cov8" title="1"> {
                                break</span>
                        }
                }

                <span class="cov8" title="1">if end-start &gt; 0 </span><span class="cov8" title="1">{
                        prettified += fmt.Sprintf("%d-%d", cores[start], cores[end])
                }</span> else<span class="cov8" title="1"> {
                        prettified += fmt.Sprintf("%d", cores[start])
                }</span>

                <span class="cov8" title="1">if end &lt; len(cores)-1 </span><span class="cov8" title="1">{
                        prettified += ","
                }</span>

                <span class="cov8" title="1">i = end</span>
        }

        <span class="cov8" title="1">return prettified</span>
}

func (r *PowerNodeReconciler) itterPods(nodeName string, workload powerv1.PowerWorkload, poolFromLibrary power.Pool, guaranteedPod powerv1.GuaranteedPod, logger logr.Logger) error <span class="cov8" title="1">{
        pod := &amp;corev1.Pod{}
        for _, container := range guaranteedPod.Containers </span><span class="cov8" title="1">{
                if workload.Name == (container.PowerProfile + "-" + nodeName) </span><span class="cov8" title="1">{
                        for _, core := range container.ExclusiveCPUs </span><span class="cov8" title="1">{
                                if !validateCoreIsInCoreList(core, poolFromLibrary.Cpus().IDs()) </span><span class="cov8" title="1">{
                                        if err := r.Client.Get(context.TODO(), types.NamespacedName{Namespace: guaranteedPod.Namespace, Name: guaranteedPod.Name}, pod); err != nil </span><span class="cov8" title="1">{
                                                logger.Error(err, "could not retrieve the pod")
                                                return err
                                        }</span>
                                        <span class="cov8" title="1">if !pod.ObjectMeta.DeletionTimestamp.IsZero() || pod.Status.Phase == corev1.PodSucceeded </span><span class="cov0" title="0">{
                                                break</span>
                                        }
                                        // this annotation is used to force a reconcile on the pod
                                        <span class="cov8" title="1">timestamp, exists := r.OrphanedPods[pod.Name].ObjectMeta.Annotations["PM-updated"]
                                        if exists </span><span class="cov8" title="1">{
                                                if t, err := strconv.ParseInt(timestamp, 10, 64); err == nil </span><span class="cov8" title="1">{
                                                        // gives 20 seconds to ensure pod is not moving from one pool to another
                                                        if (time.Now().Unix() - int64(t)) &gt; 20 </span><span class="cov8" title="1">{
                                                                logger.V(5).Info(fmt.Sprintf("pod %s found with cores in the wrong pool, updating the pod", guaranteedPod.Name))
                                                                pod.ObjectMeta.Annotations["PM-updated"] = fmt.Sprint(time.Now().Unix())
                                                                err := r.Client.Update(context.TODO(), pod)
                                                                if err != nil </span><span class="cov8" title="1">{
                                                                        logger.Error(err, "could not update the pod")
                                                                        return err
                                                                }</span>
                                                                // update success so remove from map
                                                                <span class="cov0" title="0">delete(r.OrphanedPods, pod.Name)</span>
                                                        }
                                                } else<span class="cov0" title="0"> {
                                                        logger.Error(err, fmt.Sprintf("error parsing PM-updated annotation in pod %s", guaranteedPod.Name))
                                                        delete(r.OrphanedPods, pod.Name)
                                                }</span>
                                        } else<span class="cov8" title="1"> {
                                                pod.ObjectMeta.Annotations["PM-updated"] = fmt.Sprint(time.Now().Unix())
                                                r.OrphanedPods[pod.Name] = *pod
                                        }</span>
                                        // we've found a problem pod so forego itterating other cores
                                        <span class="cov8" title="1">return nil</span>
                                }
                        }
                }
        }
        <span class="cov0" title="0">return nil</span>
}

func (r *PowerNodeReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov8" title="1">{
        pred := predicate.LabelChangedPredicate{}
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.PowerNode{}).
                WithEventFilter(pred).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file21" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        "fmt"
        "os"
        "reflect"
        "sort"
        "strconv"
        "strings"

        e "errors"

        "github.com/go-logr/logr"
        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"

        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/runtime"
        podresourcesapi "k8s.io/kubelet/pkg/apis/podresources/v1"

        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"

        "github.com/intel/kubernetes-power-manager/pkg/podresourcesclient"
        "github.com/intel/kubernetes-power-manager/pkg/podstate"
        "github.com/intel/kubernetes-power-manager/pkg/util"
)

const (
        PowerProfileAnnotation = "PowerProfile"
        ResourcePrefix         = "power.intel.com/"
        CPUResource            = "cpu"
        PowerNamespace         = "power-manager"
)

// PowerPodReconciler reconciles a PowerPod object
type PowerPodReconciler struct {
        client.Client
        Log                logr.Logger
        Scheme             *runtime.Scheme
        State              *podstate.State
        PodResourcesClient podresourcesclient.PodResourcesClient
}

// +kubebuilder:rbac:groups=power.intel.com,resources=powerpods,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=power.intel.com,resources=powerpods/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=security.openshift.io,resources=securitycontextconstraints,resourceNames=privileged,verbs=use

func (r *PowerPodReconciler) Reconcile(c context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        _ = context.Background()
        logger := r.Log.WithValues("powerpod", req.NamespacedName)
        pod := &amp;corev1.Pod{}
        logger.V(5).Info("retrieving pod instance")
        err := r.Get(context.TODO(), req.NamespacedName, pod)
        if err != nil </span><span class="cov8" title="1">{
                if errors.IsNotFound(err) </span><span class="cov0" title="0">{
                        // Delete the Pod from the internal state in case it was never deleted
                        // aAdded the check due to golangcilint errcheck
                        _ = r.State.DeletePodFromState(req.NamespacedName.Name, req.NamespacedName.Namespace)
                        return ctrl.Result{}, nil
                }</span>

                <span class="cov8" title="1">logger.Error(err, "error while trying to retrieve the pod")
                return ctrl.Result{}, err</span>
        }
        // First thing to check is if this pod is on the same node as the node agent that intercepted it
        // The NODE_NAME environment variable is passed in via the downwards API in the pod spec
        <span class="cov8" title="1">logger.V(5).Info("confirming the pod is on the same node as the power node-agent")
        nodeName := os.Getenv("NODE_NAME")
        if pod.Spec.NodeName != nodeName </span><span class="cov8" title="1">{
                return ctrl.Result{}, nil
        }</span>
        <span class="cov8" title="1">if pod.ObjectMeta.Namespace == "kube-system" </span><span class="cov8" title="1">{
                return ctrl.Result{}, nil
        }</span>

        <span class="cov8" title="1">if !pod.ObjectMeta.DeletionTimestamp.IsZero() || pod.Status.Phase == corev1.PodSucceeded </span><span class="cov8" title="1">{
                // If the pod's deletion timestamp is not zero, then the pod has been deleted

                powerPodState := r.State.GetPodFromState(pod.GetName(), pod.GetNamespace())

                logger.V(5).Info("removing the pod from the internal state")
                _ = r.State.DeletePodFromState(pod.GetName(), pod.GetNamespace())
                workloadToCPUsRemoved := make(map[string][]uint)

                logger.V(5).Info("removing pods CPUs from the internal state")
                for _, container := range powerPodState.Containers </span><span class="cov8" title="1">{
                        workload := container.Workload
                        cpus := container.ExclusiveCPUs
                        logger.V(5).Info("Removing", "Workload", workload, "CPUs", cpus)
                        if _, exists := workloadToCPUsRemoved[workload]; exists </span><span class="cov0" title="0">{
                                workloadToCPUsRemoved[workload] = append(workloadToCPUsRemoved[workload], cpus...)
                        }</span> else<span class="cov8" title="1"> {
                                workloadToCPUsRemoved[workload] = cpus
                        }</span>
                }
                <span class="cov8" title="1">for workloadName, cpus := range workloadToCPUsRemoved </span><span class="cov8" title="1">{
                        logger.V(5).Info("retrieving the workload instance", "Workload Name", workloadName)
                        workload := &amp;powerv1.PowerWorkload{}
                        err = r.Get(context.TODO(), client.ObjectKey{
                                Namespace: IntelPowerNamespace,
                                Name:      workloadName,
                        }, workload)
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "error while trying to retrieve the power workload")
                                if errors.IsNotFound(err) </span><span class="cov0" title="0">{
                                        return ctrl.Result{Requeue: false}, err
                                }</span>
                                <span class="cov0" title="0">return ctrl.Result{}, err</span>
                        }

                        <span class="cov8" title="1">logger.V(5).Info("updating CPUs workload list with their CPU IDs and the container information")
                        updatedWorkloadCPUList := getNewWorkloadCPUList(cpus, workload.Spec.Node.CpuIds, &amp;logger)
                        workload.Spec.Node.CpuIds = updatedWorkloadCPUList
                        updatedWorkloadContainerList := getNewWorkloadContainerList(workload.Spec.Node.Containers, powerPodState.Containers, &amp;logger)
                        workload.Spec.Node.Containers = updatedWorkloadContainerList

                        err = r.Client.Update(context.TODO(), workload)
                        if err != nil </span><span class="cov8" title="1">{
                                logger.Error(err, "failed to update the power workload")
                                return ctrl.Result{}, err
                        }</span>
                }

                <span class="cov8" title="1">return ctrl.Result{}, nil</span>
        }

        // If the pod's deletion timestamp is equal to zero, then the pod has been created or updated

        // Make sure the pod is running
        <span class="cov8" title="1">logger.V(5).Info("confirming the pod is in a running state")
        podNotRunningErr := errors.NewServiceUnavailable("the pod is not in the running phase")
        if pod.Status.Phase != corev1.PodRunning </span><span class="cov8" title="1">{
                return ctrl.Result{}, podNotRunningErr
        }</span>

        // Get customDevices that need to be considered in the pod
        <span class="cov8" title="1">logger.V(5).Info("retrieving custom resources from power node")
        powernode := &amp;powerv1.PowerNode{}
        err = r.Get(context.TODO(), client.ObjectKey{
                Namespace: IntelPowerNamespace,
                Name:      nodeName,
        }, powernode)
        if err != nil </span><span class="cov8" title="1">{
                if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                        return ctrl.Result{}, nil
                }</span>
                <span class="cov8" title="1">logger.Error(err, "error while trying to retrieve the power node")
                return ctrl.Result{}, err</span>
        }

        // Get the Containers of the Pod that are requesting exclusive CPUs or custom devices
        <span class="cov8" title="1">logger.V(5).Info("retrieving the containers requested for the exclusive CPUs or Custom Resources", "Custom Resources", powernode.Spec.CustomDevices)
        admissibleContainers := getAdmissibleContainers(pod, powernode.Spec.CustomDevices, r.PodResourcesClient, &amp;logger)
        if len(admissibleContainers) == 0 </span><span class="cov0" title="0">{
                logger.Info("no containers are requesting exclusive CPUs or Custom Resources")
                return ctrl.Result{}, nil
        }</span>
        <span class="cov8" title="1">podUID := pod.GetUID()
        logger.V(5).Info("retrieving the podUID", "UID", podUID)
        if podUID == "" </span><span class="cov8" title="1">{
                logger.Info("no pod UID found")
                return ctrl.Result{}, errors.NewServiceUnavailable("pod UID not found")
        }</span>

        <span class="cov8" title="1">powerProfileCRs := &amp;powerv1.PowerProfileList{}
        logger.V(5).Info("retrieving the power profiles from the cluster")
        if err = r.Client.List(context.TODO(), powerProfileCRs); err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "error retrieving the power profiles from the cluster")
                return ctrl.Result{}, err
        }</span>
        <span class="cov8" title="1">powerProfilesFromContainers, powerContainers, recoveryErrs := r.getPowerProfileRequestsFromContainers(admissibleContainers, powerProfileCRs.Items, powernode.Spec.CustomDevices, pod, &amp;logger)
        logger.V(5).Info("retrieving the power profiles and cores from the pod requests")
        for profile, cores := range powerProfilesFromContainers </span><span class="cov8" title="1">{
                logger.V(5).Info("retrieving the workload for the power profile")
                workloadName := fmt.Sprintf("%s-%s", profile, nodeName)
                workload := &amp;powerv1.PowerWorkload{}
                err = r.Client.Get(context.TODO(), client.ObjectKey{
                        Namespace: PowerNamespace,
                        Name:      workloadName,
                }, workload)
                if err != nil </span><span class="cov8" title="1">{
                        if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                                logger.Error(err, "no power workload exists for this profile")
                        }</span> else<span class="cov0" title="0"> {
                                logger.Error(err, fmt.Sprintf("error retrieving the power workload '%s'", profile))
                        }</span>
                        <span class="cov8" title="1">recoveryErrs = append(recoveryErrs, err)
                        continue</span>
                }

                // Power workload already exists so need to update it. If the node already
                // exists in the workload, we update the node's CPU list, if not we create
                // the entry for the node

                <span class="cov8" title="1">workload.Spec.Node.CpuIds = appendIfUnique(workload.Spec.Node.CpuIds, cores)
                sort.Slice(workload.Spec.Node.CpuIds, func(i, j int) bool </span><span class="cov8" title="1">{ return workload.Spec.Node.CpuIds[i] &lt; workload.Spec.Node.CpuIds[j] }</span>)
                <span class="cov8" title="1">containerList := make([]powerv1.Container, 0)
                for i, container := range powerContainers </span><span class="cov8" title="1">{
                        if container.PowerProfile == workload.Spec.PowerProfile </span><span class="cov8" title="1">{
                                logger.V(5).Info("updating the power container list")
                                powerContainers[i].Workload = workloadName
                                workloadContainer := container
                                workloadContainer.Pod = pod.Name
                                workloadContainer.PodUID = podUID
                                workloadContainer.Namespace = pod.Namespace
                                workloadContainer.Workload = workloadName
                                containerList = append(containerList, workloadContainer)
                        }</span>
                }
                <span class="cov8" title="1">var newContainerList []powerv1.Container
                for _, newContainer := range containerList </span><span class="cov8" title="1">{
                        duplicate := false
                        logger.V(5).Info("confirming the containers are not duplicated")
                        for _, oldContainer := range workload.Spec.Node.Containers </span><span class="cov8" title="1">{
                                if newContainer.Id == oldContainer.Id &amp;&amp; reflect.DeepEqual(newContainer.ExclusiveCPUs, oldContainer.ExclusiveCPUs) </span><span class="cov8" title="1">{
                                        duplicate = true
                                        continue</span>
                                }
                        }
                        <span class="cov8" title="1">if !duplicate </span><span class="cov8" title="1">{
                                newContainerList = append(newContainerList, newContainer)
                        }</span>
                }
                <span class="cov8" title="1">workload.Spec.Node.Containers = append(workload.Spec.Node.Containers, newContainerList...)
                err = r.Client.Update(context.TODO(), workload)
                logger.V(5).Info("ammending the workload in the container list")
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "error while trying to update the power workload")
                        return ctrl.Result{}, err
                }</span>
        }

        // Finally, update the controller's state

        <span class="cov8" title="1">logger.V(5).Info("updating the controller's internal state")
        guaranteedPod := powerv1.GuaranteedPod{}
        guaranteedPod.Node = pod.Spec.NodeName
        guaranteedPod.Name = pod.GetName()
        guaranteedPod.Namespace = pod.Namespace
        guaranteedPod.UID = string(podUID)
        guaranteedPod.Containers = make([]powerv1.Container, 0)
        guaranteedPod.Containers = powerContainers
        err = r.State.UpdateStateGuaranteedPods(guaranteedPod)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "error updating the internal state")
                return ctrl.Result{}, err
        }</span>
        <span class="cov8" title="1">wrappedErrs := e.Join(recoveryErrs...)
        if wrappedErrs != nil </span><span class="cov8" title="1">{
                logger.Error(wrappedErrs, "recoverable errors")
                return ctrl.Result{Requeue: false}, fmt.Errorf("recoverable errors encountered")
        }</span>
        <span class="cov8" title="1">return ctrl.Result{}, nil</span>
}

func (r *PowerPodReconciler) getPowerProfileRequestsFromContainers(containers []corev1.Container, profileCRs []powerv1.PowerProfile, customDevices []string, pod *corev1.Pod, logger *logr.Logger) (map[string][]uint, []powerv1.Container, []error) <span class="cov8" title="1">{
        logger.V(5).Info("get the power profiles from the containers")
        _ = context.Background()
        var recoverableErrs []error
        profiles := make(map[string][]uint)
        powerContainers := make([]powerv1.Container, 0)
        for _, container := range containers </span><span class="cov8" title="1">{
                logger.V(5).Info("retrieving the requested power profile from the container spec")
                profile, requestNum, err := getContainerProfileFromRequests(container, customDevices, logger)
                if err != nil </span><span class="cov8" title="1">{
                        recoverableErrs = append(recoverableErrs, err)
                        continue</span>
                }

                // If there was no profile requested in this container we can move onto the next one
                <span class="cov8" title="1">if profile == "" </span><span class="cov0" title="0">{
                        logger.V(5).Info("no profile was requested by the container")
                        continue</span>
                }
                // checks if pod has been altered by time of day
                <span class="cov8" title="1">newProf, ok := pod.ObjectMeta.Annotations["PM-altered"]
                if ok </span><span class="cov0" title="0">{
                        profile = newProf
                }</span>
                <span class="cov8" title="1">if !verifyProfileExists(profile, profileCRs, logger) </span><span class="cov8" title="1">{
                        powerProfileNotFoundError := errors.NewServiceUnavailable(fmt.Sprintf("power profile '%s' not found", profile))
                        recoverableErrs = append(recoverableErrs, powerProfileNotFoundError)
                        continue</span>
                }
                <span class="cov8" title="1">containerID := getContainerID(pod, container.Name)
                coreIDs, err := r.PodResourcesClient.GetContainerCPUs(pod.GetName(), container.Name)
                if err != nil </span><span class="cov0" title="0">{
                        logger.V(5).Info("error getting CoreIDs.", "ContainerID", containerID)
                        recoverableErrs = append(recoverableErrs, err)
                        continue</span>
                }
                <span class="cov8" title="1">cleanCoreList := getCleanCoreList(coreIDs)
                logger.V(5).Info("reserving cores to container.", "ContainerID", containerID, "Cores", cleanCoreList)
                // accounts for case where cores aquired through DRA don't match profile requests
                if len(cleanCoreList) != requestNum </span><span class="cov8" title="1">{
                        recoverableErrs = append(recoverableErrs, fmt.Errorf(fmt.Sprintf("assigned cores did not match requested profiles. cores:%d, profiles %d", len(cleanCoreList), requestNum)))
                        continue</span>
                }
                <span class="cov8" title="1">logger.V(5).Info("creating the power container")
                powerContainer := &amp;powerv1.Container{}
                powerContainer.Name = container.Name
                powerContainer.Id = strings.TrimPrefix(containerID, "docker://")
                powerContainer.ExclusiveCPUs = cleanCoreList
                powerContainer.PowerProfile = profile
                powerContainers = append(powerContainers, *powerContainer)

                if _, exists := profiles[profile]; exists </span><span class="cov8" title="1">{
                        profiles[profile] = append(profiles[profile], cleanCoreList...)
                }</span> else<span class="cov8" title="1"> {
                        profiles[profile] = cleanCoreList
                }</span>
        }

        <span class="cov8" title="1">return profiles, powerContainers, recoverableErrs</span>
}

func verifyProfileExists(profile string, powerProfiles []powerv1.PowerProfile, logger *logr.Logger) bool <span class="cov8" title="1">{
        logger.V(5).Info("confirming the power profile exists in the cluster")
        for _, powerProfile := range powerProfiles </span><span class="cov8" title="1">{
                if powerProfile.Name == profile </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov8" title="1">return false</span>
}

func getNewWorkloadCPUList(cpuList []uint, nodeCpuIds []uint, logger *logr.Logger) []uint <span class="cov8" title="1">{
        updatedWorkloadCPUList := make([]uint, 0)

        logger.V(5).Info("getting the updated workload's CPU list")
        for _, cpu := range nodeCpuIds </span><span class="cov8" title="1">{
                if !util.CPUInCPUList(cpu, cpuList) </span><span class="cov8" title="1">{
                        updatedWorkloadCPUList = append(updatedWorkloadCPUList, cpu)
                }</span>
        }

        <span class="cov8" title="1">return updatedWorkloadCPUList</span>
}

func appendIfUnique(cpuList []uint, cpus []uint) []uint <span class="cov8" title="1">{
        for _, cpu := range cpus </span><span class="cov8" title="1">{
                if !util.CPUInCPUList(cpu, cpuList) </span><span class="cov8" title="1">{
                        cpuList = append(cpuList, cpu)
                }</span>
        }

        <span class="cov8" title="1">return cpuList</span>
}

func getNewWorkloadContainerList(nodeContainers []powerv1.Container, podStateContainers []powerv1.Container, logger *logr.Logger) []powerv1.Container <span class="cov8" title="1">{
        newNodeContainers := make([]powerv1.Container, 0)

        logger.V(5).Info("checking if there are new containers for the workload")
        for _, container := range nodeContainers </span><span class="cov8" title="1">{
                if !isContainerInList(container.Name, container.Id, podStateContainers, logger) </span><span class="cov8" title="1">{
                        newNodeContainers = append(newNodeContainers, container)
                }</span>
        }

        <span class="cov8" title="1">return newNodeContainers</span>
}

// Helper function - if container is in a list of containers
func isContainerInList(name string, uid string, containers []powerv1.Container, logger *logr.Logger) bool <span class="cov8" title="1">{
        for _, container := range containers </span><span class="cov8" title="1">{
                if container.Name == name &amp;&amp; container.Id == uid </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov8" title="1">return false</span>
}

func getContainerProfileFromRequests(container corev1.Container, customDevices []string, logger *logr.Logger) (string, int, error) <span class="cov8" title="1">{
        profileName := ""
        moreThanOneProfileError := errors.NewServiceUnavailable("cannot have more than one power profile per container")
        resourceRequestsMismatchError := errors.NewServiceUnavailable("mismatch between CPU requests and the power profile requests")
        for resource := range container.Resources.Requests </span><span class="cov8" title="1">{
                if strings.HasPrefix(string(resource), ResourcePrefix) </span><span class="cov8" title="1">{
                        if profileName == "" </span><span class="cov8" title="1">{
                                profileName = string(resource[len(ResourcePrefix):])
                        }</span> else<span class="cov0" title="0"> {
                                // Cannot have more than one profile for a singular container
                                return "", 0, moreThanOneProfileError
                        }</span>
                }
        }
        <span class="cov8" title="1">var intProfileRequests int
        if profileName != "" </span><span class="cov8" title="1">{
                // Check if there is a mismatch in CPU requests and the power profile requests
                logger.V(5).Info("confirming that CPU requests and the power profiles request match")
                powerProfileResourceName := corev1.ResourceName(fmt.Sprintf("%s%s", ResourcePrefix, profileName))
                numRequestsPowerProfile := container.Resources.Requests[powerProfileResourceName]
                numLimitsPowerProfile := container.Resources.Limits[powerProfileResourceName]
                intProfileRequests = int(numRequestsPowerProfile.Value())
                intProfileLimits := int(numLimitsPowerProfile.Value())
                // Selecting resources to search
                numRequestsCPU := 0
                numLimitsCPU := 0

                // If the custom resource is requested, change the CPU request to
                // allow the check
                for _, deviceName := range customDevices </span><span class="cov8" title="1">{
                        numRequestsCPU, numLimitsCPU = checkResource(container, corev1.ResourceName(deviceName), numRequestsCPU, numLimitsCPU)
                }</span>

                <span class="cov8" title="1">if numRequestsCPU == 0 </span><span class="cov8" title="1">{
                        numRequestsCPU, numLimitsCPU = checkResource(container, CPUResource, 0, 0)
                }</span>

                // if previous checks fail we need to account for resource claims
                // if there's a problem with core numbers we'll catch it
                // before moving cores to pools by comparing intProfileRequests with assigned cores
                <span class="cov8" title="1">if numRequestsCPU == 0 &amp;&amp; len(container.Resources.Claims) &gt; 0 </span><span class="cov8" title="1">{
                        return profileName, intProfileRequests, nil
                }</span>
                <span class="cov8" title="1">if numRequestsCPU != intProfileRequests ||
                        numLimitsCPU != intProfileLimits </span><span class="cov8" title="1">{
                        return "", 0, resourceRequestsMismatchError
                }</span>
        }

        <span class="cov8" title="1">return profileName, intProfileRequests, nil</span>
}

func checkResource(container corev1.Container, resource corev1.ResourceName, numRequestsCPU int, numLimitsCPU int) (int, int) <span class="cov8" title="1">{
        numRequestsDevice := container.Resources.Requests[resource]
        numRequestsCPU += int(numRequestsDevice.Value())

        numLimitsDevice := container.Resources.Limits[resource]
        numLimitsCPU += int(numLimitsDevice.Value())
        return numRequestsCPU, numLimitsCPU
}</span>

func getAdmissibleContainers(pod *corev1.Pod, customDevices []string, resourceClient podresourcesclient.PodResourcesClient, logger *logr.Logger) []corev1.Container <span class="cov8" title="1">{

        logger.V(5).Info("receiving containers requesting exclusive CPUs")
        admissibleContainers := make([]corev1.Container, 0)
        containerList := append(pod.Spec.InitContainers, pod.Spec.Containers...)
        controlPlaneAvailable := pingControlPlane(resourceClient)
        for _, container := range containerList </span><span class="cov8" title="1">{
                if doesContainerRequireExclusiveCPUs(pod, &amp;container, logger) || validateCustomDevices(&amp;container, customDevices) || controlPlaneAvailable </span><span class="cov8" title="1">{
                        admissibleContainers = append(admissibleContainers, container)
                }</span>
        }
        <span class="cov8" title="1">logger.V(5).Info("containers requesting exclusive resources are: ", "Containers", admissibleContainers)
        return admissibleContainers</span>

}

func doesContainerRequireExclusiveCPUs(pod *corev1.Pod, container *corev1.Container, logger *logr.Logger) bool <span class="cov8" title="1">{
        if pod.Status.QOSClass != corev1.PodQOSGuaranteed </span><span class="cov8" title="1">{
                logger.V(3).Info(fmt.Sprintf("pod %s is not in guaranteed quality of service class", pod.Name))
                return false
        }</span>

        <span class="cov8" title="1">cpuQuantity := container.Resources.Requests[corev1.ResourceCPU]
        return cpuQuantity.Value()*1000 == cpuQuantity.MilliValue()</span>
}

func pingControlPlane(client podresourcesclient.PodResourcesClient) bool <span class="cov8" title="1">{
        // see if the socket sends a response
        req := podresourcesapi.ListPodResourcesRequest{}
        _, err := client.CpuControlPlaneClient.List(context.TODO(), &amp;req)
        return err == nil
}</span>

func validateCustomDevices(container *corev1.Container, customDevices []string) bool <span class="cov8" title="1">{
        presence := false
        for _, devicePlugin := range customDevices </span><span class="cov8" title="1">{
                numResources := container.Resources.Requests[corev1.ResourceName(devicePlugin)]
                if numResources.Value() &gt; 0 </span><span class="cov8" title="1">{
                        presence = numResources.Value()*1000 == numResources.MilliValue()
                }</span>
        }
        <span class="cov8" title="1">return presence</span>
}

func getContainerID(pod *corev1.Pod, containerName string) string <span class="cov8" title="1">{
        for _, containerStatus := range append(pod.Status.InitContainerStatuses, pod.Status.ContainerStatuses...) </span><span class="cov8" title="1">{
                if containerStatus.Name == containerName </span><span class="cov8" title="1">{
                        return containerStatus.ContainerID
                }</span>
        }

        <span class="cov8" title="1">return ""</span>
}

func getCleanCoreList(coreIDs string) []uint <span class="cov8" title="1">{
        cleanCores := make([]uint, 0)
        commaSeparated := strings.Split(coreIDs, ",")
        for _, splitCore := range commaSeparated </span><span class="cov8" title="1">{
                hyphenSeparated := strings.Split(splitCore, "-")
                if len(hyphenSeparated) == 1 </span><span class="cov8" title="1">{
                        intCore, err := strconv.ParseUint(hyphenSeparated[0], 10, 32)
                        if err != nil </span><span class="cov0" title="0">{
                                fmt.Printf("error getting the core list: %v", err)
                                return []uint{}
                        }</span>
                        <span class="cov8" title="1">cleanCores = append(cleanCores, uint(intCore))</span>
                } else<span class="cov8" title="1"> {
                        startCore, err := strconv.Atoi(hyphenSeparated[0])
                        if err != nil </span><span class="cov0" title="0">{
                                fmt.Printf("error getting the core list: %v", err)
                                return []uint{}
                        }</span>
                        <span class="cov8" title="1">endCore, err := strconv.Atoi(hyphenSeparated[len(hyphenSeparated)-1])
                        if err != nil </span><span class="cov0" title="0">{
                                fmt.Printf("error getting the core list: %v", err)
                                return []uint{}
                        }</span>
                        <span class="cov8" title="1">for i := startCore; i &lt;= endCore; i++ </span><span class="cov8" title="1">{
                                cleanCores = append(cleanCores, uint(i))
                        }</span>
                }
        }

        <span class="cov8" title="1">return cleanCores</span>
}

func (r *PowerPodReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov8" title="1">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;corev1.Pod{}).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file22" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        "fmt"
        "os"
        "time"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/power-optimization-library/pkg/power"

        "github.com/go-logr/logr"
        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/api/resource"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/runtime"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/predicate"
)

// value deducted from the max freq of a default profile
// this gives the profile a 0.2 Ghz frequency range
const MinFreqOffset = 200

// performance          ===&gt;  priority level 0
// balance_performance  ===&gt;  priority level 1
// balance_power        ===&gt;  priority level 2
// power                ===&gt;  priority level 3

var profilePercentages map[string]map[string]float64 = map[string]map[string]float64{
        "performance": {
                "resource":   .40,
                "difference": 0.0,
        },
        "balance_performance": {
                "resource":   .60,
                "difference": .25,
        },
        "balance_power": {
                "resource":   .80,
                "difference": .50,
        },
        "power": {
                "resource":   1.0,
                "difference": 0.0,
        },
        // We have the empty string here so users can create power profiles that are not associated with SST-CP
        "": {
                "resource": 1.0,
        },
}

// PowerProfileReconciler reconciles a PowerProfile object
type PowerProfileReconciler struct {
        client.Client
        Log          logr.Logger
        Scheme       *runtime.Scheme
        PowerLibrary power.Host
}

// +kubebuilder:rbac:groups=power.intel.com,resources=powerprofiles,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=power.intel.com,resources=powerprofiles/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=security.openshift.io,resources=securitycontextconstraints,resourceNames=privileged,verbs=use

// Reconcile method that implements the reconcile loop
func (r *PowerProfileReconciler) Reconcile(c context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        var err error
        logger := r.Log.WithValues("powerprofile", req.NamespacedName)
        if req.Namespace != IntelPowerNamespace </span><span class="cov8" title="1">{
                err := fmt.Errorf("incorrect namespace")
                logger.Error(err, "resource is not in the power-manager namespace, ignoring")
                return ctrl.Result{Requeue: false}, err
        }</span>
        <span class="cov8" title="1">logger.Info("reconciling the power profile")

        // Node name is passed down via the downwards API and used to make sure the PowerProfile is for this node
        nodeName := os.Getenv("NODE_NAME")

        profile := &amp;powerv1.PowerProfile{}
        defer func() </span><span class="cov8" title="1">{ _ = writeUpdatedStatusErrsIfRequired(c, r.Status(), profile, err) }</span>()
        <span class="cov8" title="1">err = r.Client.Get(context.TODO(), req.NamespacedName, profile)
        logger.V(5).Info("retrieving the power profile instances")
        if err != nil </span><span class="cov8" title="1">{
                if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                        // First we need to remove the profile from the Power library, this will in turn remove the pool,
                        // which will also move the cores back to the Shared/Default pool and reconfigure them. We then
                        // need to remove the Power Workload from the cluster, which in this case will do nothing as
                        // everything has already been removed. Finally, we remove the Extended Resources from the Node
                        // first we make sure the profile isn't the one used by the shared pool
                        if r.PowerLibrary.GetSharedPool().GetPowerProfile() != nil &amp;&amp; req.Name == r.PowerLibrary.GetSharedPool().GetPowerProfile().Name() </span><span class="cov8" title="1">{
                                err := r.PowerLibrary.GetSharedPool().SetPowerProfile(nil)
                                if err != nil </span><span class="cov8" title="1">{
                                        logger.Error(err, "error setting nil profile")
                                        return ctrl.Result{}, err
                                }</span>
                                <span class="cov8" title="1">pool := r.PowerLibrary.GetExclusivePool(req.Name)
                                if pool == nil </span><span class="cov8" title="1">{
                                        notFoundErr := fmt.Errorf("pool not found")
                                        logger.Error(notFoundErr, fmt.Sprintf("attempted to remove the non existing pool %s", req.Name))
                                        return ctrl.Result{Requeue: false}, notFoundErr
                                }</span>
                                <span class="cov8" title="1">err = pool.Remove()
                                if err != nil </span><span class="cov8" title="1">{
                                        logger.Error(err, "error deleting the power profile from the library")
                                        return ctrl.Result{}, err
                                }</span>
                                <span class="cov0" title="0">return ctrl.Result{}, nil</span>
                        }

                        // To get current cstate obj matching node name and removing powerprofile entry
                        <span class="cov8" title="1">currentNodeCStates := &amp;powerv1.CStates{}
                        err = r.Client.Get(c, client.ObjectKey{Name: nodeName, Namespace: IntelPowerNamespace}, currentNodeCStates)
                        // if we're unsuccessful trying to fetch the cStates coresponding to the current power profile
                        if err != nil &amp;&amp; !errors.IsNotFound(err) </span><span class="cov0" title="0">{
                                logger.Error(err, fmt.Sprintf("unable to retrieve the cState object from the library for %s", nodeName))
                                return ctrl.Result{}, err
                        }</span>
                        // we make changes to the cStates object only if an exclusive pool set-up exists for this c-state
                        // and the corresponding node configuration for exclusive pool is not empty
                        <span class="cov8" title="1">if len(currentNodeCStates.Spec.ExclusivePoolCStates) != 0 &amp;&amp; currentNodeCStates.Spec.ExclusivePoolCStates[req.Name] != nil </span><span class="cov8" title="1">{
                                delete(currentNodeCStates.Spec.ExclusivePoolCStates, req.Name) //req.name current profile
                                err = r.Update(c, currentNodeCStates)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, fmt.Sprintf("error updating the current cState object: %v", currentNodeCStates))
                                        return ctrl.Result{}, err
                                }</span>
                        }

                        <span class="cov8" title="1">powerWorkloadName := fmt.Sprintf("%s-%s", req.NamespacedName.Name, nodeName)
                        powerWorkload := &amp;powerv1.PowerWorkload{}
                        err = r.Client.Get(context.TODO(), client.ObjectKey{
                                Name:      powerWorkloadName,
                                Namespace: req.NamespacedName.Namespace,
                        }, powerWorkload)
                        if err != nil </span><span class="cov8" title="1">{
                                if !errors.IsNotFound(err) </span><span class="cov0" title="0">{
                                        logger.Error(err, fmt.Sprintf("error deleting the power workload '%s' from the cluster", powerWorkloadName))
                                        return ctrl.Result{}, err
                                }</span>
                        } else<span class="cov8" title="1"> {
                                err = r.Client.Delete(context.TODO(), powerWorkload)
                                if err != nil </span><span class="cov8" title="1">{
                                        logger.Error(err, fmt.Sprintf("error deleting the power workload '%s' from the cluster", powerWorkloadName))
                                        return ctrl.Result{}, err
                                }</span>
                        }
                        // Remove the extended resources for this power profile from the node
                        <span class="cov8" title="1">err = r.removeExtendedResources(nodeName, req.NamespacedName.Name, &amp;logger)
                        if err != nil </span><span class="cov8" title="1">{
                                logger.Error(err, "error removing the extended resources from the node")
                                return ctrl.Result{}, err
                        }</span>

                        <span class="cov8" title="1">return ctrl.Result{}, nil</span>
                }

                // Requeue the request
                <span class="cov8" title="1">return ctrl.Result{}, err</span>
        }

        // Make sure the EPP value is one of the four correct ones or empty in the case of a user-created profile
        <span class="cov8" title="1">logger.V(5).Info("confirming EPP value is one of the correct values")
        if _, exists := profilePercentages[profile.Spec.Epp]; !exists </span><span class="cov8" title="1">{
                incorrectEppErr := errors.NewServiceUnavailable(fmt.Sprintf("EPP value not allowed: %v - deleting the power profile CRD", profile.Spec.Epp))
                logger.Error(incorrectEppErr, "error reconciling the power profile")

                err = r.Client.Delete(context.TODO(), profile)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, fmt.Sprintf("error deleting the power profile %s with the incorrect EPP value %s", profile.Spec.Name, profile.Spec.Epp))
                        return ctrl.Result{}, err
                }</span>

                <span class="cov8" title="1">return ctrl.Result{}, nil</span>
        }

        <span class="cov8" title="1">logger.V(5).Info("making sure max and min values are both specified or omitted")
        if profile.Spec.Max != profile.Spec.Min &amp;&amp; (profile.Spec.Max == 0 || profile.Spec.Min == 0) </span><span class="cov8" title="1">{
                maxOrMinNotSpecifiedErr := errors.NewServiceUnavailable("max and min frequency values must be both specified or omitted")
                logger.Error(maxOrMinNotSpecifiedErr, fmt.Sprintf("error creating the profile '%s'", profile.Spec.Name))
                return ctrl.Result{Requeue: false}, maxOrMinNotSpecifiedErr
        }</span>

        <span class="cov8" title="1">logger.V(5).Info("making sure max value is greater than or equal to min value")
        if profile.Spec.Max &lt; profile.Spec.Min </span><span class="cov8" title="1">{
                maxLessThanMinErr := errors.NewServiceUnavailable("max frequency value cannot be lower than the min frequency value")
                logger.Error(maxLessThanMinErr, fmt.Sprintf("error creating the profile '%s'", profile.Spec.Name))
                return ctrl.Result{Requeue: false}, maxLessThanMinErr
        }</span>

        <span class="cov8" title="1">absoluteMinimumFrequency, absoluteMaximumFrequency, err := getMaxMinFrequencyValues(r.PowerLibrary)
        logger.V(5).Info("retrieving the max possible frequency and min possible frequency from the system")
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "error retrieving the frequency values from the node")
                return ctrl.Result{Requeue: false}, err
        }</span>

        <span class="cov8" title="1">var profileMaxFreq int
        var profileMinFreq int
        // check if max and min frequency values are specified
        if profile.Spec.Max == 0 &amp;&amp; profile.Spec.Min == 0 </span><span class="cov8" title="1">{
                if profile.Spec.Epp != "" </span><span class="cov8" title="1">{
                        profileMaxFreq = int(float64(absoluteMaximumFrequency) - (float64((absoluteMaximumFrequency - absoluteMinimumFrequency)) * profilePercentages[profile.Spec.Epp]["difference"]))
                        profileMinFreq = int(profileMaxFreq) - MinFreqOffset
                }</span> else<span class="cov8" title="1"> {
                        profileMaxFreq = absoluteMaximumFrequency
                        profileMinFreq = absoluteMinimumFrequency
                }</span>
        } else<span class="cov8" title="1"> {
                profileMaxFreq = profile.Spec.Max
                profileMinFreq = profile.Spec.Min
        }</span>
        <span class="cov8" title="1">if profileMaxFreq &gt; absoluteMaximumFrequency || profileMinFreq &lt; absoluteMinimumFrequency </span><span class="cov8" title="1">{
                InvalidRangeError := fmt.Errorf("max and min frequency must be within the range %d-%d", absoluteMinimumFrequency, absoluteMaximumFrequency)
                logger.Error(InvalidRangeError, fmt.Sprintf("error creating the profile '%s'", profile.Spec.Name))
                return ctrl.Result{Requeue: false}, InvalidRangeError
        }</span>
        <span class="cov8" title="1">actualEpp := profile.Spec.Epp
        if !power.IsFeatureSupported(power.EPPFeature) &amp;&amp; actualEpp != "" </span><span class="cov8" title="1">{
                err = fmt.Errorf("EPP is not supported but %s provides one, setting EPP to ''", profile.Name)
                logger.Error(err, "invalid EPP")
                actualEpp = ""
        }</span>

        <span class="cov8" title="1">if !checkGovs(profile.Spec.Governor) </span><span class="cov8" title="1">{
                err = fmt.Errorf("governor %s is not supported, please use one of the following %v''", profile.Spec.Governor, power.GetAvailableGovernors())
                logger.Error(err, "invalid governor")
                return ctrl.Result{Requeue: false}, err
        }</span>
        <span class="cov8" title="1">powerProfile, err := power.NewPowerProfile(profile.Spec.Name, uint(profileMinFreq), uint(profileMaxFreq), profile.Spec.Governor, actualEpp)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "could not create the power profile")
                return ctrl.Result{Requeue: false}, err
        }</span>
        // check if profile has an associated pool
        <span class="cov8" title="1">profileFromLibrary := r.PowerLibrary.GetExclusivePool(profile.Spec.Name)
        // if not create one
        if profileFromLibrary == nil </span><span class="cov8" title="1">{
                pool, err := r.PowerLibrary.AddExclusivePool(profile.Spec.Name)
                if err != nil </span><span class="cov8" title="1">{
                        logger.Error(err, "failed to create the power profile")
                        return ctrl.Result{}, err
                }</span>
                <span class="cov8" title="1">err = pool.SetPowerProfile(powerProfile)
                if err != nil </span><span class="cov8" title="1">{
                        logger.Error(err, fmt.Sprintf("error adding the profile '%s' to the power library for host '%s'", profile.Spec.Name, nodeName))
                        return ctrl.Result{}, err
                }</span>
                <span class="cov8" title="1">if profile.Spec.Shared </span><span class="cov8" title="1">{
                        logger.V(5).Info(fmt.Sprintf("shared power profile successfully created: name - %s max - %d min - %d EPP - %s", profile.Spec.Name, profileMaxFreq, profileMinFreq, actualEpp))
                        workloadName := fmt.Sprintf("shared-%s-workload", nodeName)
                        // check if the current node has a shared workload
                        workload := &amp;powerv1.PowerWorkload{}
                        err = r.Client.Get(context.TODO(), client.ObjectKey{
                                Name:      workloadName,
                                Namespace: req.NamespacedName.Namespace,
                        }, workload)
                        if err != nil </span><span class="cov8" title="1">{
                                if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                                        return ctrl.Result{}, nil
                                }</span>
                                <span class="cov0" title="0">logger.Error(err, "client error")
                                return ctrl.Result{}, err</span>
                        }
                        // check if the shared workload uses this profile
                        <span class="cov0" title="0">if workload.Spec.PowerProfile == profile.Spec.Name </span><span class="cov0" title="0">{
                                // if workload uses this profile, update it to use the latest info
                                workload.ObjectMeta.Annotations = map[string]string{"PM-updated": fmt.Sprint(time.Now().Unix())}
                                err = r.Client.Update(context.TODO(), workload)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "error updating workload attached to profile")
                                        return ctrl.Result{}, err
                                }</span>
                        }
                        <span class="cov0" title="0">return ctrl.Result{}, nil</span>
                }
                // Create the extended resources for the profile
                <span class="cov8" title="1">err = r.createExtendedResources(nodeName, profile.Spec.Name, profile.Spec.Epp, &amp;logger)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "error creating the extended resources for the base profile")
                        return ctrl.Result{}, err
                }</span>
        } else<span class="cov8" title="1"> {
                err = r.PowerLibrary.GetExclusivePool(profile.Spec.Name).SetPowerProfile(powerProfile)
                logger.V(5).Info(fmt.Sprintf("updating the power profile '%s' to the power library for node '%s'", profile.Spec.Name, nodeName))
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, fmt.Sprintf("error updating the profile '%s' to the power library for node '%s'", profile.Spec.Name, nodeName))
                        return ctrl.Result{}, err
                }</span>
        }

        <span class="cov8" title="1">logger.V(5).Info(fmt.Sprintf("power profile successfully created: name - %s max - %d min - %d EPP - %s", profile.Spec.Name, profileMaxFreq, profileMinFreq, actualEpp))

        workloadName := fmt.Sprintf("%s-%s", profile.Spec.Name, nodeName)
        logger.V(5).Info(fmt.Sprintf("configuring the workload name: %s", workloadName))
        workload := &amp;powerv1.PowerWorkload{}
        err = r.Client.Get(context.TODO(), client.ObjectKey{
                Name:      workloadName,
                Namespace: req.NamespacedName.Namespace,
        }, workload)
        if err != nil </span><span class="cov8" title="1">{
                if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                        powerWorkloadSpec := &amp;powerv1.PowerWorkloadSpec{
                                Name: workloadName,
                                Node: powerv1.WorkloadNode{
                                        Name: nodeName,
                                },
                                PowerProfile: profile.Spec.Name,
                        }

                        powerWorkload := &amp;powerv1.PowerWorkload{
                                ObjectMeta: metav1.ObjectMeta{
                                        Name:      workloadName,
                                        Namespace: req.NamespacedName.Namespace,
                                },
                        }
                        powerWorkload.Spec = *powerWorkloadSpec

                        err = r.Client.Create(context.TODO(), powerWorkload)
                        if err != nil </span><span class="cov8" title="1">{
                                logger.Error(err, fmt.Sprintf("error creating the power workload '%s'", workloadName))
                                return ctrl.Result{}, err
                        }</span>

                        <span class="cov8" title="1">logger.V(5).Info("power workload successfully created", "name", workloadName, "profile", profile.Spec.Name)
                        return ctrl.Result{}, nil</span>
                }

                <span class="cov0" title="0">return ctrl.Result{}, err</span>
        }

        // If the workload already exists then the power profile was just updated and the power library will take care of reconfiguring cores
        <span class="cov0" title="0">return ctrl.Result{}, nil</span>
}

func (r *PowerProfileReconciler) createExtendedResources(nodeName string, profileName string, eppValue string, logger *logr.Logger) error <span class="cov8" title="1">{
        node := &amp;corev1.Node{}
        err := r.Client.Get(context.TODO(), client.ObjectKey{
                Name: nodeName,
        }, node)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov8" title="1">numCPUsOnNode := float64(len(*r.PowerLibrary.GetAllCpus()))
        logger.V(5).Info("configuring based on the percentage associated to the specific power profile")
        numExtendedResources := int64(numCPUsOnNode * profilePercentages[eppValue]["resource"])
        profilesAvailable := resource.NewQuantity(numExtendedResources, resource.DecimalSI)
        extendedResourceName := corev1.ResourceName(fmt.Sprintf("%s%s", ExtendedResourcePrefix, profileName))
        node.Status.Capacity[extendedResourceName] = *profilesAvailable

        err = r.Client.Status().Update(context.TODO(), node)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov8" title="1">return nil</span>
}

func (r *PowerProfileReconciler) removeExtendedResources(nodeName string, profileName string, logger *logr.Logger) error <span class="cov8" title="1">{
        node := &amp;corev1.Node{}
        err := r.Client.Get(context.TODO(), client.ObjectKey{
                Name: nodeName,
        }, node)
        if err != nil </span><span class="cov8" title="1">{
                return err
        }</span>

        <span class="cov8" title="1">logger.V(5).Info("removing the extended resources")
        newNodeCapacityList := make(map[corev1.ResourceName]resource.Quantity)
        extendedResourceName := corev1.ResourceName(fmt.Sprintf("%s%s", ExtendedResourcePrefix, profileName))
        for resourceFromNode, numberOfResources := range node.Status.Capacity </span><span class="cov8" title="1">{
                if resourceFromNode == extendedResourceName </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">newNodeCapacityList[resourceFromNode] = numberOfResources</span>
        }

        <span class="cov8" title="1">node.Status.Capacity = newNodeCapacityList
        err = r.Client.Status().Update(context.TODO(), node)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov8" title="1">return nil</span>
}

func getMaxMinFrequencyValues(h power.Host) (int, int, error) <span class="cov8" title="1">{
        typeList := h.GetFreqRanges()
        if len(typeList) == 0 </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("could not retireve hardware frequency limits")
        }</span>
        <span class="cov8" title="1">absoluteMaximumFrequency := int(typeList[0].GetMax())
        absoluteMinimumFrequency := int(typeList[0].GetMin())

        absoluteMaximumFrequency = absoluteMaximumFrequency / 1000
        absoluteMinimumFrequency = absoluteMinimumFrequency / 1000

        return absoluteMinimumFrequency, absoluteMaximumFrequency, nil</span>
}

// SetupWithManager specifies how the controller is built and watch a CR and other resources that are owned and managed by the controller
func (r *PowerProfileReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov8" title="1">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.PowerProfile{}).
                WithEventFilter(predicate.GenerationChangedPredicate{}).
                Complete(r)
}</span>

func checkGovs(profileGovernor string) bool <span class="cov8" title="1">{
        if profileGovernor == "" </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">for _, gov := range power.GetAvailableGovernors() </span><span class="cov8" title="1">{
                if gov == profileGovernor </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">return false</span>
}
</pre>
		
		<pre class="file" id="file23" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        "fmt"
        "os"
        "strings"

        e "errors"
        "github.com/go-logr/logr"
        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/kubernetes-power-manager/pkg/util"
        "github.com/intel/power-optimization-library/pkg/power"
        "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/runtime"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/predicate"

        corev1 "k8s.io/api/core/v1"
)

// PowerWorkloadReconciler reconciles a PowerWorkload object
type PowerWorkloadReconciler struct {
        client.Client
        Log          logr.Logger
        Scheme       *runtime.Scheme
        PowerLibrary power.Host
}

const (
        SharedWorkloadName string = "shared-workload"
        WorkloadNameSuffix string = "-workload"
)

var sharedPowerWorkloadName = ""

// +kubebuilder:rbac:groups=power.intel.com,resources=powerworkloads,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=power.intel.com,resources=powerworkloads/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=security.openshift.io,resources=securitycontextconstraints,resourceNames=privileged,verbs=use

func (r *PowerWorkloadReconciler) Reconcile(c context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        var err error
        logger := r.Log.WithValues("powerworkload", req.NamespacedName)
        if req.Namespace != IntelPowerNamespace </span><span class="cov8" title="1">{
                err := fmt.Errorf("incorrect namespace")
                logger.Error(err, "resource is not in the power-manager namespace, ignoring")
                return ctrl.Result{Requeue: false}, err
        }</span>
        <span class="cov8" title="1">nodeName := os.Getenv("NODE_NAME")

        workload := &amp;powerv1.PowerWorkload{}
        defer func() </span><span class="cov8" title="1">{ _ = writeUpdatedStatusErrsIfRequired(c, r.Status(), workload, err) }</span>()

        <span class="cov8" title="1">err = r.Client.Get(context.TODO(), req.NamespacedName, workload)
        logger.V(5).Info("retrieving the power workload instance")
        if err != nil </span><span class="cov8" title="1">{
                if errors.IsNotFound(err) </span><span class="cov8" title="1">{
                        // If the profile still exists in the power library, then only the power workload was deleted
                        // and we need to remove it from the power library here. If the profile doesn't exist, then
                        // the power library will have deleted it for us
                        if req.NamespacedName.Name == sharedPowerWorkloadName </span><span class="cov8" title="1">{
                                movedCores := *r.PowerLibrary.GetSharedPool().Cpus()
                                pools := r.PowerLibrary.GetAllExclusivePools()
                                for _, pool := range *pools </span><span class="cov8" title="1">{
                                        if strings.Contains(pool.Name(), nodeName+"-reserved-") </span><span class="cov8" title="1">{
                                                movedCores = append(movedCores, *pool.Cpus()...)
                                                if err := pool.Remove(); err != nil </span><span class="cov0" title="0">{
                                                        logger.Error(err, "failed to remove reserved pool")
                                                        return ctrl.Result{}, err
                                                }</span>
                                        }
                                }
                                <span class="cov8" title="1">err = r.PowerLibrary.GetReservedPool().MoveCpus(movedCores)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "failed to return all non exclusive cores to default reserved pool")
                                        return ctrl.Result{}, err
                                }</span>
                                <span class="cov8" title="1">sharedPowerWorkloadName = ""</span>
                        } else<span class="cov8" title="1"> {
                                pool := r.PowerLibrary.GetExclusivePool(strings.ReplaceAll(req.NamespacedName.Name, ("-" + nodeName), ""))
                                if pool != nil </span><span class="cov8" title="1">{
                                        err = pool.Remove()
                                        if err != nil </span><span class="cov8" title="1">{
                                                logger.Error(err, "failed to remove the exclusive pool")
                                                return ctrl.Result{}, err
                                        }</span>
                                }
                        }

                        <span class="cov8" title="1">return ctrl.Result{}, nil</span>
                }

                <span class="cov0" title="0">return ctrl.Result{}, err</span>
        }

        // If there are multiple nodes the shared power workload's node selector satisfies we need to fail here before anything is done
        <span class="cov8" title="1">logger.V(5).Info("checking the node elector is satisfied with the shared power workload")
        if workload.Spec.AllCores </span><span class="cov8" title="1">{
                labelledNodeList := &amp;corev1.NodeList{}
                listOption := workload.Spec.PowerNodeSelector

                err = r.Client.List(context.TODO(), labelledNodeList, client.MatchingLabels(listOption))
                if err != nil </span><span class="cov8" title="1">{
                        logger.Error(err, "error retrieving the node with the power node selector", "selector", listOption)
                        return ctrl.Result{}, err
                }</span>

                // If there were no nodes that matched the provided labels, check the node info of the workload for a name
                <span class="cov8" title="1">logger.V(5).Info("checking the node info to see if the node name has been provided")
                if (len(labelledNodeList.Items) == 0 &amp;&amp; workload.Spec.Node.Name != nodeName) || !util.NodeNameInNodeList(nodeName, labelledNodeList.Items) </span><span class="cov8" title="1">{
                        return ctrl.Result{}, nil
                }</span>

                <span class="cov8" title="1">logger.V(5).Info("verifying there is only one shared power workload and if there is more than one delete this instance")
                if sharedPowerWorkloadName != "" &amp;&amp; sharedPowerWorkloadName != req.NamespacedName.Name </span><span class="cov8" title="1">{
                        // Delete this shared power workload as another already exists
                        err = r.Client.Delete(context.TODO(), workload)
                        if err != nil </span><span class="cov8" title="1">{
                                logger.Error(err, "error deleting the second shared power workload")
                                return ctrl.Result{}, err
                        }</span>

                        <span class="cov8" title="1">sharedPowerWorkloadAlreadyExists := errors.NewServiceUnavailable("a shared power workload already exists for this node")
                        logger.Error(sharedPowerWorkloadAlreadyExists, "error creating the shared power workload")
                        return ctrl.Result{Requeue: false}, sharedPowerWorkloadAlreadyExists</span>
                }
                // retrieve pool with the profile we want to attach to the shared pool
                <span class="cov8" title="1">pool := r.PowerLibrary.GetExclusivePool(workload.Spec.PowerProfile)
                if pool == nil </span><span class="cov0" title="0">{
                        logger.Error(fmt.Errorf("pool not found"), fmt.Sprintf("could not retrieve pool for profile %s", workload.Spec.PowerProfile))
                        return ctrl.Result{Requeue: false}, fmt.Errorf("pool not found")
                }</span>
                <span class="cov8" title="1">profile := pool.GetPowerProfile()
                // shouldn't be possible but just in case
                if profile == nil </span><span class="cov0" title="0">{
                        logger.Error(fmt.Errorf("pool not found"), fmt.Sprintf("pool  %s did not have the subsequent profile", workload.Spec.PowerProfile))
                        return ctrl.Result{Requeue: false}, fmt.Errorf("profile not found")
                }</span>
                <span class="cov8" title="1">err = r.PowerLibrary.GetSharedPool().SetPowerProfile(profile)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "could not set the power profile for the shared pool")
                        return ctrl.Result{Requeue: false}, err
                }</span>

                // move all cores to the shared pool,
                // then set up individual pools for reserved cores
                <span class="cov8" title="1">logger.V(5).Info("creating the shared pool in the power library")
                if err := r.PowerLibrary.GetReservedPool().SetCpuIDs([]uint{}); err != nil </span><span class="cov8" title="1">{
                        logger.Error(err, "error initializing reserved pool")
                        return ctrl.Result{}, err
                }</span>
                // remove the existing reserved pools in case they aren't needed after this
                <span class="cov8" title="1">pools := r.PowerLibrary.GetAllExclusivePools()
                for _, pool := range *pools </span><span class="cov8" title="1">{
                        if strings.Contains(pool.Name(), nodeName+"-reserved-") </span><span class="cov8" title="1">{
                                if err := pool.Remove(); err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "failed to remove reserved pool")
                                        return ctrl.Result{}, err
                                }</span>
                        }
                }
                <span class="cov8" title="1">var recoveryErrs []error
                for _, coreConfig := range workload.Spec.ReservedCPUs </span><span class="cov8" title="1">{
                        // move cores to shared pool to prevent exclusive-&gt;reserved conflicts
                        if err := r.PowerLibrary.GetSharedPool().MoveCpuIDs(coreConfig.Cores); err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "error moving cores to shared pool")
                                return ctrl.Result{}, err
                        }</span>
                        <span class="cov8" title="1">if coreConfig.PowerProfile != "" </span><span class="cov8" title="1">{
                                if err := createReservedPool(r.PowerLibrary, coreConfig, &amp;logger); err != nil </span><span class="cov8" title="1">{
                                        recoveryErrs = append(recoveryErrs, err)
                                        // if attaching a profile failed, try moving the cores to the default reserved pool
                                        if err := r.PowerLibrary.GetReservedPool().MoveCpuIDs(coreConfig.Cores); err != nil </span><span class="cov8" title="1">{
                                                logger.Error(err, "error moving cores to reserved pool")
                                                return ctrl.Result{}, err
                                        }</span>
                                }
                        } else<span class="cov8" title="1"> {
                                // no profile specified so leave the cores in the default reserved pool
                                if err := r.PowerLibrary.GetReservedPool().MoveCpuIDs(coreConfig.Cores); err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "error moving cores to reserved pool")
                                        return ctrl.Result{}, err
                                }</span>
                        }
                }
                <span class="cov8" title="1">sharedPowerWorkloadName = req.NamespacedName.Name
                wrappedErrs := e.Join(recoveryErrs...)
                if wrappedErrs != nil </span><span class="cov8" title="1">{
                        errString := "error(s) encountered establishing reserved pool"
                        logger.Error(wrappedErrs, errString)
                        return ctrl.Result{Requeue: false}, fmt.Errorf(errString)
                }</span>
                <span class="cov8" title="1">return ctrl.Result{}, nil</span>
        }

        <span class="cov8" title="1">if workload.Spec.Node.Name == nodeName </span><span class="cov8" title="1">{
                poolFromLibrary := r.PowerLibrary.GetExclusivePool(workload.Spec.PowerProfile)
                if poolFromLibrary == nil </span><span class="cov8" title="1">{
                        poolDoesNotExistError := errors.NewServiceUnavailable(fmt.Sprintf("pool '%s' does not exist in the power library", workload.Spec.PowerProfile))
                        logger.Error(poolDoesNotExistError, "error retrieving the pool from the power library")
                        return ctrl.Result{Requeue: false}, poolDoesNotExistError
                }</span>

                <span class="cov8" title="1">logger.V(5).Info("updating the CPU list in the power library")
                cores := poolFromLibrary.Cpus().IDs()
                coresToRemoveFromLibrary := detectCoresRemoved(cores, workload.Spec.Node.CpuIds, &amp;logger)
                coresToBeAddedToLibrary := detectCoresAdded(cores, workload.Spec.Node.CpuIds, &amp;logger)

                if len(coresToRemoveFromLibrary) &gt; 0 </span><span class="cov8" title="1">{
                        err = r.PowerLibrary.GetSharedPool().MoveCpuIDs(coresToRemoveFromLibrary)
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "error updating the power library CPU list")
                                return ctrl.Result{}, err
                        }</span>
                }

                <span class="cov8" title="1">if len(coresToBeAddedToLibrary) &gt; 0 </span><span class="cov8" title="1">{
                        err = r.PowerLibrary.GetExclusivePool(workload.Spec.PowerProfile).MoveCpuIDs(coresToBeAddedToLibrary)
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "error updating the power library CPU list")
                                return ctrl.Result{}, err
                        }</span>
                }
        }

        <span class="cov8" title="1">return ctrl.Result{}, nil</span>
}

func detectCoresRemoved(originalCoreList []uint, updatedCoreList []uint, logger *logr.Logger) []uint <span class="cov8" title="1">{
        var coresRemoved []uint
        logger.V(5).Info("detecting if cores are removed from the cores list")
        for _, core := range originalCoreList </span><span class="cov8" title="1">{
                if !validateCoreIsInCoreList(core, updatedCoreList) </span><span class="cov8" title="1">{
                        coresRemoved = append(coresRemoved, core)
                }</span>
        }

        <span class="cov8" title="1">return coresRemoved</span>
}

func detectCoresAdded(originalCoreList []uint, updatedCoreList []uint, logger *logr.Logger) []uint <span class="cov8" title="1">{
        var coresAdded []uint
        logger.V(5).Info("detecting if cores are added to the cores list")
        for _, core := range updatedCoreList </span><span class="cov8" title="1">{
                if !validateCoreIsInCoreList(core, originalCoreList) </span><span class="cov8" title="1">{
                        coresAdded = append(coresAdded, core)
                }</span>
        }

        <span class="cov8" title="1">return coresAdded</span>
}

func validateCoreIsInCoreList(core uint, coreList []uint) bool <span class="cov8" title="1">{
        for _, c := range coreList </span><span class="cov8" title="1">{
                if c == core </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov8" title="1">return false</span>
}

func createReservedPool(library power.Host, coreConfig powerv1.ReservedSpec, logger *logr.Logger) error <span class="cov8" title="1">{
        pseudoReservedPool, err := library.AddExclusivePool(os.Getenv("NODE_NAME") + "-reserved-" + fmt.Sprintf("%v", coreConfig.Cores))
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, fmt.Sprintf("error creating reserved pool for cores %v", coreConfig.Cores))
                return err
        }</span>

        <span class="cov8" title="1">if err := pseudoReservedPool.SetCpuIDs(coreConfig.Cores); err != nil </span><span class="cov8" title="1">{
                if removePoolError := pseudoReservedPool.Remove(); removePoolError != nil </span><span class="cov0" title="0">{
                        logger.Error(removePoolError, fmt.Sprintf("error removing pool %v", pseudoReservedPool.Name()))
                }</span>

                <span class="cov8" title="1">logger.Error(err, "error moving cores to special reserved pool")
                return err</span>
        }

        <span class="cov8" title="1">corePool := library.GetExclusivePool(coreConfig.PowerProfile)
        if corePool == nil </span><span class="cov8" title="1">{
                if removePoolError := pseudoReservedPool.Remove(); removePoolError != nil </span><span class="cov8" title="1">{
                        logger.Error(removePoolError, fmt.Sprintf("error removing pool %v", pseudoReservedPool.Name()))
                }</span>

                <span class="cov8" title="1">logger.Error(err, "error setting retrieving exclusive pool for reserved cores")
                return fmt.Errorf(fmt.Sprintf("specified profile %s has no existing pool", coreConfig.PowerProfile))</span>
        }
        <span class="cov8" title="1">if err := pseudoReservedPool.SetPowerProfile(corePool.GetPowerProfile()); err != nil </span><span class="cov8" title="1">{
                if removePoolError := pseudoReservedPool.Remove(); removePoolError != nil </span><span class="cov8" title="1">{
                        logger.Error(removePoolError, fmt.Sprintf("error removing pool %v", pseudoReservedPool.Name()))
                }</span>
                <span class="cov8" title="1">logger.Error(err, "error setting profile for reserved cores")
                return err</span>
        }

        <span class="cov8" title="1">return nil</span>
}

func (r *PowerWorkloadReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov0" title="0">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.PowerWorkload{}).
                WithEventFilter(predicate.GenerationChangedPredicate{}).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file24" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        "fmt"
        "os"
        "regexp"
        "strconv"
        "strings"
        "time"
        _ "time/tzdata"

        "github.com/go-logr/logr"
        apierrors "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/runtime"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/predicate"

        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"

        "github.com/intel/kubernetes-power-manager/pkg/util"
)

// TimeOfDayReconciler reconciles a TimeOfDay object
type TimeOfDayReconciler struct {
        client.Client
        Log    logr.Logger
        Scheme *runtime.Scheme
}

//+kubebuilder:rbac:groups=power.intel.com,resources=timeofdays,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups=power.intel.com,resources=timeofdays/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=security.openshift.io,resources=securitycontextconstraints,resourceNames=privileged,verbs=use

func (r *TimeOfDayReconciler) Reconcile(c context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        var err error
        logger := r.Log.WithValues("timeofday", req.NamespacedName)
        if req.Namespace != IntelPowerNamespace </span><span class="cov8" title="1">{
                err := fmt.Errorf("incorrect namespace")
                logger.Error(err, "resource is not in the power-manager namespace, ignoring")
                return ctrl.Result{Requeue: false}, err
        }</span>
        <span class="cov8" title="1">nodeName := os.Getenv("NODE_NAME")
        if req.Name != nodeName </span><span class="cov0" title="0">{
                return ctrl.Result{}, nil
        }</span>
        //enforces HH:MM:SS time format
        <span class="cov8" title="1">timeRegex := regexp.MustCompile("(0[0-9]|1[0-9]|2[0-3]):[0-5][0-9](:[0-5][0-9])?")

        timeOfDayList := &amp;powerv1.TimeOfDayList{}
        logger.V(5).Info("retrieving time-of-day objects from the lists")
        err = r.Client.List(c, timeOfDayList)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "error retrieving the time-of-day list")
                return ctrl.Result{}, err
        }</span>

        <span class="cov8" title="1">logger.V(5).Info("confirming that there can only be one time-of-day object")
        if len(timeOfDayList.Items) &gt; 1 </span><span class="cov8" title="1">{
                err = apierrors.NewServiceUnavailable("cannot have more than one time-of-day")
                logger.Error(err, "error reconciling time-of-day")
                return ctrl.Result{}, err
        }</span>

        <span class="cov8" title="1">timeOfDay := &amp;powerv1.TimeOfDay{}
        defer func() </span><span class="cov8" title="1">{ _ = writeUpdatedStatusErrsIfRequired(c, r.Status(), timeOfDay, err) }</span>()

        <span class="cov8" title="1">err = r.Client.Get(c, req.NamespacedName, timeOfDay)
        if err != nil </span><span class="cov8" title="1">{
                if apierrors.IsNotFound(err) </span><span class="cov8" title="1">{
                        logger.V(5).Info("deleting time-of-day cron jobs from cluster")
                        err = r.Client.DeleteAllOf(c, &amp;powerv1.TimeOfDayCronJob{}, client.InNamespace(IntelPowerNamespace))
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "error deleting the time-of-day cron jobs")
                                return ctrl.Result{}, err
                        }</span>
                }
                <span class="cov8" title="1">logger.Error(err, "error retrieving time-of-day")
                return ctrl.Result{}, err</span>
        }

        // Validate incoming values from time-of-day manifest
        <span class="cov8" title="1">timeZone := timeOfDay.Spec.TimeZone
        logger.V(5).Info(fmt.Sprintf("validated timezone for time-of-day, values are: %s", timeZone))

        if timeZone != "" </span><span class="cov8" title="1">{
                _, err = time.LoadLocation(timeZone)
                logger.Info(fmt.Sprintf("timezone is %s\n", timeZone))
                if err != nil </span><span class="cov8" title="1">{
                        err = apierrors.NewServiceUnavailable("invalid timezone, refer to the IANA timezone database for a list of valid timezones")
                        logger.Error(err, "error creating time-of-day")
                        return ctrl.Result{}, err
                }</span>
        }

        <span class="cov8" title="1">var cronJobNames []string
        logger.V(5).Info("creating time-of-day Cronjobs")
        for _, scheduleInfo := range timeOfDay.Spec.Schedule </span><span class="cov8" title="1">{
                if !timeRegex.MatchString(scheduleInfo.Time) </span><span class="cov8" title="1">{
                        err = apierrors.NewServiceUnavailable("the time filed must be in format HH:MM:SS or HH:MM and cannot be empty")
                        logger.Error(err, "error creating the time-of-day schedule")
                        return ctrl.Result{}, err
                }</span>

                <span class="cov8" title="1">scheduledTime := strings.Split(scheduleInfo.Time, ":")
                if len(scheduledTime) == 2 </span><span class="cov8" title="1">{
                        scheduledTime = append(scheduledTime, "00")
                }</span>

                <span class="cov8" title="1">hr, _ := strconv.Atoi(scheduledTime[0])
                min, _ := strconv.Atoi(scheduledTime[1])
                sec, _ := strconv.Atoi(scheduledTime[2])
                if scheduleInfo.PowerProfile != nil &amp;&amp; timeOfDay.Spec.ReservedCPUs == nil </span><span class="cov0" title="0">{
                        err = apierrors.NewServiceUnavailable("profile detected with no reserved CPUs set")
                        logger.Error(err, "error creating the time-of-day schedule")
                        return ctrl.Result{}, err
                }</span>

                <span class="cov8" title="1">cronJobName := fmt.Sprintf("%s-%d-%d-%d", timeOfDay.Name, hr, min, sec)

                cronJob := &amp;powerv1.TimeOfDayCronJob{}
                err = r.Client.Get(c, client.ObjectKey{
                        Name:      cronJobName,
                        Namespace: IntelPowerNamespace,
                }, cronJob)
                // if cronjob doesn't exist create one
                logger.V(5).Info("creating the cron job if one doesn't exist")
                if err != nil </span><span class="cov8" title="1">{

                        if apierrors.IsNotFound(err) </span><span class="cov8" title="1">{
                                // passing spec values from timeofday object to cronjob
                                cronJobSpec := &amp;powerv1.TimeOfDayCronJobSpec{
                                        Hour:         hr,
                                        Minute:       min,
                                        Second:       sec,
                                        TimeZone:     &amp;timeOfDay.Spec.TimeZone,
                                        Profile:      scheduleInfo.PowerProfile,
                                        Pods:         scheduleInfo.Pods,
                                        ReservedCPUs: timeOfDay.Spec.ReservedCPUs,
                                        CState:       scheduleInfo.CState,
                                }

                                cronJob = &amp;powerv1.TimeOfDayCronJob{
                                        ObjectMeta: metav1.ObjectMeta{
                                                Namespace: IntelPowerNamespace,
                                                Name:      cronJobName,
                                        },
                                }
                                // creating the new cronjob
                                cronJob.Spec = *cronJobSpec
                                err = r.Client.Create(c, cronJob)

                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "error creating the time-of-day cron job")
                                        return ctrl.Result{}, err
                                }</span>

                                <span class="cov8" title="1">logger.Info(fmt.Sprintf("cron job for %d:%d successfully created", hr, min))</span>
                        }
                }

                <span class="cov8" title="1">cronJobNames = append(cronJobNames, cronJobName)</span>
        }

        <span class="cov8" title="1">cronJobList := &amp;powerv1.TimeOfDayCronJobList{}
        err = r.Client.List(c, cronJobList, client.InNamespace(IntelPowerNamespace))
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "error retrieving the cron job list")
                return ctrl.Result{}, err
        }</span>

        <span class="cov8" title="1">err = r.cleanUpCronJobs(cronJobList.Items, cronJobNames)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "error reconciling time-of-day")
                return ctrl.Result{}, err
        }</span>

        <span class="cov8" title="1">return ctrl.Result{}, nil</span>
}

func (r *TimeOfDayReconciler) cleanUpCronJobs(cronJobs []powerv1.TimeOfDayCronJob, expectedCronJobs []string) error <span class="cov8" title="1">{
        for _, cronJob := range cronJobs </span><span class="cov8" title="1">{
                if !util.StringInStringList(cronJob.Name, expectedCronJobs) </span><span class="cov8" title="1">{
                        err := r.Client.Delete(context.TODO(), &amp;cronJob)
                        if err != nil </span><span class="cov8" title="1">{
                                return err
                        }</span>
                }
        }
        <span class="cov8" title="1">return nil</span>
}

// SetupWithManager sets up the controller with the Manager.
func (r *TimeOfDayReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov8" title="1">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.TimeOfDay{}).
                WithEventFilter(predicate.GenerationChangedPredicate{}).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file25" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        "fmt"
        "os"

        corev1 "k8s.io/api/core/v1"
        apierrors "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/labels"

        "time"

        "github.com/go-logr/logr"
        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/kubernetes-power-manager/pkg/podstate"
        "github.com/intel/power-optimization-library/pkg/power"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/runtime"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/predicate"
)

// TimeOfDayCronJobReconciler reconciles a TimeOfDayCronJob object
type TimeOfDayCronJobReconciler struct {
        client.Client
        Log          logr.Logger
        Scheme       *runtime.Scheme
        State        *podstate.State
        PowerLibrary power.Host
}

// +kubebuilder:rbac:groups=power.intel.com,resources=timeofdaycronjobs,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=power.intel.com,resources=timeofdaycronjobs/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=security.openshift.io,resources=securitycontextconstraints,resourceNames=privileged,verbs=use
// Reconcile is part of the main kubernetes reconciliation loop which aims to
// move the current state of the cluster closer to the desired state.
// TODO(user): Modify the Reconcile function to compare the state specified by
// the TimeOfDayCronJob object against the actual cluster state, and then
// perform operations to make the cluster state reflect the state specified by
// the user.
//
// For more details, check Reconcile and its Result here:
// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.6.4/pkg/reconcile
func (r *TimeOfDayCronJobReconciler) Reconcile(c context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov8" title="1">{
        var err error
        logger := r.Log.WithValues("timeofdaycronjob", req.NamespacedName)
        if req.Namespace != IntelPowerNamespace </span><span class="cov8" title="1">{
                err := fmt.Errorf("incorrect namespace")
                logger.Error(err, "resource is not in the power-manager namespace, ignoring")
                return ctrl.Result{Requeue: false}, err
        }</span>
        <span class="cov8" title="1">logger.Info("reconciling time-of-day cron job")

        cronJob := &amp;powerv1.TimeOfDayCronJob{}
        defer func() </span><span class="cov8" title="1">{ _ = writeUpdatedStatusErrsIfRequired(c, r.Status(), cronJob, err) }</span>()

        <span class="cov8" title="1">err = r.Client.Get(context.TODO(), req.NamespacedName, cronJob)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "error retrieving the time-of-day cron job")
                return ctrl.Result{Requeue: false}, err
        }</span>

        // setting up the location
        <span class="cov8" title="1">var location *time.Location
        if cronJob.Spec.TimeZone != nil </span><span class="cov8" title="1">{
                location, err = time.LoadLocation(*cronJob.Spec.TimeZone)
                if err != nil </span><span class="cov8" title="1">{
                        location = time.Local
                }</span>
        } else<span class="cov8" title="1"> {
                location = time.Local
        }</span>
        <span class="cov8" title="1">nodeName := os.Getenv("NODE_NAME")
        // reading the schedule
        hr := cronJob.Spec.Hour
        min := cronJob.Spec.Minute
        sec := cronJob.Spec.Second
        jobActiveTime := time.Date(time.Now().In(location).Year(), time.Now().In(location).Month(), time.Now().In(location).Day(), hr, min, sec, 0, location)
        wait := jobActiveTime.Sub(time.Now().In(location))
        // calculating when to schedule the job next
        nextActiveTime := jobActiveTime.Add(24 * time.Hour)
        logger.V(5).Info(fmt.Sprintf("the next active time is: %s", nextActiveTime))
        nextWait := nextActiveTime.Sub(time.Now().In(location))
        // the cron job missed the deadline
        if wait.Seconds() &lt;= 0 &amp;&amp; cronJob.Status.LastScheduleTime == nil </span><span class="cov8" title="1">{
                logger.Info(fmt.Sprintf("the cron job missed the deadline by %s, scheduling for tommorow", wait.String()))
                cronJob.Status.LastScheduleTime = &amp;metav1.Time{Time: time.Now().In(location)}
                if err = r.Status().Update(c, cronJob); err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "cannot update status")
                        return ctrl.Result{}, err
                }</span>
                <span class="cov8" title="1">return ctrl.Result{RequeueAfter: nextWait}, nil</span>
        }
        <span class="cov8" title="1">if cronJob.Status.LastScheduleTime == nil </span><span class="cov8" title="1">{
                // cron job just created
                logger.V(5).Info("reconciling newly created cron job")
                logger.Info(fmt.Sprintf("telling reconciler to wait %s", wait.String()))
                cronJob.Status.LastScheduleTime = &amp;metav1.Time{Time: time.Now().In(location)}
                if err = r.Status().Update(c, cronJob); err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "cannot update status")
                        return ctrl.Result{}, err
                }</span>
                <span class="cov8" title="1">return ctrl.Result{RequeueAfter: wait}, nil</span>

        } else<span class="cov8" title="1"> {
                // cron job ready for application
                if wait.Seconds() &lt;= 0 </span><span class="cov8" title="1">{
                        logger.V(5).Info("cron job ready to be applied")
                        if cronJob.Spec.Profile != nil </span><span class="cov8" title="1">{
                                var workloadMatch *powerv1.PowerWorkload
                                var profileMaxFreq int
                                var profileMinFreq int
                                // check if shared workload exists, if not create one
                                logger.V(5).Info("checking for an existing shared workload")
                                workloadList := &amp;powerv1.PowerWorkloadList{}
                                err = r.Client.List(context.TODO(), workloadList)
                                if err != nil </span><span class="cov8" title="1">{
                                        logger.Error(err, "error retrieving the workloads")
                                        return ctrl.Result{}, err
                                }</span>
                                // if an active workload exists with all cores set to true it must be shared
                                <span class="cov8" title="1">for _, workload := range workloadList.Items </span><span class="cov8" title="1">{
                                        if workload.Spec.AllCores </span><span class="cov8" title="1">{
                                                workloadMatch = &amp;workload
                                                break</span>
                                        }
                                }
                                // a shared workload does not exist so make one
                                <span class="cov8" title="1">if workloadMatch == nil </span><span class="cov8" title="1">{
                                        if cronJob.Spec.ReservedCPUs == nil </span><span class="cov8" title="1">{
                                                err = fmt.Errorf("reserved CPU field left blank")
                                                logger.Error(err, "reservedCPUs must be set")
                                                return ctrl.Result{Requeue: false}, err
                                        }</span>
                                        <span class="cov8" title="1">logger.V(5).Info("creating the shared workload as none exists")
                                        workloadName := fmt.Sprintf("shared-%s", nodeName)
                                        workload := &amp;powerv1.PowerWorkload{
                                                ObjectMeta: metav1.ObjectMeta{
                                                        Namespace: IntelPowerNamespace,
                                                        Name:      workloadName,
                                                },
                                                Spec: powerv1.PowerWorkloadSpec{
                                                        Name:         workloadName,
                                                        AllCores:     true,
                                                        ReservedCPUs: []powerv1.ReservedSpec{{Cores: *cronJob.Spec.ReservedCPUs}},
                                                        Node: powerv1.WorkloadNode{
                                                                Name: nodeName,
                                                        },
                                                        PowerProfile: *cronJob.Spec.Profile,
                                                },
                                        }
                                        if err = r.Client.Create(context.TODO(), workload); err != nil </span><span class="cov0" title="0">{
                                                logger.Error(err, "error creating workload")
                                                return ctrl.Result{}, err
                                        }</span>
                                        <span class="cov8" title="1">workloadMatch = workload</span>
                                }
                                // A shared workload exists so we attach it to the profile
                                <span class="cov8" title="1">logger.V(5).Info("modifying the shared workload")
                                workloadMatch.Spec.PowerProfile = *cronJob.Spec.Profile
                                logger.V(5).Info(fmt.Sprintf("setting profile %s", *cronJob.Spec.Profile))
                                prof := &amp;powerv1.PowerProfile{}
                                if err = r.Client.Get(context.TODO(), client.ObjectKey{Name: *cronJob.Spec.Profile, Namespace: IntelPowerNamespace}, prof); err != nil </span><span class="cov8" title="1">{
                                        logger.Error(err, "cannot retrieve the profile")
                                        return ctrl.Result{Requeue: false}, err
                                }</span>

                                <span class="cov8" title="1">absoluteMinimumFrequency, absoluteMaximumFrequency, err := getMaxMinFrequencyValues(r.PowerLibrary)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "error retrieving the frequency values from the node")
                                        return ctrl.Result{Requeue: false}, err
                                }</span>
                                <span class="cov8" title="1">if prof.Spec.Epp != "" &amp;&amp; prof.Spec.Max == 0 &amp;&amp; prof.Spec.Min == 0 </span><span class="cov8" title="1">{
                                        profileMaxFreq = int(float64(absoluteMaximumFrequency) - (float64((absoluteMaximumFrequency - absoluteMinimumFrequency)) * profilePercentages[prof.Spec.Epp]["difference"]))
                                        profileMinFreq = int(profileMaxFreq) - 200
                                }</span> else<span class="cov8" title="1"> {
                                        profileMaxFreq = prof.Spec.Max
                                        profileMinFreq = prof.Spec.Min
                                }</span>
                                <span class="cov8" title="1">powerProfile, err := power.NewPowerProfile(prof.Spec.Name, uint(profileMinFreq), uint(profileMaxFreq), prof.Spec.Governor, prof.Spec.Epp)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "could not set the power profile for the shared pool")
                                        return ctrl.Result{Requeue: false}, err
                                }</span>
                                <span class="cov8" title="1">err = r.PowerLibrary.GetSharedPool().SetPowerProfile(powerProfile)
                                if err != nil </span><span class="cov8" title="1">{
                                        logger.Error(err, "could not set the power profile for the shared pool")
                                        return ctrl.Result{Requeue: false}, err
                                }</span>
                                <span class="cov8" title="1">if err = r.Client.Update(c, workloadMatch); err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, "cannot update the workload")
                                        return ctrl.Result{}, err
                                }</span>

                                <span class="cov8" title="1">logger.V(5).Info("new shared pool applied")</span>
                        }
                        <span class="cov8" title="1">if cronJob.Spec.CState != nil </span><span class="cov8" title="1">{
                                cstate := &amp;powerv1.CStates{}
                                err = r.Client.Get(context.TODO(), client.ObjectKey{
                                        Name:      nodeName,
                                        Namespace: IntelPowerNamespace,
                                }, cstate)
                                if apierrors.IsNotFound(err) </span><span class="cov8" title="1">{
                                        // if C-State does not exist
                                        logger.V(5).Info("creating new C-State")
                                        newCstate := &amp;powerv1.CStates{
                                                ObjectMeta: metav1.ObjectMeta{
                                                        Namespace: IntelPowerNamespace,
                                                        Name:      nodeName,
                                                },
                                                Spec: powerv1.CStatesSpec{
                                                        SharedPoolCStates:     cronJob.Spec.CState.SharedPoolCStates,
                                                        ExclusivePoolCStates:  cronJob.Spec.CState.ExclusivePoolCStates,
                                                        IndividualCoreCStates: cronJob.Spec.CState.IndividualCoreCStates,
                                                },
                                        }
                                        if err = r.Client.Create(context.TODO(), newCstate); err != nil </span><span class="cov0" title="0">{
                                                logger.Error(err, "error creating the workload")
                                                return ctrl.Result{}, err
                                        }</span>

                                } else<span class="cov8" title="1"> {
                                        //if cstate already exists
                                        logger.V(5).Info(fmt.Sprintf("modifying the C-State %s", cstate.Name))
                                        newSpec := powerv1.CStatesSpec{
                                                SharedPoolCStates:     cronJob.Spec.CState.SharedPoolCStates,
                                                ExclusivePoolCStates:  cronJob.Spec.CState.ExclusivePoolCStates,
                                                IndividualCoreCStates: cronJob.Spec.CState.IndividualCoreCStates,
                                        }
                                        cstate.Spec = newSpec
                                        if err = r.Client.Update(c, cstate); err != nil </span><span class="cov0" title="0">{
                                                logger.Error(err, "cannot update the C-State")
                                                return ctrl.Result{}, err
                                        }</span>
                                }
                                <span class="cov8" title="1">logger.V(5).Info("successfully applied the C-State")</span>

                        }
                        // logic for tuning individual pods
                        <span class="cov8" title="1">if cronJob.Spec.Pods != nil </span><span class="cov8" title="1">{
                                logger.V(5).Info("changing profile for the exclusive pods")
                                workloadFrom := powerv1.PowerWorkload{}
                                workloadTo := powerv1.PowerWorkload{}
                                // looping over each pod to tune
                                for _, podInfo := range *cronJob.Spec.Pods </span><span class="cov8" title="1">{
                                        var selector labels.Selector
                                        if selector, err = metav1.LabelSelectorAsSelector(&amp;podInfo.Labels); err != nil </span><span class="cov0" title="0">{
                                                logger.Error(err, "error parsing the pod label info")
                                                return ctrl.Result{Requeue: false}, err
                                        }</span>
                                        <span class="cov8" title="1">listOptions := client.ListOptions{
                                                LabelSelector: selector,
                                        }
                                        powerpods := &amp;corev1.PodList{}
                                        if err = r.Client.List(context.TODO(), powerpods, &amp;listOptions); err != nil </span><span class="cov8" title="1">{
                                                logger.Error(err, "retrieving pods...")
                                                return ctrl.Result{}, err
                                        }</span>
                                        <span class="cov8" title="1">for _, pod := range powerpods.Items </span><span class="cov8" title="1">{
                                                podName := pod.Name
                                                podState := r.State.GetPodFromState(pod.Name, pod.Namespace)
                                                if podState.Name != pod.Name </span><span class="cov8" title="1">{
                                                        logger.Error(err, fmt.Sprintf("mismatch between the pod name and the internal state name: %s and %s", podState.Name, pod.Name))
                                                        return ctrl.Result{Requeue: false}, err
                                                }</span>
                                                <span class="cov8" title="1">var from string
                                                for i, container := range podState.Containers </span><span class="cov8" title="1">{
                                                        if container.Workload != "" </span><span class="cov8" title="1">{
                                                                from = container.Workload
                                                                podState.Containers[i].Workload = podInfo.Target + "-" + nodeName
                                                        }</span>
                                                }
                                                <span class="cov8" title="1">if err = r.State.UpdateStateGuaranteedPods(podState); err != nil </span><span class="cov0" title="0">{
                                                        logger.Error(err, "error updating the internal state")
                                                        return ctrl.Result{}, err
                                                }</span>
                                                // useful check to see if we've already retrieved the workload in an earlier loop
                                                <span class="cov8" title="1">if workloadFrom.Name != from </span><span class="cov8" title="1">{
                                                        err = r.Client.Get(context.TODO(), client.ObjectKey{
                                                                Name:      from,
                                                                Namespace: IntelPowerNamespace,
                                                        }, &amp;workloadFrom)
                                                        if err != nil </span><span class="cov8" title="1">{
                                                                logger.Error(err, fmt.Sprintf("error retrieving the workload %s", from))
                                                                return ctrl.Result{Requeue: false}, err
                                                        }</span>
                                                }
                                                // same check as before
                                                <span class="cov8" title="1">if workloadTo.Name != podInfo.Target+"-"+nodeName </span><span class="cov8" title="1">{
                                                        err = r.Client.Get(context.TODO(), client.ObjectKey{
                                                                Name:      podInfo.Target + "-" + nodeName,
                                                                Namespace: IntelPowerNamespace,
                                                        }, &amp;workloadTo)
                                                        if err != nil </span><span class="cov0" title="0">{
                                                                logger.Error(err, fmt.Sprintf("error retrieving the workload %s", (podInfo.Target+"-"+nodeName)))
                                                                return ctrl.Result{Requeue: false}, err
                                                        }</span>
                                                }
                                                <span class="cov8" title="1">var remainingFromContainers []powerv1.Container
                                                // getting the indices of containers we need to change
                                                for i := 0; i &lt; len(workloadFrom.Spec.Node.Containers); i++ </span><span class="cov8" title="1">{
                                                        container := workloadFrom.Spec.Node.Containers[i]
                                                        if container.Pod == podName </span><span class="cov8" title="1">{
                                                                logger.V(5).Info(fmt.Sprintf("Found %s for tuning", container.Pod))
                                                                // first we set the profile on the container to its new value
                                                                container.PowerProfile = podInfo.Target
                                                                // copying container to its new workload
                                                                workloadTo.Spec.Node.Containers = append(workloadTo.Spec.Node.Containers, container)
                                                                //getting cores to be removed from one workload and added to another
                                                                coresToSwap := workloadFrom.Spec.Node.Containers[i].ExclusiveCPUs
                                                                // append cores to one workload and shrink the list in the other
                                                                workloadTo.Spec.Node.CpuIds = append(workloadTo.Spec.Node.CpuIds, coresToSwap...)
                                                                updatedWorkloadCPUList := getNewWorkloadCPUList(coresToSwap, workloadFrom.Spec.Node.CpuIds, &amp;logger)
                                                                workloadFrom.Spec.Node.CpuIds = updatedWorkloadCPUList
                                                        }</span> else<span class="cov0" title="0"> {
                                                                // take note of containers that should stay in the workload
                                                                remainingFromContainers = append(remainingFromContainers, workloadFrom.Spec.Node.Containers[i])
                                                        }</span>
                                                }
                                                // some containers have moved workload
                                                <span class="cov8" title="1">if len(remainingFromContainers) != len(workloadFrom.Spec.Node.Containers) </span><span class="cov8" title="1">{
                                                        workloadFrom.Spec.Node.Containers = remainingFromContainers
                                                        //update both workloads to bring changes into affect
                                                        if err = r.Client.Update(c, &amp;workloadFrom); err != nil </span><span class="cov0" title="0">{
                                                                logger.Error(err, "cannot update the workload")
                                                                return ctrl.Result{}, err
                                                        }</span>
                                                        <span class="cov8" title="1">if err = r.Client.Update(c, &amp;workloadTo); err != nil </span><span class="cov0" title="0">{
                                                                logger.Error(err, "cannot update the workload")
                                                                return ctrl.Result{}, err
                                                        }</span>
                                                }
                                                <span class="cov8" title="1">pod.ObjectMeta.Annotations["PM-updated"] = fmt.Sprint(time.Now().Unix())
                                                pod.ObjectMeta.Annotations["PM-altered"] = podInfo.Target
                                                if err = r.Client.Update(context.TODO(), &amp;pod); err != nil </span><span class="cov0" title="0">{
                                                        logger.Error(err, "could not update the pod")
                                                        return ctrl.Result{}, err
                                                }</span>
                                        }
                                }
                        }

                        // reschedule for tomorrow
                        <span class="cov8" title="1">cronJob.Status.LastSuccessfulTime = &amp;metav1.Time{Time: time.Now().In(location)}
                        cronJob.Status.LastScheduleTime = &amp;metav1.Time{Time: time.Now().In(location)}
                        logger.V(5).Info(fmt.Sprintf("telling reconciler to wait till %s", nextWait.String()))
                        if err := r.Status().Update(c, cronJob); err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "cannot update status")
                                return ctrl.Result{}, err
                        }</span>
                        <span class="cov8" title="1">return ctrl.Result{RequeueAfter: nextWait}, nil</span>
                }

        }

        <span class="cov0" title="0">return ctrl.Result{}, nil</span>
}

// SetupWithManager sets up the controller with the Manager.
func (r *TimeOfDayCronJobReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov8" title="1">{
        // this predicate prevents an unwanted reconcile when updating a cronjob to reschedule
        predicate := predicate.GenerationChangedPredicate{}
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.TimeOfDayCronJob{}).
                WithEventFilter(predicate).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file26" style="display: none">/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
        "context"
        "fmt"
        "os"

        apierrors "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/runtime"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/predicate"

        "github.com/go-logr/logr"
        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
        "github.com/intel/power-optimization-library/pkg/power"
)

// UncoreReconciler reconciles a Uncore object
type UncoreReconciler struct {
        client.Client
        Log          logr.Logger
        Scheme       *runtime.Scheme
        PowerLibrary power.Host
}

//+kubebuilder:rbac:groups=power.intel.com,resources=uncores,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups=power.intel.com,resources=uncores/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=power.intel.com,resources=uncores/finalizers,verbs=update
//+kubebuilder:rbac:groups=security.openshift.io,resources=securitycontextconstraints,resourceNames=privileged,verbs=use

// Reconcile is part of the main kubernetes reconciliation loop which aims to
// move the current state of the cluster closer to the desired state.
// TODO(user): Modify the Reconcile function to compare the state specified by
// the Uncore object against the actual cluster state, and then
// perform operations to make the cluster state reflect the state specified by
// the user.
//
// For more details, check Reconcile and its Result here:
// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.13.1/pkg/reconcile
func (r *UncoreReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov0" title="0">{
        var err error
        nodeName := os.Getenv("NODE_NAME")
        // uncore is not for this node
        if req.Name != nodeName </span><span class="cov0" title="0">{
                return ctrl.Result{}, nil
        }</span>
        <span class="cov0" title="0">logger := r.Log.WithValues("uncore", req.NamespacedName)
        if req.Namespace != IntelPowerNamespace </span><span class="cov0" title="0">{
                err = fmt.Errorf("incorrect namespace")
                logger.Error(err, "resource is not in the power-manager namespace, ignoring")
                return ctrl.Result{Requeue: false}, err
        }</span>
        <span class="cov0" title="0">logger.Info("Reconciling uncore")
        uncore := &amp;powerv1.Uncore{}
        defer func() </span><span class="cov0" title="0">{ _ = writeUpdatedStatusErrsIfRequired(ctx, r.Status(), uncore, err) }</span>()
        // resets all values to allow for CRD updates
        <span class="cov0" title="0">err = r.PowerLibrary.Topology().SetUncore(nil)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "could not reset uncore for topology")
                return ctrl.Result{}, err
        }</span>
        <span class="cov0" title="0">for _, pkg := range *r.PowerLibrary.Topology().Packages() </span><span class="cov0" title="0">{
                if err := pkg.SetUncore(nil); err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "could not reset uncore on package")
                        return ctrl.Result{}, err
                }</span>
                <span class="cov0" title="0">for _, die := range *pkg.Dies() </span><span class="cov0" title="0">{
                        if err := die.SetUncore(nil); err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "could not reset uncore on die")
                                return ctrl.Result{}, err
                        }</span>
                }
        }
        <span class="cov0" title="0">err = r.Client.Get(context.TODO(), req.NamespacedName, uncore)
        if err != nil </span><span class="cov0" title="0">{
                // uncore deleted so we can ignore here since everything is already reset
                if apierrors.IsNotFound(err) </span><span class="cov0" title="0">{
                        return ctrl.Result{}, nil

                }</span> else<span class="cov0" title="0"> {
                        logger.Error(err, "could not retrieve uncore specification")
                        return ctrl.Result{Requeue: false}, err
                }</span>
        }
        // setting system wide uncore
        <span class="cov0" title="0">if uncore.Spec.SysMax != nil &amp;&amp; uncore.Spec.SysMin != nil </span><span class="cov0" title="0">{
                p_uncore, err := power.NewUncore(*uncore.Spec.SysMin, *uncore.Spec.SysMax)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "error creating uncore")
                        return ctrl.Result{Requeue: false}, err
                }</span>
                <span class="cov0" title="0">err = r.PowerLibrary.Topology().SetUncore(p_uncore)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "error setting uncore")
                        return ctrl.Result{Requeue: false}, err
                }</span>
        }
        // setting die/package specific uncore
        <span class="cov0" title="0">if uncore.Spec.DieSelectors != nil </span><span class="cov0" title="0">{
                for _, dieselect := range *uncore.Spec.DieSelectors </span><span class="cov0" title="0">{
                        if dieselect.Max == nil || dieselect.Min == nil || dieselect.Package == nil </span><span class="cov0" title="0">{
                                err = apierrors.NewServiceUnavailable("die selector max, min and package fields must not be empty")
                                logger.Error(err, "max, min and package values must be set for die selector")
                                return ctrl.Result{Requeue: false}, err
                        }</span>
                        <span class="cov0" title="0">p_uncore, err := power.NewUncore(*dieselect.Min, *dieselect.Max)
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Error(err, "error creating uncore")
                                return ctrl.Result{Requeue: false}, err
                        }</span>
                        // package tuning
                        <span class="cov0" title="0">if dieselect.Die == nil </span><span class="cov0" title="0">{
                                pkg := r.PowerLibrary.Topology().Package(*dieselect.Package)
                                // used to prevent invalid package or die input causing a panic
                                if pkg == nil </span><span class="cov0" title="0">{
                                        err = apierrors.NewServiceUnavailable(fmt.Sprintf("invalid package: %d", *dieselect.Package))
                                        return ctrl.Result{Requeue: false}, err
                                }</span>
                                <span class="cov0" title="0">err = pkg.SetUncore(p_uncore)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, fmt.Sprintf("error setting uncore for package %d and die %d", dieselect.Package, dieselect.Die))
                                        return ctrl.Result{Requeue: false}, err
                                }</span>
                        } else<span class="cov0" title="0"> { // die tuning
                                pkg := r.PowerLibrary.Topology().Package(*dieselect.Package)
                                if pkg == nil </span><span class="cov0" title="0">{
                                        err = apierrors.NewServiceUnavailable(fmt.Sprintf("invalid package: %d", *dieselect.Package))
                                        return ctrl.Result{Requeue: false}, err
                                }</span>
                                <span class="cov0" title="0">die := pkg.Die(*dieselect.Die)
                                if die == nil </span><span class="cov0" title="0">{
                                        err = apierrors.NewServiceUnavailable(fmt.Sprintf("invalid die: %d", *dieselect.Die))
                                        return ctrl.Result{Requeue: false}, err
                                }</span>
                                <span class="cov0" title="0">err = die.SetUncore(p_uncore)
                                if err != nil </span><span class="cov0" title="0">{
                                        logger.Error(err, fmt.Sprintf("error setting uncore for package %d and die %d", dieselect.Package, dieselect.Die))
                                        return ctrl.Result{Requeue: false}, err
                                }</span>
                        }
                }
        }
        <span class="cov0" title="0">if uncore.Spec.DieSelectors == nil &amp;&amp; uncore.Spec.SysMax == nil &amp;&amp; uncore.Spec.SysMin == nil </span><span class="cov0" title="0">{
                err = apierrors.NewServiceUnavailable("no system wide or per die min/max values were provided")
                logger.Error(err, "error setting uncore values")
                return ctrl.Result{Requeue: false}, err
        }</span>
        <span class="cov0" title="0">return ctrl.Result{}, nil</span>
}

// SetupWithManager sets up the controller with the Manager.
func (r *UncoreReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov0" title="0">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;powerv1.Uncore{}).
                WithEventFilter(predicate.GenerationChangedPredicate{}).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file27" style="display: none">package metrics

/*
#cgo CFLAGS: -I${SRCDIR}/../../e-sms/e_smi/include -I${SRCDIR}/../../e-sms/amd_hsmp
#cgo LDFLAGS: -L${SRCDIR}/../../e-sms/e_smi/lib -le_smi64
#include &lt;stdint.h&gt;
#include &lt;stdlib.h&gt;
#include "e_smi/e_smi.h"

// CGO does not support bitfields, wrappers defined below adress that
struct dimm_power_no_bitfields {
    uint16_t power;
    uint16_t update_rate;
    uint8_t dimm_addr;
};

esmi_status_t esmi_dimm_power_consumption_get_wrapper(uint8_t pkg_id, uint8_t dimm_addr,
                          struct dimm_power_no_bitfields* cgo_dimm_power) {
    struct dimm_power dimm_power = {0};
    esmi_status_t status = esmi_dimm_power_consumption_get(pkg_id, dimm_addr, &amp;dimm_power);

    if (status == 0) {
        cgo_dimm_power-&gt;power = dimm_power.power;
        cgo_dimm_power-&gt;update_rate = dimm_power.update_rate;
        cgo_dimm_power-&gt;dimm_addr = dimm_power.dimm_addr;
    }

    return status;
}

struct dimm_thermal_no_bitfields {
    uint16_t sensor;
    uint16_t update_rate;
    uint8_t dimm_addr;
    float temp;
};

esmi_status_t esmi_dimm_thermal_sensor_get_wrapper(uint8_t pkg_id, uint8_t dimm_addr,
                          struct dimm_thermal_no_bitfields* cgo_dimm_thermal) {
    struct dimm_thermal dimm_thermal = {0};
    esmi_status_t status = esmi_dimm_thermal_sensor_get(pkg_id, dimm_addr, &amp;dimm_thermal);

    if (status == 0) {
        cgo_dimm_thermal-&gt;sensor = dimm_thermal.sensor;
        cgo_dimm_thermal-&gt;update_rate = dimm_thermal.update_rate;
        cgo_dimm_thermal-&gt;dimm_addr = dimm_thermal.dimm_addr;
        cgo_dimm_thermal-&gt;temp = dimm_thermal.temp;
    }

    return status;
}
*/
import "C"

import (
        "errors"
        "fmt"
        "unsafe"

        "github.com/intel/power-optimization-library/pkg/power"

        "github.com/go-logr/logr"
)

// Enum of bandwidth types with names preserved from e_smi lib
const (
        AGG_BW int = 1 &lt;&lt; iota
        RD_BW
        WR_BW
)

const (
        microMultiplier float64 = 1e-6
        milliMultiplier float64 = 1e-3
)

var (
        // ErrESMIMetricUnavailable is returned when status code of CGO function call indicates that the
        // metric is not available to read currently, but the issue might be temporary.
        ErrESMIMetricReadFailure = errors.New("esmi metric read failed")
)

// ESMIClient implements ESMI library CGO bindings. Instance should be
// created using constructor and passed as a pointer.
type ESMIClient struct{}

// ESMIClient initializes ESMI C library and returns pointer to ESMIClient.
func NewESMIClient(log logr.Logger) (*ESMIClient, error) <span class="cov0" title="0">{
        if esmiStatus := C.esmi_init(); esmiStatus != 0 </span><span class="cov0" title="0">{
                err := fmt.Errorf("esmi initialization failed: return code %d, ESMIClient cannot be created", esmiStatus)
                log.Error(err, "")
                return nil, err
        }</span>

        <span class="cov0" title="0">return &amp;ESMIClient{}, nil</span>
}

func (e *ESMIClient) GetCoreEnergy(core power.Core) (float64, error) <span class="cov0" title="0">{
        var coreEnergy uint64
        if esmiStatus := C.esmi_core_energy_get(
                C.uint32_t(core.GetID()),
                (*C.uint64_t)(unsafe.Pointer(&amp;coreEnergy)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        // Convert result from microJoules to Joules
        <span class="cov0" title="0">return float64(coreEnergy) * microMultiplier, nil</span>
}

func (e *ESMIClient) GetPackageEnergy(pkg power.Package) (float64, error) <span class="cov0" title="0">{
        var pkgEnergy uint64
        if esmiStatus := C.esmi_socket_energy_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint64_t)(unsafe.Pointer(&amp;pkgEnergy)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        // Convert result from microJoules to Joules
        <span class="cov0" title="0">return float64(pkgEnergy) * microMultiplier, nil</span>
}

func (e *ESMIClient) GetDataFabricClock(pkg power.Package) (uint32, error) <span class="cov0" title="0">{
        var fabricClock, dataClock uint32
        if esmiStatus := C.esmi_fclk_mclk_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;fabricClock)),
                (*C.uint32_t)(unsafe.Pointer(&amp;dataClock)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return fabricClock, nil</span>
}

func (e *ESMIClient) GetMemoryClock(pkg power.Package) (uint32, error) <span class="cov0" title="0">{
        var fabricClock, dataClock uint32
        if esmiStatus := C.esmi_fclk_mclk_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;fabricClock)),
                (*C.uint32_t)(unsafe.Pointer(&amp;dataClock)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return dataClock, nil</span>
}

func (e *ESMIClient) GetCoreClockThrottleLimit(pkg power.Package) (uint32, error) <span class="cov0" title="0">{
        var cclk uint32
        if esmiStatus := C.esmi_cclk_limit_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;cclk)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return cclk, nil</span>
}

func (e *ESMIClient) GetPackageFreqLimit(pkg power.Package) (uint16, error) <span class="cov0" title="0">{
        var freq uint16
        // size 8 is taken from esmi_library repository
        cArr := C.malloc(C.size_t(8) * C.size_t(unsafe.Sizeof(uintptr(0))))
        defer C.free(unsafe.Pointer(cArr))

        if esmiStatus := C.esmi_socket_current_active_freq_limit_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint16_t)(unsafe.Pointer(&amp;freq)),
                ((**C.char)(cArr)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return freq, nil</span>
}

func (e *ESMIClient) GetPackageMinFreq(pkg power.Package) (uint16, error) <span class="cov0" title="0">{
        var fMin, fMax uint16

        if esmiStatus := C.esmi_socket_freq_range_get(
                C.uint8_t(pkg.GetID()),
                (*C.uint16_t)(unsafe.Pointer(&amp;fMax)),
                (*C.uint16_t)(unsafe.Pointer(&amp;fMin)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return fMin, nil</span>
}

func (e *ESMIClient) GetPackageMaxFreq(pkg power.Package) (uint16, error) <span class="cov0" title="0">{
        var fMin, fMax uint16

        if esmiStatus := C.esmi_socket_freq_range_get(
                C.uint8_t(pkg.GetID()),
                (*C.uint16_t)(unsafe.Pointer(&amp;fMax)),
                (*C.uint16_t)(unsafe.Pointer(&amp;fMin)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return fMax, nil</span>
}

func (e *ESMIClient) GetCoreFreqLimit(core power.Core) (uint32, error) <span class="cov0" title="0">{
        var freq uint32
        if esmiStatus := C.esmi_current_freq_limit_core_get(
                C.uint32_t(core.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;freq)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return freq, nil</span>
}

func (e *ESMIClient) GetRailFreqLimitPolicy(pkg power.Package) (uint8, error) <span class="cov0" title="0">{
        var railPolicy bool

        if esmiStatus := C.esmi_cpurail_isofreq_policy_get(
                C.uint8_t(pkg.GetID()),
                (*C.bool)(unsafe.Pointer(&amp;railPolicy)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">if railPolicy </span><span class="cov0" title="0">{
                return 1, nil
        }</span>
        <span class="cov0" title="0">return 0, nil</span>
}

func (e *ESMIClient) GetDFCStateEnablingControl(pkg power.Package) (uint8, error) <span class="cov0" title="0">{
        var dfCStateControl bool

        if esmiStatus := C.esmi_dfc_ctrl_setting_get(
                C.uint8_t(pkg.GetID()),
                (*C.bool)(unsafe.Pointer(&amp;dfCStateControl)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">if dfCStateControl </span><span class="cov0" title="0">{
                return 1, nil
        }</span>
        <span class="cov0" title="0">return 0, nil</span>
}

func (e *ESMIClient) GetPackagePower(pkg power.Package) (float64, error) <span class="cov0" title="0">{
        var pkgPower uint32
        if esmiStatus := C.esmi_socket_power_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;pkgPower)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        // Convert result from milliwatts to watts.
        <span class="cov0" title="0">return float64(pkgPower) * milliMultiplier, nil</span>
}

func (e *ESMIClient) GetPackagePowerCap(pkg power.Package) (float64, error) <span class="cov0" title="0">{
        var pkgPowerCap uint32
        if esmiStatus := C.esmi_socket_power_cap_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;pkgPowerCap)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        // Convert result from milliwatts to watts.
        <span class="cov0" title="0">return float64(pkgPowerCap) * milliMultiplier, nil</span>
}

func (e *ESMIClient) GetPackagePowerMaxCap(pkg power.Package) (float64, error) <span class="cov0" title="0">{
        var pkgPowerMaxCap uint32
        if esmiStatus := C.esmi_socket_power_cap_max_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;pkgPowerMaxCap)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        // Convert result from milliwatts to watts.
        <span class="cov0" title="0">return float64(pkgPowerMaxCap) * milliMultiplier, nil</span>
}

func (e *ESMIClient) GetPackagePowerEfficiencyMode(pkg power.Package) (uint8, error) <span class="cov0" title="0">{
        var pkgPowerEffMode uint8
        if esmiStatus := C.esmi_pwr_efficiency_mode_get(
                C.uint8_t(pkg.GetID()),
                (*C.uint8_t)(unsafe.Pointer(&amp;pkgPowerEffMode)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return pkgPowerEffMode, nil</span>
}

func (e *ESMIClient) GetCoreBoostLimit(core power.Core) (uint32, error) <span class="cov0" title="0">{
        var pBoostLimit uint32
        if esmiStatus := C.esmi_core_boostlimit_get(
                C.uint32_t(core.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;pBoostLimit)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return pBoostLimit, nil</span>
}

func (e *ESMIClient) GetPackageC0Residency(pkg power.Package) (uint32, error) <span class="cov0" title="0">{
        var c0Residency uint32
        if esmiStatus := C.esmi_socket_c0_residency_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;c0Residency)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return c0Residency, nil</span>
}

func (e *ESMIClient) GetPackageTemp(pkg power.Package) (float64, error) <span class="cov0" title="0">{
        var pkgTemp uint32
        if esmiStatus := C.esmi_socket_temperature_get(
                C.uint32_t(pkg.GetID()),
                (*C.uint32_t)(unsafe.Pointer(&amp;pkgTemp)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        // Convert result from millicelsius to celsius.
        <span class="cov0" title="0">return float64(pkgTemp) * milliMultiplier, nil</span>
}

func (e *ESMIClient) GetDDRBandwidthUtil(pkg power.Package) (uint32, error) <span class="cov0" title="0">{
        ddrBW := C.struct_ddr_bw_metrics{
                max_bw:       C.uint32_t(0),
                utilized_bw:  C.uint32_t(0),
                utilized_pct: C.uint32_t(0),
        }

        if esmiStatus := C.esmi_ddr_bw_get(
                C.uint8_t(pkg.GetID()),
                &amp;ddrBW,
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return uint32(ddrBW.utilized_bw), nil</span>
}

func (e *ESMIClient) GetDDRBandwidthUtilPercent(pkg power.Package) (uint32, error) <span class="cov0" title="0">{
        ddrBW := C.struct_ddr_bw_metrics{
                max_bw:       C.uint32_t(0),
                utilized_bw:  C.uint32_t(0),
                utilized_pct: C.uint32_t(0),
        }

        if esmiStatus := C.esmi_ddr_bw_get(
                C.uint8_t(pkg.GetID()),
                &amp;ddrBW,
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return uint32(ddrBW.utilized_pct), nil</span>
}

func (e *ESMIClient) GetDIMMPower(pkg power.Package, dimmAddr uint8) (float64, error) <span class="cov0" title="0">{
        dimmPower := C.struct_dimm_power_no_bitfields{
                power:       C.uint16_t(0),
                update_rate: C.uint16_t(0),
                dimm_addr:   C.uint8_t(0),
        }

        if esmiStatus := C.esmi_dimm_power_consumption_get_wrapper(
                C.uint8_t(pkg.GetID()),
                C.uint8_t(dimmAddr),
                &amp;dimmPower,
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        // update_rate == 0 is indication of metric unavailability on the system
        <span class="cov0" title="0">if dimmPower.update_rate == 0 </span><span class="cov0" title="0">{
                return 0, ErrMetricMissing
        }</span>

        <span class="cov0" title="0">return float64(dimmPower.power) * milliMultiplier, nil</span>
}

func (e *ESMIClient) GetDIMMTemp(pkg power.Package, dimmAddr uint8) (float32, error) <span class="cov0" title="0">{
        dimmThermal := C.struct_dimm_thermal_no_bitfields{
                sensor:      C.uint16_t(0),
                update_rate: C.uint16_t(0),
                dimm_addr:   C.uint8_t(0),
                temp:        C.float(0),
        }

        if esmiStatus := C.esmi_dimm_thermal_sensor_get_wrapper(
                C.uint8_t(pkg.GetID()),
                C.uint8_t(dimmAddr),
                &amp;dimmThermal,
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        // update_rate == 0 is indication of metric unavailability on the system
        <span class="cov0" title="0">if dimmThermal.update_rate == 0 </span><span class="cov0" title="0">{
                return 0, ErrMetricMissing
        }</span>

        <span class="cov0" title="0">return float32(dimmThermal.temp), nil</span>
}

func (e *ESMIClient) GetLCLKDPMMaxLevel(pkg power.Package, nbioID uint8) (uint8, error) <span class="cov0" title="0">{
        dpmLevel := C.struct_dpm_level{
                max_dpm_level: C.uint8_t(0),
                min_dpm_level: C.uint8_t(0),
        }

        if esmiStatus := C.esmi_socket_lclk_dpm_level_get(
                C.uint8_t(pkg.GetID()),
                C.uint8_t(nbioID),
                &amp;dpmLevel,
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return uint8(dpmLevel.max_dpm_level), nil</span>
}

func (e *ESMIClient) GetLCLKDPMMinLevel(pkg power.Package, nbioID uint8) (uint8, error) <span class="cov0" title="0">{
        dpmLevel := C.struct_dpm_level{
                max_dpm_level: C.uint8_t(0),
                min_dpm_level: C.uint8_t(0),
        }

        if esmiStatus := C.esmi_socket_lclk_dpm_level_get(
                C.uint8_t(pkg.GetID()),
                C.uint8_t(nbioID),
                &amp;dpmLevel,
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return uint8(dpmLevel.min_dpm_level), nil</span>
}

func (e *ESMIClient) GetIOLinkBandwidthUtil(pkg power.Package, linkName string) (uint32, error) <span class="cov0" title="0">{
        var ioBW uint32
        linkIDBandwidthType := C.struct_link_id_bw_type{
                // Only aggregate bandwidth type is supported for this metric
                bw_type:   C.io_bw_encoding(AGG_BW),
                link_name: C.CString(linkName),
        }

        if esmiStatus := C.esmi_current_io_bandwidth_get(
                C.uint8_t(pkg.GetID()),
                linkIDBandwidthType,
                (*C.uint32_t)(unsafe.Pointer(&amp;ioBW)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return ioBW, nil</span>
}

func (e *ESMIClient) GetxGMIAggregateBandwidthUtil(linkName string) (uint32, error) <span class="cov0" title="0">{
        var xGMIBW uint32
        linkIDBandwidthType := C.struct_link_id_bw_type{
                bw_type:   C.io_bw_encoding(AGG_BW),
                link_name: C.CString(linkName),
        }

        if esmiStatus := C.esmi_current_xgmi_bw_get(
                linkIDBandwidthType,
                (*C.uint32_t)(unsafe.Pointer(&amp;xGMIBW)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return xGMIBW, nil</span>
}

func (e *ESMIClient) GetxGMIReadBandwidthUtil(linkName string) (uint32, error) <span class="cov0" title="0">{
        var xGMIBW uint32
        linkIDBandwidthType := C.struct_link_id_bw_type{
                bw_type:   C.io_bw_encoding(RD_BW),
                link_name: C.CString(linkName),
        }

        if esmiStatus := C.esmi_current_xgmi_bw_get(
                linkIDBandwidthType,
                (*C.uint32_t)(unsafe.Pointer(&amp;xGMIBW)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return xGMIBW, nil</span>
}

func (e *ESMIClient) GetxGMIWriteBandwidthUtil(linkName string) (uint32, error) <span class="cov0" title="0">{
        var xGMIBW uint32
        linkIDBandwidthType := C.struct_link_id_bw_type{
                bw_type:   C.io_bw_encoding(WR_BW),
                link_name: C.CString(linkName),
        }

        if esmiStatus := C.esmi_current_xgmi_bw_get(
                linkIDBandwidthType,
                (*C.uint32_t)(unsafe.Pointer(&amp;xGMIBW)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return xGMIBW, nil</span>
}

func (e *ESMIClient) GetCPUFamily() (uint32, error) <span class="cov0" title="0">{
        var cpuFamily uint32
        if esmiStatus := C.esmi_cpu_family_get(
                (*C.uint32_t)(unsafe.Pointer(&amp;cpuFamily)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return cpuFamily, nil</span>
}

func (e *ESMIClient) GetCPUModel() (uint32, error) <span class="cov0" title="0">{
        var cpuModel uint32
        if esmiStatus := C.esmi_cpu_model_get(
                (*C.uint32_t)(unsafe.Pointer(&amp;cpuModel)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return cpuModel, nil</span>
}

func (e *ESMIClient) GetNumberOfCPUsPerCore() (uint32, error) <span class="cov0" title="0">{
        var threadsPerCore uint32
        if esmiStatus := C.esmi_threads_per_core_get(
                (*C.uint32_t)(unsafe.Pointer(&amp;threadsPerCore)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return threadsPerCore, nil</span>
}

func (e *ESMIClient) GetNumberOfCPUs() (uint32, error) <span class="cov0" title="0">{
        var cpusTotal uint32
        if esmiStatus := C.esmi_number_of_cpus_get(
                (*C.uint32_t)(unsafe.Pointer(&amp;cpusTotal)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return cpusTotal, nil</span>
}

func (e *ESMIClient) GetNumberOfPackages() (uint32, error) <span class="cov0" title="0">{
        var pkgsTotal uint32
        if esmiStatus := C.esmi_number_of_sockets_get(
                (*C.uint32_t)(unsafe.Pointer(&amp;pkgsTotal)),
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return pkgsTotal, nil</span>
}

func (e *ESMIClient) GetSMUFWMajorVersion() (uint8, error) <span class="cov0" title="0">{
        fwVersion := C.struct_smu_fw_version{
                debug:  C.uint8_t(0),
                minor:  C.uint8_t(0),
                major:  C.uint8_t(0),
                unused: C.uint8_t(0),
        }

        if esmiStatus := C.esmi_smu_fw_version_get(
                &amp;fwVersion,
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return uint8(fwVersion.major), nil</span>
}

func (e *ESMIClient) GetSMUFWMinorVersion() (uint8, error) <span class="cov0" title="0">{
        fwVersion := C.struct_smu_fw_version{
                debug:  C.uint8_t(0),
                minor:  C.uint8_t(0),
                major:  C.uint8_t(0),
                unused: C.uint8_t(0),
        }

        if esmiStatus := C.esmi_smu_fw_version_get(
                &amp;fwVersion,
        ); esmiStatus != 0 </span><span class="cov0" title="0">{
                return 0, mapESMIError(esmiStatus)
        }</span>

        <span class="cov0" title="0">return uint8(fwVersion.minor), nil</span>
}

// mapESMIError maps esmi_status_t (CGO functions return code), which is integer, to golang errors.
func mapESMIError(esmiErr C.esmi_status_t) error <span class="cov0" title="0">{
        switch esmiErr </span>{
        // Errors numbers which indicate metric won't be readable during process lifitme.
        case C.ESMI_NO_ENERGY_DRV, C.ESMI_NO_MSR_DRV, C.ESMI_NO_HSMP_DRV, C.ESMI_NO_HSMP_SUP, C.ESMI_NO_DRV,
                C.ESMI_NOT_SUPPORTED, C.ESMI_NOT_INITIALIZED, C.ESMI_FILE_ERROR, C.ESMI_INVALID_INPUT, C.ESMI_PERMISSION,
                C.ESMI_FILE_NOT_FOUND, C.ESMI_NO_HSMP_MSG_SUP:<span class="cov0" title="0">
                return fmt.Errorf("%w: esmi function returned %d status code", ErrMetricMissing, esmiErr)</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("%w: esmi function returned %d status code", ErrESMIMetricReadFailure, esmiErr)</span>
        }
}
</pre>
		
		<pre class="file" id="file28" style="display: none">package metrics

import (
        "context"
        "errors"
        "fmt"
        "math"
        "sync"
        "time"

        "github.com/go-logr/logr"
        "github.com/intel/kubernetes-power-manager/pkg/util"
        "github.com/intel/power-optimization-library/pkg/power"
)

// Func definitions for unit testing
var (
        newMSRReaderFunc func(int) (msrReader, error) = newMSRReader
)

// MSR offsets definitions
const (
        tscOffset   uint64 = 0x00000010
        mperfOffset uint64 = 0x000000E7
        aperfOffset uint64 = 0x000000E8

        raplOffset                uint64 = 0xC0010299
        totalPkgEnergyTicksOfsset uint64 = 0xC001029B
        totalCoreEnergyOffset     uint64 = 0xC001029A
)

const (
        workersInterval time.Duration = 1 * time.Second
)

var (
        // ErrCStateResidencyInsufficientData is returned when msrReader.read() method returned error
        // during runtime. We assume that the issue is temporary since MSR file handle for that CPU
        // was created properly and was readable.
        ErrCStateResidencyInsufficientData error = errors.New("insufficient data to calculate C-state residency")

        // ErrCStateResidencyNotYetCalculated is returned when trying to read C0 and Cx residency values when they
        // were not yet calculated (meaning time period of 2 intervals has not yet passed since client creation).
        ErrCStateResidencyNotYetCalculated error = errors.New("not yet calculated C-state residency")
)

// MSRClient is thread safe client to MSR pseudofiles located by default in
// /dev/cpuX/ directories. Single instance should be created using constructor
// and passed as a pointer.
type MSRClient struct {
        readers map[uint]msrReader
        host    power.Host
        log     logr.Logger

        workersCancel       context.CancelFunc
        workersWaitGroup    sync.WaitGroup
        c0ResPercentResults sync.Map
}

// MSRClient opens handles to all CPUs found on the system during power-library
// initialization. Handles need to be closed after client is no longer in use.
// Client also starts worker goroutine per CPU to constantly calculate C-state
// residency of that core in specified interval (set as const in in metrics package).
// host is instance of power-library Host that exposes system topology.
// Returns pointer to MSRClient that should be the only instance created within binary.
func NewMSRClient(log logr.Logger, host power.Host) *MSRClient <span class="cov8" title="1">{
        ctx, cancel := context.WithCancel(context.Background())
        msr := MSRClient{
                readers:       make(map[uint]msrReader),
                host:          host,
                log:           log,
                workersCancel: cancel,
        }

        msr.addReaders()
        msr.startC0ResidencyWorkers(ctx)
        msr.log.V(4).Info("New MSRClient created")

        return &amp;msr
}</span>

type c0ResidencyResult struct {
        value uint8
        err   error
}

func (msr *MSRClient) Close() <span class="cov8" title="1">{
        msr.log.V(4).Info("Closing all registered readers")
        for cpuId, reader := range msr.readers </span><span class="cov8" title="1">{
                if err := reader.close(); err != nil </span><span class="cov0" title="0">{
                        msr.log.V(5).Info(fmt.Sprintf("error while closing reader, err: %v", err), "cpu id", cpuId)
                }</span>
        }

        <span class="cov8" title="1">msr.log.V(4).Info("Closing all C-state residency worker goroutines")
        msr.workersCancel()
        msr.workersWaitGroup.Wait()</span>
}

func (msr *MSRClient) GetC0ResidencyPercent(cpu power.Cpu) (uint8, error) <span class="cov8" title="1">{
        logger := msr.log.WithValues("cpu", cpu.GetID())

        result, ok := msr.c0ResPercentResults.Load(cpu.GetID())
        if !ok </span><span class="cov0" title="0">{
                // Map keys are added on client creation so this branch should not happen at all.
                logger.V(5).Info(
                        fmt.Sprintf("unexpected behavior, ensure MSRClient was created using constructor, err: %v",
                                ErrMetricMissing),
                )
                return 0, ErrMetricMissing
        }</span>
        <span class="cov8" title="1">r := result.(c0ResidencyResult)

        return r.value, r.err</span>
}

func (msr *MSRClient) GetCxResidencyPercent(cpu power.Cpu) (uint8, error) <span class="cov0" title="0">{
        logger := msr.log.WithValues("cpu", cpu.GetID())

        result, ok := msr.c0ResPercentResults.Load(cpu.GetID())
        if !ok </span><span class="cov0" title="0">{
                // Map keys are added on client creation so this branch should not happen at all.
                logger.V(5).Info(
                        fmt.Sprintf("unexpected behavior, ensure MSRClient was created using constructor, err: %v",
                                ErrMetricMissing),
                )
                return 0, ErrMetricMissing
        }</span>
        <span class="cov0" title="0">r := result.(c0ResidencyResult)

        return 100 - r.value, r.err</span>
}

func (msr *MSRClient) GetPackageEnergyConsumption(pkg power.Package) (float64, error) <span class="cov0" title="0">{
        cpu := (*pkg.CPUs())[0]

        energyTicks, err := msr.readMetric(cpu.GetID(), totalPkgEnergyTicksOfsset, pkg.GetID(), packageLogKey)
        if err != nil </span><span class="cov0" title="0">{
                return 0.0, err
        }</span>
        <span class="cov0" title="0">energyUnits, err := msr.getRAPLEnergyUnit(cpu)
        if err != nil </span><span class="cov0" title="0">{
                return 0.0, err
        }</span>
        <span class="cov0" title="0">joulesConsumed := float64(energyTicks) * energyUnits

        return joulesConsumed, nil</span>
}

func (msr *MSRClient) GetCoreEnergyConsumption(core power.Core) (float64, error) <span class="cov0" title="0">{
        cpu := (*core.CPUs())[0]

        energyTicks, err := msr.readMetric(cpu.GetID(), totalCoreEnergyOffset, core.GetID(), packageLogKey)
        if err != nil </span><span class="cov0" title="0">{
                return 0.0, err
        }</span>
        <span class="cov0" title="0">energyUnits, err := msr.getRAPLEnergyUnit(cpu)
        if err != nil </span><span class="cov0" title="0">{
                return 0.0, err
        }</span>
        <span class="cov0" title="0">joulesConsumed := float64(energyTicks) * energyUnits

        return joulesConsumed, nil</span>
}

func (msr *MSRClient) getRAPLEnergyUnit(cpu power.Cpu) (float64, error) <span class="cov8" title="1">{
        raplMeta, err := msr.readMetric(cpu.GetID(), raplOffset, cpu.GetID(), cpuLogKey)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>
        <span class="cov8" title="1">const energyUnitBits uint64 = 0b0001111100000000
        exponent := (raplMeta &amp; energyUnitBits) &gt;&gt; 8

        return 1 / math.Pow(2, float64(exponent)), nil</span>
}

// scopeid and scopeName are passed for user friendly logs
func (msr *MSRClient) readMetric(cpu uint, offset uint64, scopeId uint, scopeName string) (uint64, error) <span class="cov8" title="1">{
        logger := msr.log.WithValues("cpu", cpu, "scope id", scopeId, "scope name", scopeName)

        reader, ok := msr.readers[cpu]
        if !ok </span><span class="cov8" title="1">{
                logger.V(5).Info(fmt.Sprintf("err: %v", ErrMetricMissing))
                return 0, ErrMetricMissing
        }</span>
        <span class="cov8" title="1">val, err := reader.read(offset)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov8" title="1">return val, nil</span>
}

func (msr *MSRClient) addReaders() <span class="cov8" title="1">{
        util.IterateOverCPUs(msr.host, func(cpu power.Cpu, _ power.Core, _ power.Die, _ power.Package) </span><span class="cov8" title="1">{
                logger := msr.log.WithValues("cpu", cpu.GetID())

                reader, err := newMSRReaderFunc(int(cpu.GetID()))
                if err != nil </span><span class="cov8" title="1">{
                        logger.Error(err, "error while creating event reader")
                        return
                }</span>
                <span class="cov8" title="1">msr.readers[cpu.GetID()] = reader

                logger.V(5).Info("Initialized reader")</span>
        })
}

// startC0ResidencyWorkers first checks if MSR readers needed for workers calculations are readable.
// If yes, it starts goroutine for each CPU, if not, it logs an error.
func (msr *MSRClient) startC0ResidencyWorkers(ctx context.Context) <span class="cov8" title="1">{
        util.IterateOverCPUs(msr.host, func(cpu power.Cpu, _ power.Core, _ power.Die, _ power.Package) </span><span class="cov8" title="1">{
                logger := msr.log.WithValues("cpu", cpu.GetID())

                // Test if MSR readers are active before starting worker goroutine
                _, errTsc := msr.readMetric(cpu.GetID(), tscOffset, cpu.GetID(), cpuLogKey)
                _, errMperf := msr.readMetric(cpu.GetID(), mperfOffset, cpu.GetID(), cpuLogKey)
                if errMperf == ErrMetricMissing || errTsc == ErrMetricMissing </span><span class="cov8" title="1">{
                        logger.Error(ErrMetricMissing, "not starting C-state residency worker goroutine")
                        msr.c0ResPercentResults.Store(cpu.GetID(), c0ResidencyResult{err: ErrMetricMissing})
                        return
                }</span>

                <span class="cov8" title="1">msr.workersWaitGroup.Add(1)
                msr.c0ResPercentResults.Store(cpu.GetID(), c0ResidencyResult{err: ErrCStateResidencyNotYetCalculated})
                go msr.c0ResidencyWorker(cpu, ctx)
                logger.V(5).Info("Started C-state residency worker goroutine")</span>
        })
}

// c0ResidencyWorker calculates percent of CPU C0-state residency in last time interval (specified by
// const variable). It takes as arguments CPU that will be monitored and context - used only for cancellation.
// At the end of each calculation loop it updates the value stored in sync.Map (client field) for that CPU.
// It pushes first value after 2 intervals, and then updates it every interval. Worker supports error handling.
func (msr *MSRClient) c0ResidencyWorker(cpu power.Cpu, ctx context.Context) <span class="cov8" title="1">{
        defer msr.workersWaitGroup.Done()
        logger := msr.log.WithValues("cpu", cpu.GetID(), "worker", "C-state residency")

        var (
                tsc      uint64
                tscErr   error = ErrCStateResidencyNotYetCalculated
                mperf    uint64
                mperfErr = ErrCStateResidencyNotYetCalculated

                prevTSC      uint64
                prevTSCErr   error
                prevMPERF    uint64
                prevMPERFErr error
        )

        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov8" title="1">
                        logger.V(5).Info("cancellation signal received, exiting work")
                        return</span>
                case &lt;-time.After(workersInterval):<span class="cov8" title="1">
                        prevTSC, prevTSCErr = tsc, tscErr
                        if tsc, tscErr = msr.readMetric(cpu.GetID(), tscOffset, cpu.GetID(), cpuLogKey); tscErr != nil </span><span class="cov0" title="0">{
                                msr.c0ResPercentResults.Store(cpu.GetID(), c0ResidencyResult{err: tscErr})
                                logger.V(5).Info(
                                        fmt.Sprintf("error retrieving TSC value, continuing to next iteration, err: %v", tscErr),
                                )
                                continue</span>
                        }

                        <span class="cov8" title="1">prevMPERF, prevMPERFErr = mperf, mperfErr
                        if mperf, mperfErr = msr.readMetric(cpu.GetID(), mperfOffset, cpu.GetID(), cpuLogKey); mperfErr != nil </span><span class="cov0" title="0">{
                                msr.c0ResPercentResults.Store(cpu.GetID(), c0ResidencyResult{err: mperfErr})
                                logger.V(5).Info(
                                        fmt.Sprintf("error retrieving MPERF value, continuing to next iteration, err: %v", mperfErr),
                                )
                                continue</span>
                        }

                        // tsc &lt;= prevTSC check is there to prevent dividing by 0 that would happen
                        // when 2 consecutive TSC reads will have the same value. We also handle
                        // situation in which counters were reset and prev is bigger than current.
                        // Both situation very unlikely to happen.
                        <span class="cov8" title="1">if prevTSCErr != nil || prevMPERFErr != nil || tsc &lt;= prevTSC || mperf &lt; prevMPERF </span><span class="cov8" title="1">{
                                continue</span>
                        }

                        <span class="cov8" title="1">c0ResPercentFloat := (float64(mperf-prevMPERF) / float64(tsc-prevTSC)) * 100
                        // Both TSC and MPERF counters are going up by a lot every millisecond. MPERF is retrieved after TSC so
                        // in situation when C0-state residency is close to 100% those nanoseconds between retrieval of both values
                        // might cause MPERF &gt; TSC which will yield value &gt;100%. The same could happen when C0-state residency
                        // is close to 0%, then the calculated value will be a little larger than actual. Since we want to return %,
                        // and the calcuations cannot be fully accurate, we round to integers.
                        c0ResPercent := uint8(math.Round(c0ResPercentFloat))

                        msr.c0ResPercentResults.Store(cpu.GetID(), c0ResidencyResult{value: c0ResPercent})</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file29" style="display: none">package metrics

import (
        "encoding/binary"
        "fmt"
        "os"
        "path/filepath"
        "strconv"
)

const (
        msrDirPath       string = "/dev/cpu/"
        msrFilename      string = "msr"
        msrReaderBufSize int    = 8
)

type msrReader interface {
        read(offset uint64) (uint64, error)
        close() error
}

type msrReaderImpl struct {
        cpu  int
        file *os.File
}

func newMSRReader(cpu int) (msrReader, error) <span class="cov0" title="0">{
        msrFile, err := os.OpenFile(
                filepath.Join(msrDirPath, strconv.Itoa(cpu), msrFilename),
                os.O_RDONLY,
                0660,
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to open MSR file for CPU %d: %w", cpu, err)
        }</span>

        <span class="cov0" title="0">return &amp;msrReaderImpl{cpu: cpu, file: msrFile}, nil</span>
}

func (m *msrReaderImpl) read(offset uint64) (uint64, error) <span class="cov0" title="0">{
        buf := make([]byte, perfEventReaderBufSize)
        if _, err := m.file.ReadAt(buf, int64(offset)); err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to read properly opened MSR file for CPU %d: %w", m.cpu, err)
        }</span>

        <span class="cov0" title="0">return binary.LittleEndian.Uint64(buf), nil</span>
}

func (m *msrReaderImpl) close() error <span class="cov0" title="0">{
        return m.file.Close()
}</span>
</pre>
		
		<pre class="file" id="file30" style="display: none">package metrics

import (
        "fmt"
        "math"
        "os"
        "path/filepath"
        "strconv"
        "strings"

        "github.com/go-logr/logr"
        "github.com/intel/kubernetes-power-manager/pkg/util"
        "github.com/intel/power-optimization-library/pkg/power"
        "golang.org/x/sys/unix"
)

// Func definitions for unit testing
var (
        newDefaultPerfEventReaderFunc func(int, int, int) (perfEventReader, error) = newDefaultPerfEventReader
)

// Helper map for iterations, new supported hardware measurements must be added here
var hwPerfEvents = map[int][]int{
        perCPU: {
                unix.PERF_COUNT_HW_CPU_CYCLES,
                unix.PERF_COUNT_HW_INSTRUCTIONS,
                unix.PERF_COUNT_HW_CACHE_REFERENCES,
                unix.PERF_COUNT_HW_CACHE_MISSES,
                unix.PERF_COUNT_HW_BRANCH_INSTRUCTIONS,
                unix.PERF_COUNT_HW_BRANCH_MISSES,
                // not verified, not supported by linux kernel as of 2024/11
                unix.PERF_COUNT_HW_BUS_CYCLES,
                unix.PERF_COUNT_HW_STALLED_CYCLES_FRONTEND,
                // not verified, not supported by linux kernel as of 2024/11
                unix.PERF_COUNT_HW_STALLED_CYCLES_BACKEND,
                // not verified, not supported by linux kernel as of 2024/11
                unix.PERF_COUNT_HW_REF_CPU_CYCLES,
        },
}

// Helper map for iterations, new supported software measurements must be added here.
var swPerfEvents = map[int][]int{
        perCPU: {
                unix.PERF_COUNT_SW_BPF_OUTPUT,
        },
}

// nolint: unused
// Cache perf events helper consts.
// See PERF_TYPE_HW_CACHE section in manpage https://man7.org/linux/man-pages/man2/perf_event_open.2.html for more info.
const (
        cacheL1DReadAccesses     = unix.PERF_COUNT_HW_CACHE_L1D | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheL1DReadMisses       = unix.PERF_COUNT_HW_CACHE_L1D | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheL1DWriteAccesses    = unix.PERF_COUNT_HW_CACHE_L1D | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheL1DWriteMisses      = unix.PERF_COUNT_HW_CACHE_L1D | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheL1DPrefetchAccesses = unix.PERF_COUNT_HW_CACHE_L1D | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheL1DPrefetchMisses   = unix.PERF_COUNT_HW_CACHE_L1D | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16

        cacheL1IReadAccesses     = unix.PERF_COUNT_HW_CACHE_L1I | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheL1IReadMisses       = unix.PERF_COUNT_HW_CACHE_L1I | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheL1IWriteAccesses    = unix.PERF_COUNT_HW_CACHE_L1I | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheL1IWriteMisses      = unix.PERF_COUNT_HW_CACHE_L1I | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheL1IPrefetchAccesses = unix.PERF_COUNT_HW_CACHE_L1I | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheL1IPrefetchMisses   = unix.PERF_COUNT_HW_CACHE_L1I | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16

        cacheBPUReadAccesses     = unix.PERF_COUNT_HW_CACHE_BPU | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheBPUReadMisses       = unix.PERF_COUNT_HW_CACHE_BPU | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheBPUWriteAccesses    = unix.PERF_COUNT_HW_CACHE_BPU | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheBPUWriteMisses      = unix.PERF_COUNT_HW_CACHE_BPU | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheBPUPrefetchAccesses = unix.PERF_COUNT_HW_CACHE_BPU | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheBPUPrefetchMisses   = unix.PERF_COUNT_HW_CACHE_BPU | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16

        cacheNodeReadAccesses     = unix.PERF_COUNT_HW_CACHE_NODE | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheNodeReadMisses       = unix.PERF_COUNT_HW_CACHE_NODE | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheNodeWriteAccesses    = unix.PERF_COUNT_HW_CACHE_NODE | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheNodeWriteMisses      = unix.PERF_COUNT_HW_CACHE_NODE | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheNodePrefetchAccesses = unix.PERF_COUNT_HW_CACHE_NODE | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheNodePrefetchMisses   = unix.PERF_COUNT_HW_CACHE_NODE | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16

        cacheLLReadAccesses     = unix.PERF_COUNT_HW_CACHE_LL | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheLLReadMisses       = unix.PERF_COUNT_HW_CACHE_LL | unix.PERF_COUNT_HW_CACHE_OP_READ&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheLLWriteAccesses    = unix.PERF_COUNT_HW_CACHE_LL | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheLLWriteMisses      = unix.PERF_COUNT_HW_CACHE_LL | unix.PERF_COUNT_HW_CACHE_OP_WRITE&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
        cacheLLPrefetchAccesses = unix.PERF_COUNT_HW_CACHE_LL | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_ACCESS&lt;&lt;16
        cacheLLPrefetchMisses   = unix.PERF_COUNT_HW_CACHE_LL | unix.PERF_COUNT_HW_CACHE_OP_PREFETCH&lt;&lt;8 | unix.PERF_COUNT_HW_CACHE_RESULT_MISS&lt;&lt;16
)

// Helper map for iterations, new supported cache measurements must be added here.
var cachePerfEvents = map[int][]int{
        perCPU: {
                cacheL1DReadAccesses,
                cacheL1DReadMisses,
                cacheL1DWriteAccesses, // not verified, not supported by linux kernel as of 2024/11
                cacheL1DWriteMisses,   // not verified, not supported by linux kernel as of 2024/11
                cacheL1DPrefetchAccesses,
                cacheL1DPrefetchMisses, // not verified, not supported by linux kernel as of 2024/11

                cacheL1IReadAccesses,
                cacheL1IReadMisses,
                cacheL1IWriteAccesses,    // not verified, not supported by linux kernel as of 2024/11
                cacheL1IWriteMisses,      // not verified, not supported by linux kernel as of 2024/11
                cacheL1IPrefetchAccesses, // not verified, not supported by linux kernel as of 2024/11
                cacheL1IPrefetchMisses,   // not verified, not supported by linux kernel as of 2024/11

                cacheBPUReadAccesses,
                cacheBPUReadMisses,
                cacheBPUWriteAccesses,    // not verified, not supported by linux kernel as of 2024/11
                cacheBPUWriteMisses,      // not verified, not supported by linux kernel as of 2024/11
                cacheBPUPrefetchAccesses, // not verified, not supported by linux kernel as of 2024/11
                cacheBPUPrefetchMisses,   // not verified, not supported by linux kernel as of 2024/11

                cacheNodeReadAccesses,     // not verified, not supported by linux kernel as of 2024/11
                cacheNodeReadMisses,       // not verified, not supported by linux kernel as of 2024/11
                cacheNodeWriteAccesses,    // not verified, not supported by linux kernel as of 2024/11
                cacheNodeWriteMisses,      // not verified, not supported by linux kernel as of 2024/11
                cacheNodePrefetchAccesses, // not verified, not supported by linux kernel as of 2024/11
                cacheNodePrefetchMisses,   // not verified, not supported by linux kernel as of 2024/11
        },
        perDie: {
                cacheLLReadAccesses,     // not verified, not supported by linux kernel as of 2024/11
                cacheLLReadMisses,       // not verified, not supported by linux kernel as of 2024/11
                cacheLLWriteAccesses,    // not verified, not supported by linux kernel as of 2024/11
                cacheLLWriteMisses,      // not verified, not supported by linux kernel as of 2024/11
                cacheLLPrefetchAccesses, // not verified, not supported by linux kernel as of 2024/11
                cacheLLPrefetchMisses,   // not verified, not supported by linux kernel as of 2024/11
        },
}

// Helper maps defined below are holding strings instead of ints as event id needs to be queried from filename.
// See 'dynamic PMU' section for more info: man7.org/linux/man-pages/man2/perf_event_open.2.html.

const (
        typeFileName  string = "type"
        eventsDirName string = "events"

        powerPMUName      string = "power"
        powerPMUEnergyPkg string = "energy-pkg"
)

var dynamicPMUPath string = "/sys/bus/event_source/devices/"

// Helper map for iterations, new supported dynamic-power measurements must be added here.
var powerPerfEvents = map[int][]string{
        perPackage: {
                powerPMUEnergyPkg,
        },
}

// dynamicEvent holds data about dynamic PMU event discovered from sysfs.
type dynamicEvent struct {
        // Sourced from the /sys/bus/event_sources/devices/&lt;pmu&gt;/type file.
        kindID int
        // Sourced from the /sys/bus/event_sources/devices/&lt;pmu&gt;/events/&lt;event&gt; file.
        eventID int
        // Sourced from the /sys/bus/event_sources/devices/&lt;pmu&gt;/events/&lt;event&gt;.scale file.
        scale float64
}

// PerfEventClient is thread safe client to perf_event_open counters.
// Single instance should be created using constructor and passed as
// a pointer.
type PerfEventClient struct {
        readers       map[string]map[uint]perfEventReader
        dynamicEvents map[string]dynamicEvent
        host          power.Host
        log           logr.Logger
}

// By default, all supported perf measurements are enabled.
// host is instance of power optimization library Host that exposes system topology.
// Readers are automatically started on client creation, but need to be closed
// after no longer in use.
// Return pointer to PerfEventClient that should be the only instance created within binary.
func NewPerfEventClient(log logr.Logger, host power.Host) *PerfEventClient <span class="cov8" title="1">{
        pc := PerfEventClient{
                readers:       make(map[string]map[uint]perfEventReader),
                dynamicEvents: make(map[string]dynamicEvent),
                host:          host,
                log:           log,
        }

        // Static events
        pc.addEventGroup(hwPerfEvents, unix.PERF_TYPE_HARDWARE, pc.addDefaultEvent)
        pc.addEventGroup(swPerfEvents, unix.PERF_TYPE_SOFTWARE, pc.addDefaultEvent)
        pc.addEventGroup(cachePerfEvents, unix.PERF_TYPE_HW_CACHE, pc.addDefaultEvent)
        // Dynamic events
        pc.addDynamicEventGroup(powerPerfEvents, powerPMUName, pc.addDefaultEvent)

        pc.log.V(4).Info("New PerfEventClient created")

        return &amp;pc
}</span>

func (pc *PerfEventClient) Close() <span class="cov8" title="1">{
        pc.log.V(4).Info("Closing all registered readers")

        for eventID, eventReaders := range pc.readers </span><span class="cov8" title="1">{
                for scopeID, reader := range eventReaders </span><span class="cov8" title="1">{
                        if err := reader.close(); err != nil </span><span class="cov0" title="0">{
                                pc.log.V(5).Info(fmt.Sprintf("error while closing reader, err: %v", err),
                                        "event ID", eventID, "scope ID", scopeID)
                        }</span>
                }
        }
}

func (pc *PerfEventClient) GetCycles(cpu power.Cpu) (uint64, error) <span class="cov8" title="1">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_CPU_CYCLES),
                cpuLogKey, "cpu cycles",
        )
}</span>

func (pc *PerfEventClient) GetInstructions(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_INSTRUCTIONS),
                cpuLogKey, "retired instructions",
        )
}</span>

func (pc *PerfEventClient) GetCacheAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_CACHE_REFERENCES),
                cpuLogKey, "cache accesses",
        )
}</span>

func (pc *PerfEventClient) GetCacheMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_CACHE_MISSES),
                cpuLogKey, "cpu misses",
        )
}</span>

func (pc *PerfEventClient) GetBranchInstructions(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_BRANCH_INSTRUCTIONS),
                cpuLogKey, "branch instructions",
        )
}</span>

func (pc *PerfEventClient) GetBranchMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_BRANCH_MISSES),
                cpuLogKey, "mispredicted branch instructions",
        )
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetBusCycles(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_BUS_CYCLES),
                cpuLogKey, "bus cycles",
        )
}</span>

func (pc *PerfEventClient) GetStalledCyclesFrontend(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_STALLED_CYCLES_FRONTEND),
                cpuLogKey, "stalled cycles frontend",
        )
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetStalledCyclesBackend(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_STALLED_CYCLES_BACKEND),
                cpuLogKey, "stalled cycles backend",
        )
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetRefCycles(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HARDWARE, unix.PERF_COUNT_HW_REF_CPU_CYCLES),
                cpuLogKey, "ref cycles",
        )
}</span>

func (pc *PerfEventClient) GetBPFOutput(cpu power.Cpu) (uint64, error) <span class="cov8" title="1">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_SOFTWARE, unix.PERF_COUNT_SW_BPF_OUTPUT),
                cpuLogKey, "BPF output",
        )
}</span>

func (pc *PerfEventClient) GetL1DCacheReadAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1DReadAccesses),
                cpuLogKey, "l1 data cache read accesses")
}</span>

func (pc *PerfEventClient) GetL1DCacheReadMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1DReadMisses),
                cpuLogKey, "l1 data cache read misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetL1DCacheWriteAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1DWriteAccesses),
                cpuLogKey, "l1 data cache write accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetL1DCacheWriteMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1DWriteMisses),
                cpuLogKey, "l1 data cache write misses")
}</span>

func (pc *PerfEventClient) GetL1DCachePrefetchAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1DPrefetchAccesses),
                cpuLogKey, "l1 data cache prefetch accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetL1DCachePrefetchMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1DPrefetchMisses),
                cpuLogKey, "l1 data cache prefetch misses")
}</span>

func (pc *PerfEventClient) GetL1ICacheReadAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1IReadAccesses),
                cpuLogKey, "l1 instruction cache read accesses")
}</span>

func (pc *PerfEventClient) GetL1ICacheReadMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1IReadMisses),
                cpuLogKey, "l1 instruction cache read misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetL1ICacheWriteAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1IWriteAccesses),
                cpuLogKey, "l1 instruction cache write accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetL1ICacheWriteMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1IWriteMisses),
                cpuLogKey, "l1 instruction cache write misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetL1ICachePrefetchAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1IPrefetchAccesses),
                cpuLogKey, "l1 instruction cache prefetch accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetL1ICachePrefetchMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheL1IPrefetchMisses),
                cpuLogKey, "l1 instruction cache prefetch misses")
}</span>

func (pc *PerfEventClient) GetBPUCacheReadAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheBPUReadAccesses),
                cpuLogKey, "branch prediction unit cache read accesses")
}</span>

func (pc *PerfEventClient) GetBPUCacheReadMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheBPUReadMisses),
                cpuLogKey, "branch prediction unit cache read misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetBPUCacheWriteAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheBPUWriteAccesses),
                cpuLogKey, "branch prediction unit cache write accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetBPUCacheWriteMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheBPUWriteMisses),
                cpuLogKey, "branch prediction unit cache write misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetBPUCachePrefetchAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheBPUPrefetchAccesses),
                cpuLogKey, "branch prediction unit cache prefetch accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetBPUCachePrefetchMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheBPUPrefetchMisses),
                cpuLogKey, "branch prediction unit cache prefetch misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetNodeCacheReadAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheNodeReadAccesses),
                cpuLogKey, "node cache read accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetNodeCacheReadMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheNodeReadMisses),
                cpuLogKey, "node cache read misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetNodeCacheWriteAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheNodeWriteAccesses),
                cpuLogKey, "node cache write accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetNodeCacheWriteMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheNodeWriteMisses),
                cpuLogKey, "node cache write misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetNodeCachePrefetchAccesses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheNodePrefetchAccesses),
                cpuLogKey, "node cache prefetch accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetNodeCachePrefetchMisses(cpu power.Cpu) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                cpu.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheNodePrefetchMisses),
                cpuLogKey, "node cache prefetch misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetLLCacheReadAccesses(die power.Die) (uint64, error) <span class="cov8" title="1">{
        return pc.readEvent(
                die.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheLLReadAccesses),
                dieLogKey, "last level cache read accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetLLCacheReadMisses(die power.Die) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                die.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheLLReadMisses),
                dieLogKey, "last level cache read misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetLLCacheWriteAccesses(die power.Die) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                die.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheLLWriteAccesses),
                dieLogKey, "last level cache write accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetLLCacheWriteMisses(die power.Die) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                die.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheLLWriteMisses),
                dieLogKey, "last level cache write misses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetLLCachePrefetchAccesses(die power.Die) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                die.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheLLPrefetchAccesses),
                dieLogKey, "last level cache prefetch accesses")
}</span>

// not verified, not supported by linux kernel as of 2024/11
func (pc *PerfEventClient) GetLLCachePrefetchMisses(die power.Die) (uint64, error) <span class="cov0" title="0">{
        return pc.readEvent(
                die.GetID(), pc.getKey(unix.PERF_TYPE_HW_CACHE, cacheLLPrefetchMisses),
                dieLogKey, "last level cache prefetch misses")
}</span>

func (pc *PerfEventClient) GetPackageEnergyConsumption(pkg power.Package) (float64, error) <span class="cov8" title="1">{
        return pc.readDynamicEvent(
                pkg.GetID(),
                pc.getDynamicKey(powerPMUName, powerPMUEnergyPkg),
                packageLogKey, "package energy consumption")
}</span>

// getDynamicKey creates string identifier for dynamic perf event.
// Key is created by combining pmuName with eventName seperated by delimeter.
func (pc *PerfEventClient) getDynamicKey(pmuName, eventName string) string <span class="cov8" title="1">{
        return fmt.Sprintf("%s:%s", pmuName, eventName)
}</span>

// getKey creates string identifier for specific perf event reader.
// Key is created by combining kindID with eventID seperated by delimeter.
func (pc *PerfEventClient) getKey(kindID, eventID int) string <span class="cov8" title="1">{
        return fmt.Sprintf("%d:%d", kindID, eventID)
}</span>

// scopeName and eventName are passed for user friendly logs
func (pc *PerfEventClient) readDynamicEvent(scopeID uint, eventKey string, scopeName, eventName string,
) (float64, error) <span class="cov8" title="1">{
        logger := pc.log.WithValues("event key", eventKey, "event name", eventName, "scope", scopeName, "scope ID", scopeID)

        event, ok := pc.dynamicEvents[eventKey]
        if !ok </span><span class="cov0" title="0">{
                logger.V(5).Info(fmt.Sprintf("err: %v", ErrMetricMissing))
                return 0, ErrMetricMissing
        }</span>

        <span class="cov8" title="1">counterVal, err := pc.readEvent(scopeID, pc.getKey(event.kindID, event.eventID), scopeName, eventName)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov8" title="1">return float64(counterVal) * event.scale, nil</span>
}

// scopeName and eventName are passed for user friendly logs
func (pc *PerfEventClient) readEvent(scopeID uint, eventKey string, scopeName, eventName string) (uint64, error) <span class="cov8" title="1">{
        logger := pc.log.WithValues("event key", eventKey, "event name", eventName, "scope", scopeName, "scope ID", scopeID)

        reader, ok := pc.readers[eventKey][scopeID]
        if !ok </span><span class="cov0" title="0">{
                logger.V(5).Info(fmt.Sprintf("err: %v", ErrMetricMissing))
                return 0, ErrMetricMissing
        }</span>
        <span class="cov8" title="1">val, err := reader.read()
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov8" title="1">return val, nil</span>
}

func (pc *PerfEventClient) addDynamicEventGroup(kindMap map[int][]string, pmuName string,
        addEvent func(scopeID uint, cpuID uint, eventID, kind int, scopeName string),
) <span class="cov8" title="1">{
        logger := pc.log.WithValues("dynamic PMU name", pmuName)

        kindID, err := pc.getDynamicPMUTypeID(pmuName)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "failed to use dynamic PMU")
                return
        }</span>

        <span class="cov8" title="1">if pkgScoped, ok := kindMap[perPackage]; ok </span><span class="cov8" title="1">{
                for _, eventName := range pkgScoped </span><span class="cov8" title="1">{
                        util.IterateOverPackages(pc.host, func(pkg power.Package) </span><span class="cov8" title="1">{
                                logger = logger.WithValues("event name", eventName)

                                eventID, err := pc.getDynamicPMUEventConfig(pmuName, eventName)
                                if err != nil </span><span class="cov8" title="1">{
                                        logger.Error(err, "error while adding event")
                                        return
                                }</span>
                                <span class="cov8" title="1">scale, err := pc.getDynamicEventScale(pmuName, eventName)
                                if err != nil </span><span class="cov8" title="1">{
                                        logger.Error(err, "error while adding event")
                                        return
                                }</span>

                                <span class="cov8" title="1">pc.dynamicEvents[pc.getDynamicKey(pmuName, eventName)] = dynamicEvent{kindID, eventID, scale}
                                addEvent(pkg.GetID(), pkg.CPUs().IDs()[0], eventID, kindID, packageLogKey)</span>
                        })
                }
        }
}

func (pc *PerfEventClient) addEventGroup(kindMap map[int][]int, kind int,
        addEvent func(scopeID uint, cpuID uint, eventID, kind int, scopeName string),
) <span class="cov8" title="1">{
        if dieScoped, ok := kindMap[perDie]; ok </span><span class="cov8" title="1">{
                for _, eventID := range dieScoped </span><span class="cov8" title="1">{
                        util.IterateOverDies(pc.host, func(die power.Die, _ power.Package) </span><span class="cov8" title="1">{
                                addEvent(die.GetID(), die.CPUs().IDs()[0], eventID, kind, dieLogKey)
                        }</span>)
                }
        }
        <span class="cov8" title="1">if cpuScoped, ok := kindMap[perCPU]; ok </span><span class="cov8" title="1">{
                for _, eventID := range cpuScoped </span><span class="cov8" title="1">{
                        util.IterateOverCPUs(pc.host, func(cpu power.Cpu, _ power.Core, _ power.Die, _ power.Package) </span><span class="cov8" title="1">{
                                addEvent(cpu.GetID(), cpu.GetID(), eventID, kind, cpuLogKey)
                        }</span>)
                }
        }
}

// scopeName is passed for user friendly logs
func (pc *PerfEventClient) addDefaultEvent(scopeID uint, cpuID uint, eventID, kind int, scopeName string) <span class="cov8" title="1">{
        logger := pc.log.WithValues("event ID", eventID, "scope", scopeName, "scope ID", scopeID, "type", kind)

        reader, err := newDefaultPerfEventReaderFunc(int(cpuID), kind, eventID)
        if err != nil </span><span class="cov8" title="1">{
                logger.Error(err, "error while creating event reader")
                return
        }</span>

        <span class="cov8" title="1">key := pc.getKey(kind, eventID)
        if _, ok := pc.readers[key]; !ok </span><span class="cov8" title="1">{
                pc.readers[key] = make(map[uint]perfEventReader)
        }</span>
        <span class="cov8" title="1">pc.readers[key][scopeID] = reader
        logger.V(5).Info("Initialized reader")

        if err := reader.start(); err != nil </span><span class="cov0" title="0">{
                logger.Error(err, "error while starting reader, closing it immediately")
                if err := reader.close(); err != nil </span><span class="cov0" title="0">{
                        logger.Error(err, "error while closing reader, nothing else to do")
                }</span>
                <span class="cov0" title="0">delete(pc.readers[key], scopeID)</span>
        }
}

func (pc *PerfEventClient) getDynamicPMUTypeID(pmuName string) (int, error) <span class="cov8" title="1">{
        typeFilepath := filepath.Join(dynamicPMUPath, pmuName, typeFileName)
        typeBytes, err := os.ReadFile(typeFilepath)
        if err != nil </span><span class="cov0" title="0">{
                err = fmt.Errorf("failed to read content of dynamic PMU file %s: %w", typeFilepath, err)
                return 0, err
        }</span>
        <span class="cov8" title="1">typeContent := strings.Trim(string(typeBytes), "\n ")
        kindID, err := strconv.Atoi(typeContent)
        if err != nil </span><span class="cov8" title="1">{
                err = fmt.Errorf("failed to convert content '%s' of dynamic PMU file %s to integer: %w",
                        typeContent, typeFilepath, err)
                return 0, err
        }</span>

        <span class="cov8" title="1">return kindID, nil</span>
}

func (pc *PerfEventClient) getDynamicEventScale(pmuName string, eventName string) (float64, error) <span class="cov8" title="1">{
        scaleFilepath := filepath.Join(dynamicPMUPath, pmuName, eventsDirName, eventName+".scale")
        scaleBytes, err := os.ReadFile(scaleFilepath)
        if err != nil </span><span class="cov0" title="0">{
                err = fmt.Errorf("failed to read content of dynamic PMU file %s: %w", scaleFilepath, err)
                return 0.0, err
        }</span>
        <span class="cov8" title="1">scaleContent := strings.Trim(string(scaleBytes), "\n ")
        scale, err := strconv.ParseFloat(scaleContent, 64)
        if err != nil || math.IsNaN(scale) || math.IsInf(scale, 0) </span><span class="cov8" title="1">{
                err = fmt.Errorf("failed to convert content '%s' of dynamic PMU file %s to float64: %w",
                        scaleContent, scaleFilepath, err,
                )
                return 0.0, err
        }</span>

        <span class="cov8" title="1">return scale, nil</span>
}

func (pc *PerfEventClient) getDynamicPMUEventConfig(pmuName, eventName string) (int, error) <span class="cov8" title="1">{
        configFilepath := filepath.Join(dynamicPMUPath, pmuName, eventsDirName, eventName)
        configBytes, err := os.ReadFile(configFilepath)
        if err != nil </span><span class="cov0" title="0">{
                pc.log.Error(err, "failed to read content of dynamic PMU file", "file", configFilepath)
                return 0, err
        }</span>
        <span class="cov8" title="1">configStr := strings.Trim(string(configBytes), "\n ")

        var eventID int
        for _, pair := range strings.Split(configStr, ",") </span><span class="cov8" title="1">{
                var val int
                if n, err := fmt.Sscanf(pair, "event=0x%x", &amp;val); err == nil &amp;&amp; n == 1 </span><span class="cov8" title="1">{
                        eventID = val
                        continue</span>
                }
                <span class="cov8" title="1">return 0, fmt.Errorf("%s key-value pair found in %s not supported/recognized", pair, configFilepath)</span>
        }

        <span class="cov8" title="1">return eventID, nil</span>
}
</pre>
		
		<pre class="file" id="file31" style="display: none">package metrics

import (
        "encoding/binary"
        "fmt"
        "sync/atomic"
        "syscall"
        "unsafe"

        "golang.org/x/sys/unix"
)

const (
        // vars not defined in x/sys/unix.
        perfSampleIdentifier = 1 &lt;&lt; 16
        perfIOCFlagGroup     = 1 &lt;&lt; 0

        // 3 uint64 values: the event value, running time, enabled time
        perfEventReaderBufSize = 3 * unsafe.Sizeof(uint64(0))

        maxWriteConflictRetries = 10
)

var syscallRead = syscall.Read

type perfEventValues struct {
        lastTimeEnabled uint64
        lastTimeRunning uint64
        lastRawValue    uint64
        lastScaledValue uint64
}

type perfEventReader interface {
        start() error
        close() error
        read() (uint64, error)
}

type defaultPerfEventReader struct {
        cpu    int
        kind   int
        config int

        values atomic.Pointer[perfEventValues]

        fd int
}

func newDefaultPerfEventReader(cpu, kind, config int) (perfEventReader, error) <span class="cov0" title="0">{
        eventAttr := &amp;unix.PerfEventAttr{
                Type:        uint32(kind),
                Config:      uint64(config),
                Size:        uint32(unsafe.Sizeof(unix.PerfEventAttr{})),
                Bits:        unix.PerfBitDisabled,
                Read_format: unix.PERF_FORMAT_TOTAL_TIME_RUNNING | unix.PERF_FORMAT_TOTAL_TIME_ENABLED,
                Sample_type: perfSampleIdentifier,
        }
        fd, err := unix.PerfEventOpen(eventAttr, -1, cpu, -1, 0)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to open perf event counter file for CPU %d, type %d, kind %d: %w",
                        cpu, kind, config, err)
        }</span>

        <span class="cov0" title="0">dp := defaultPerfEventReader{cpu: cpu, kind: kind, config: config, fd: fd}
        dp.values.Store(&amp;perfEventValues{})

        return &amp;dp, nil</span>
}

func (p *defaultPerfEventReader) start() error <span class="cov0" title="0">{
        return unix.IoctlSetInt(p.fd, unix.PERF_EVENT_IOC_ENABLE, 0)
}</span>

func (p *defaultPerfEventReader) close() error <span class="cov0" title="0">{
        return syscall.Close(p.fd)
}</span>

func (p *defaultPerfEventReader) read() (uint64, error) <span class="cov8" title="1">{
        buf := make([]byte, perfEventReaderBufSize)
        for attempt := 0; attempt &lt; maxWriteConflictRetries; attempt++ </span><span class="cov8" title="1">{
                oldValues := p.values.Load()

                if _, err := syscallRead(p.fd, buf); err != nil </span><span class="cov0" title="0">{
                        return 0, fmt.Errorf("failed to read properly created perf event counter file for CPU %d, type %d, kind %d: %w",
                                p.cpu, p.kind, p.config, err)
                }</span>

                <span class="cov8" title="1">rawValue := binary.LittleEndian.Uint64(buf[0:8])
                timeEnabled := binary.LittleEndian.Uint64(buf[8:16])
                timeRunning := binary.LittleEndian.Uint64(buf[16:24])

                deltaTimeEnabled := timeEnabled - oldValues.lastTimeEnabled
                deltaTimeRunning := timeRunning - oldValues.lastTimeRunning
                deltaValue := rawValue - oldValues.lastRawValue

                if deltaTimeRunning == 0 </span><span class="cov8" title="1">{
                        // no time counted since last read
                        return oldValues.lastScaledValue, nil
                }</span>
                <span class="cov8" title="1">if timeRunning &lt; oldValues.lastTimeRunning || timeEnabled &lt; oldValues.lastTimeEnabled || rawValue &lt; oldValues.lastRawValue </span><span class="cov8" title="1">{
                        return 0, fmt.Errorf("inconsistent values from perf event counter for CPU %d, type %d, kind %d",
                                p.cpu, p.kind, p.config)
                }</span>
                <span class="cov8" title="1">scaledValue := oldValues.lastScaledValue
                if deltaTimeRunning &lt; deltaTimeEnabled </span><span class="cov8" title="1">{
                        // multiplexing happened since last read, scaling needs to be done
                        scaledValue += uint64(float64(deltaValue) * float64(deltaTimeEnabled) / float64(deltaTimeRunning))
                }</span> else<span class="cov8" title="1"> {
                        scaledValue += deltaValue
                }</span>
                <span class="cov8" title="1">newValues := &amp;perfEventValues{
                        lastTimeEnabled: timeEnabled,
                        lastTimeRunning: timeRunning,
                        lastRawValue:    rawValue,
                        lastScaledValue: scaledValue,
                }
                if p.values.CompareAndSwap(oldValues, newValues) </span><span class="cov8" title="1">{
                        return scaledValue, nil
                }</span>
        }
        <span class="cov0" title="0">return 0, fmt.Errorf("attempts exceeded while trying to update perf event counter for CPU %d, type %d, kind %d",
                p.cpu, p.kind, p.config)</span>
}
</pre>
		
		<pre class="file" id="file32" style="display: none">package monitoring

import (
        "errors"
        "fmt"
        "strconv"

        "golang.org/x/exp/constraints"

        "github.com/intel/kubernetes-power-manager/internal/metrics"
        "github.com/intel/kubernetes-power-manager/pkg/util"
        "github.com/intel/power-optimization-library/pkg/power"

        "github.com/go-logr/logr"
        prom "github.com/prometheus/client_golang/prometheus"
)

// Helper constants for prom Collectors
const (
        promNamespace string = "power"

        LogTopName    string = "monitoring"
        perfSubsystem string = "perf"
        msrSubsystem  string = "msr"
        esmiSubsystem string = "esmi"

        logTypeKey      string = "type"
        logTypeHardware string = "hardware"
        logTypeSoftware string = "software"
        logTypeCache    string = "cache"
        logTypePower    string = "power"
        logNameKey      string = "name"
)

type collectorImpl struct {
        collectFunc  func(ch chan&lt;- prom.Metric)
        describeFunc func(ch chan&lt;- *prom.Desc)
}

func (c collectorImpl) Collect(ch chan&lt;- prom.Metric) <span class="cov8" title="1">{
        c.collectFunc(ch)
}</span>

func (c collectorImpl) Describe(ch chan&lt;- *prom.Desc) <span class="cov8" title="1">{
        c.describeFunc(ch)
}</span>

type number interface {
        constraints.Integer | constraints.Float
}

// newPerCPUCollector is generic factory of prometheus Collectors for metrics that are CPU bound.
// host is instance of power optimization library Host that exposes system topology.
// readFunc is generic function which signature corresponds to methods of southbound telemetry clients.
// log is Logger that should have all Names, KeysValues and other... already attached.
// return prometheus Collector that is ready for registration
func newPerCPUCollector[T number](metricName, metricDesc string, metricType prom.ValueType,
        host power.Host, readFunc func(power.Cpu) (T, error), log logr.Logger,
) prom.Collector <span class="cov8" title="1">{
        desc := prom.NewDesc(
                metricName,
                metricDesc,
                []string{"cpu", "core", "die", "package"},
                nil,
        )

        collectorFuncs := make([]func(ch chan&lt;- prom.Metric), 0)
        util.IterateOverCPUs(host, func(cpu power.Cpu, core power.Core, die power.Die, pkg power.Package) </span><span class="cov8" title="1">{
                if _, err := readFunc(cpu); errors.Is(err, metrics.ErrMetricMissing) </span><span class="cov8" title="1">{
                        log.Info("Not registering collection, client will not be able to read this metric",
                                "error", err.Error(), "cpu", cpu.GetID())
                }</span> else<span class="cov8" title="1"> {
                        collectorFuncs = append(collectorFuncs, func(ch chan&lt;- prom.Metric) </span><span class="cov8" title="1">{
                                log.V(5).Info("Collecting metrics for reporting", "cpu", cpu.GetID())
                                if val, err := readFunc(cpu); err == nil </span><span class="cov8" title="1">{
                                        ch &lt;- prom.MustNewConstMetric(
                                                desc,
                                                metricType,
                                                float64(val),
                                                strconv.Itoa(int(cpu.GetID())),
                                                strconv.Itoa(int(core.GetID())),
                                                strconv.Itoa(int(die.GetID())),
                                                strconv.Itoa(int(pkg.GetID())),
                                        )
                                }</span> else<span class="cov0" title="0"> {
                                        log.V(5).Info(fmt.Sprintf("error reading metric value, err: %v", err), "cpu", cpu.GetID())
                                }</span>
                        })
                }
        })
        <span class="cov8" title="1">log.V(4).Info("New perCPU prometheus Collector created")

        return collectorImpl{
                describeFunc: func(ch chan&lt;- *prom.Desc) </span><span class="cov8" title="1">{
                        ch &lt;- desc
                }</span>,
                collectFunc: func(ch chan&lt;- prom.Metric) <span class="cov8" title="1">{
                        for _, collectFunc := range collectorFuncs </span><span class="cov8" title="1">{
                                collectFunc(ch)
                        }</span>
                },
        }
}

// newPerCoreCollector is generic factory of prometheus Collectors for metrics that are core bound.
// host is instance of power optimization library Host that exposes system topology.
// readFunc is generic function which signature corresponds to methods of southbound telemetry clients.
// log is Logger that should have all Names, KeysValues and other... already attached.
// return prometheus Collector that is ready for registration
func newPerCoreCollector[T number](metricName, metricDesc string, metricType prom.ValueType,
        host power.Host, readFunc func(power.Core) (T, error), log logr.Logger,
) prom.Collector <span class="cov8" title="1">{
        desc := prom.NewDesc(
                metricName,
                metricDesc,
                []string{"core", "die", "package"},
                nil,
        )

        collectorFuncs := make([]func(ch chan&lt;- prom.Metric), 0)
        util.IterateOverCores(host, func(core power.Core, die power.Die, pkg power.Package) </span><span class="cov8" title="1">{
                if _, err := readFunc(core); errors.Is(err, metrics.ErrMetricMissing) </span><span class="cov8" title="1">{
                        log.Info("Not registering collection, client will not be able to read this metric",
                                "error", err.Error(), "core", core.GetID())
                }</span> else<span class="cov8" title="1"> {
                        collectorFuncs = append(collectorFuncs, func(ch chan&lt;- prom.Metric) </span><span class="cov8" title="1">{
                                log.V(5).Info("Collecting metrics for reporting", "core", core.GetID())
                                if val, err := readFunc(core); err == nil </span><span class="cov8" title="1">{
                                        ch &lt;- prom.MustNewConstMetric(
                                                desc,
                                                metricType,
                                                float64(val),
                                                strconv.Itoa(int(core.GetID())),
                                                strconv.Itoa(int(die.GetID())),
                                                strconv.Itoa(int(pkg.GetID())),
                                        )
                                }</span> else<span class="cov0" title="0"> {
                                        log.V(5).Info(fmt.Sprintf("error reading metric value, err: %v", err), "core", core.GetID())
                                }</span>
                        })
                }
        })
        <span class="cov8" title="1">log.V(4).Info("New perCore prometheus Collector created")

        return collectorImpl{
                describeFunc: func(ch chan&lt;- *prom.Desc) </span><span class="cov8" title="1">{
                        ch &lt;- desc
                }</span>,
                collectFunc: func(ch chan&lt;- prom.Metric) <span class="cov8" title="1">{
                        for _, collectFunc := range collectorFuncs </span><span class="cov8" title="1">{
                                collectFunc(ch)
                        }</span>
                },
        }
}

// nolint: unused
// newPerDieCollector is generic factory of prometheus Collectors for metrics that are die bound.
// host is instance of power optimization library Host that exposes system topology.
// readFunc is generic function which signature corresponds to methods of southbound telemetry clients.
// log is Logger that should have all Names, KeysValues and other... already attached.
// return prometheus Collector that is ready for registration.
func newPerDieCollector[T number](metricName, metricDesc string, metricType prom.ValueType,
        host power.Host, readFunc func(power.Die) (T, error), log logr.Logger,
) prom.Collector <span class="cov0" title="0">{
        desc := prom.NewDesc(
                metricName,
                metricDesc,
                []string{"die", "package"},
                nil,
        )

        collectorFuncs := make([]func(ch chan&lt;- prom.Metric), 0)
        util.IterateOverDies(host, func(die power.Die, pkg power.Package) </span><span class="cov0" title="0">{
                if _, err := readFunc(die); errors.Is(err, metrics.ErrMetricMissing) </span><span class="cov0" title="0">{
                        log.Info("Not registering collection, client will not be able to read this metric",
                                "error", err.Error(), "die", die.GetID())
                }</span> else<span class="cov0" title="0"> {
                        collectorFuncs = append(collectorFuncs, func(ch chan&lt;- prom.Metric) </span><span class="cov0" title="0">{
                                log.V(5).Info("Collecting metrics for reporting", "die", die.GetID())
                                if val, err := readFunc(die); err == nil </span><span class="cov0" title="0">{
                                        ch &lt;- prom.MustNewConstMetric(
                                                desc,
                                                metricType,
                                                float64(val),
                                                strconv.Itoa(int(die.GetID())),
                                                strconv.Itoa(int(pkg.GetID())),
                                        )
                                }</span> else<span class="cov0" title="0"> {
                                        log.V(5).Info(fmt.Sprintf("error reading metric value, err: %v", err), "die", die.GetID())
                                }</span>
                        })
                }
        })
        <span class="cov0" title="0">log.V(4).Info("New perDie prometheus Collector created")

        return collectorImpl{
                describeFunc: func(ch chan&lt;- *prom.Desc) </span><span class="cov0" title="0">{
                        ch &lt;- desc
                }</span>,
                collectFunc: func(ch chan&lt;- prom.Metric) <span class="cov0" title="0">{
                        for _, collectFunc := range collectorFuncs </span><span class="cov0" title="0">{
                                collectFunc(ch)
                        }</span>
                },
        }
}

// newPerPackageCollector is generic factory of prometheus Collectors for metrics that are package bound.
// host is instance of power optimization library Host that exposes system topology.
// readFunc is generic function which signature corresponds to methods of southbound telemetry clients.
// log is Logger that should have all Names, KeysValues and other... already attached.
// return prometheus Collector that is ready for registration
func newPerPackageCollector[T number](metricName, metricDesc string, metricType prom.ValueType,
        host power.Host, readFunc func(power.Package) (T, error), log logr.Logger,
) prom.Collector <span class="cov8" title="1">{
        desc := prom.NewDesc(
                metricName,
                metricDesc,
                []string{"package"},
                nil,
        )

        collectorFuncs := make([]func(ch chan&lt;- prom.Metric), 0)
        util.IterateOverPackages(host, func(pkg power.Package) </span><span class="cov8" title="1">{
                if _, err := readFunc(pkg); errors.Is(err, metrics.ErrMetricMissing) </span><span class="cov8" title="1">{
                        log.Info("Not registering collection, client will not be able to read this metric",
                                "error", err.Error(), "package", pkg.GetID())
                }</span> else<span class="cov8" title="1"> {
                        collectorFuncs = append(collectorFuncs, func(ch chan&lt;- prom.Metric) </span><span class="cov8" title="1">{
                                log.V(5).Info("Collecting metrics for reporting", "package", pkg.GetID())
                                if val, err := readFunc(pkg); err == nil </span><span class="cov8" title="1">{
                                        ch &lt;- prom.MustNewConstMetric(
                                                desc,
                                                metricType,
                                                float64(val),
                                                strconv.Itoa(int(pkg.GetID())),
                                        )
                                }</span> else<span class="cov0" title="0"> {
                                        log.V(5).Info(fmt.Sprintf("error reading metric value, err: %v", err), "package", pkg.GetID())
                                }</span>
                        })
                }
        })
        <span class="cov8" title="1">log.V(4).Info("New perPackage prometheus Collector created")

        return collectorImpl{
                describeFunc: func(ch chan&lt;- *prom.Desc) </span><span class="cov8" title="1">{
                        ch &lt;- desc
                }</span>,
                collectFunc: func(ch chan&lt;- prom.Metric) <span class="cov8" title="1">{
                        for _, collectFunc := range collectorFuncs </span><span class="cov8" title="1">{
                                collectFunc(ch)
                        }</span>
                },
        }
}

// newPerSystemCollector is generic factory of prometheus Collectors for metrics that are system scoped.
// readFunc is generic function which signature corresponds to methods of southbound telemetry clients.
// log is Logger that should have all Names, KeysValues and other... already attached.
// return prometheus Collector that is ready for registration
func newPerSystemCollector[T number](metricName, metricDesc string, metricType prom.ValueType,
        readFunc func() (T, error), log logr.Logger,
) prom.Collector <span class="cov8" title="1">{
        desc := prom.NewDesc(
                metricName,
                metricDesc,
                nil,
                nil,
        )

        collectorFuncs := make([]func(ch chan&lt;- prom.Metric), 0)
        if _, err := readFunc(); errors.Is(err, metrics.ErrMetricMissing) </span><span class="cov8" title="1">{
                log.Info("Not registering collection, client will not be able to read this metric", "error", err.Error())
        }</span> else<span class="cov8" title="1"> {
                collectorFuncs = append(collectorFuncs, func(ch chan&lt;- prom.Metric) </span><span class="cov8" title="1">{
                        log.V(5).Info("Collecting metrics for reporting")
                        if val, err := readFunc(); err == nil </span><span class="cov8" title="1">{
                                ch &lt;- prom.MustNewConstMetric(
                                        desc,
                                        metricType,
                                        float64(val),
                                )
                        }</span> else<span class="cov0" title="0"> {
                                log.V(5).Info(fmt.Sprintf("error reading metric value, err: %v", err))
                        }</span>
                })
        }
        <span class="cov8" title="1">log.V(4).Info("New perSystem prometheus Collector created")

        return collectorImpl{
                describeFunc: func(ch chan&lt;- *prom.Desc) </span><span class="cov8" title="1">{
                        ch &lt;- desc
                }</span>,
                collectFunc: func(ch chan&lt;- prom.Metric) <span class="cov8" title="1">{
                        for _, collectFunc := range collectorFuncs </span><span class="cov8" title="1">{
                                collectFunc(ch)
                        }</span>
                },
        }
}
</pre>
		
		<pre class="file" id="file33" style="display: none">package monitoring

import (
        "errors"
        "fmt"
        "strconv"

        "github.com/intel/kubernetes-power-manager/internal/metrics"
        "github.com/intel/kubernetes-power-manager/pkg/util"
        "github.com/intel/power-optimization-library/pkg/power"

        "github.com/go-logr/logr"
        prom "github.com/prometheus/client_golang/prometheus"
        ctrlMetrics "sigs.k8s.io/controller-runtime/pkg/metrics"
)

func RegisterESMICollectors(esmiClient *metrics.ESMIClient, host power.Host, logger logr.Logger) <span class="cov0" title="0">{
        logger = logger.WithName(esmiSubsystem)

        ctrlMetrics.Registry.MustRegister(
                newPerCoreCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "core_energy_consumption_joules_total"),
                        "Counter of total core energy consumption in joules.",
                        prom.CounterValue,
                        host,
                        esmiClient.GetCoreEnergy,
                        logger.WithValues(logNameKey, "core_energy_consumption_joules_total"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "package_energy_consumption_joules_total"),
                        "Counter of total core energy consumption in joules.",
                        prom.CounterValue,
                        host,
                        esmiClient.GetPackageEnergy,
                        logger.WithValues(logNameKey, "core_energy_consumption_joules_total"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "data_fabric_clock_megahertz"),
                        "Gauge of data fabric clock in MHz.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetDataFabricClock,
                        logger.WithValues(logNameKey, "data_fabric_clock_megahertz"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "memory_clock_megahertz"),
                        "Gauge of memory clock in MHz.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetMemoryClock,
                        logger.WithValues(logNameKey, "memory_clock_megahertz"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "core_clock_throttle_limit_megahertz"),
                        "Gauge of package core clock throttle limit in MHz.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetCoreClockThrottleLimit,
                        logger.WithValues(logNameKey, "core_clock_throttle_limit_megahertz"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "package_frequency_limit_megahertz"),
                        "Gauge of package frequency limit in MHz.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetPackageFreqLimit,
                        logger.WithValues(logNameKey, "package_frequency_limit"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "package_min_frequency_megahertz"),
                        "Gauge of package minimum frequency in MHz.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetPackageMinFreq,
                        logger.WithValues(logNameKey, "package_min_frequency_megahertz"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "package_max_frequency_megahertz"),
                        "Gauge of package maximum frequency in MHz.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetPackageMaxFreq,
                        logger.WithValues(logNameKey, "package_max_frequency_megahertz"),
                ),
                newPerCoreCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "core_frequency_limit_megahertz"),
                        "Gauge of core frequency limit in MHz.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetCoreFreqLimit,
                        logger.WithValues(logNameKey, "core_frequency_limit_megahertz"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "rail_frequency_limit"),
                        "Gauge of package rail frequency limit policy. Values: 1 = all cores on both rails "+
                                "have same frequency limit, 0 = each rail has different independent frequency limit.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetRailFreqLimitPolicy,
                        logger.WithValues(logNameKey, "rail_frequency_limit"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "df_cstate_enabling_control"),
                        "Gauge of package DF C-state enabling control. Values: 1 = DFC enabled, 0 = DFC disabled.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetDFCStateEnablingControl,
                        logger.WithValues(logNameKey, "df_cstate_enabling_control"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "package_power_watts"),
                        "Gauge of package power in watts.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetPackagePower,
                        logger.WithValues(logNameKey, "package_power_watts"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "package_power_cap_watts"),
                        "Gauge of package power cap in watts.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetPackagePowerCap,
                        logger.WithValues(logNameKey, "package_power_cap_watts"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "package_power_max_cap_watts"),
                        "Gauge of package power max cap in watts.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetPackagePowerMaxCap,
                        logger.WithValues(logNameKey, "package_power_max_cap_watts"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "power_efficiency_mode"),
                        "Gauge of package power efficiency mode. Values: 0 = high performance mode, "+
                                "1 = power efficient mode, 2 = IO performance mode, 3 = balanced memory performance mode, "+
                                "4 = balanced core performance mode, 5 = balanced core and memory performance mode.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetPackagePowerEfficiencyMode,
                        logger.WithValues(logNameKey, "power_efficiency_mode"),
                ),
                newPerCoreCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "core_boost_limit_megahertz"),
                        "Gauge of core frequency boost limit in MHz.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetCoreBoostLimit,
                        logger.WithValues(logNameKey, "core_boost_limit_megahertz"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "c0_residency_percent"),
                        "Gauge of package residency in C0 in percents.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetPackageC0Residency,
                        logger.WithValues(logNameKey, "c0_residency_percent"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "package_temperature_celsius"),
                        "Gauge of package temperature in degree Celsius.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetPackageTemp,
                        logger.WithValues(logNameKey, "package_temperature_celsius"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "ddr_bandwidth_utilization_gigabytes_per_second"),
                        "Gauge of DDR bandwidth utilization in GB/s.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetDDRBandwidthUtil,
                        logger.WithValues(logNameKey, "ddr_bandwidth_utilization_gigabytes_per_second"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "ddr_bandwidth_utilization_percent"),
                        "Gauge of DDR bandwidth utilization in percent of maximum bandwidth.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetDDRBandwidthUtilPercent,
                        logger.WithValues(logNameKey, "ddr_bandwidth_utilization_percent"),
                ),
                newPackageDimmCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "dimm_power_watts"),
                        "Gauge of DIMM power in watts.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetDIMMPower,
                        logger.WithValues(logNameKey, "dimm_power_watts"),
                ),
                newPackageDimmCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "dimm_temperature_celsius"),
                        "Gauge of DIMM temperature in degree Celsius.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetDIMMTemp,
                        logger.WithValues(logNameKey, "dimm_temperature_celsius"),
                ),
                newPackageNBIOCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "lclk_dpm_min_level"),
                        "Gauge of minimum LCLK DPM level. Values: either 0 or 1",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetLCLKDPMMinLevel,
                        logger.WithValues(logNameKey, "lclk_dpm_min_level"),
                ),
                newPackageNBIOCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "lclk_dpm_max_level"),
                        "Gauge of maximum LCLK DPM level. Values: either 0 or 1",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetLCLKDPMMaxLevel,
                        logger.WithValues(logNameKey, "lclk_dpm_max_level"),
                ),
                newPackageIOLinkCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "io_link_bandwidth_utilization_megabits_per_second"),
                        "Gauge of IO link bandwidth utilization in Mb/s.",
                        prom.GaugeValue,
                        host,
                        esmiClient.GetIOLinkBandwidthUtil,
                        logger.WithValues(logNameKey, "io_link_bandwidth_utilization_megabits_per_second"),
                ),
                newPerIOLinkCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "xgmi_aggregate_bandwidth_utilization_megabits_per_second"),
                        "Gauge of xGMI aggregate bandwidth utilization in Mb/s.",
                        prom.GaugeValue,
                        esmiClient.GetxGMIAggregateBandwidthUtil,
                        logger.WithValues(logNameKey, "xgmi_aggregate_bandwidth_utilization_megabits_per_second"),
                ),
                newPerIOLinkCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "xgmi_read_bandwidth_utilization_megabits_per_second"),
                        "Gauge of xGMI read bandwidth utilization in Mb/s.",
                        prom.GaugeValue,
                        esmiClient.GetxGMIReadBandwidthUtil,
                        logger.WithValues(logNameKey, "xgmi_read_bandwidth_utilization_megabits_per_second"),
                ),
                newPerIOLinkCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "xgmi_write_bandwidth_utilization_megabits_per_second"),
                        "Gauge of xGMI write bandwidth utilization in Mb/s.",
                        prom.GaugeValue,
                        esmiClient.GetxGMIWriteBandwidthUtil,
                        logger.WithValues(logNameKey, "xgmi_write_bandwidth_utilization_megabits_per_second"),
                ),
                newPerSystemCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "processor_family"),
                        "Gauge of processor family.",
                        prom.GaugeValue,
                        esmiClient.GetCPUFamily,
                        logger.WithValues(logNameKey, "processor_family"),
                ),
                newPerSystemCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "processor_model"),
                        "Gauge of processor model.",
                        prom.GaugeValue,
                        esmiClient.GetCPUModel,
                        logger.WithValues(logNameKey, "processor_model"),
                ),
                newPerSystemCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "cpus_per_core"),
                        "Gauge of CPUs per core.",
                        prom.GaugeValue,
                        esmiClient.GetNumberOfCPUsPerCore,
                        logger.WithValues(logNameKey, "cpus_per_core"),
                ),
                newPerSystemCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "cpus"),
                        "Gauge of total number of CPUs in the system.",
                        prom.GaugeValue,
                        esmiClient.GetNumberOfCPUs,
                        logger.WithValues(logNameKey, "cpus"),
                ),
                newPerSystemCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "packages"),
                        "Gauge of total number of packages in the system.",
                        prom.GaugeValue,
                        esmiClient.GetNumberOfPackages,
                        logger.WithValues(logNameKey, "packages"),
                ),
                newPerSystemCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "smu_firmware_major_version"),
                        "Gauge of SMU firmware major version.",
                        prom.GaugeValue,
                        esmiClient.GetSMUFWMajorVersion,
                        logger.WithValues(logNameKey, "smu_firmware_major_version"),
                ),
                newPerSystemCollector(
                        prom.BuildFQName(promNamespace, esmiSubsystem, "smu_firmware_minor_version"),
                        "Gauge of SMU firmware minor version.",
                        prom.GaugeValue,
                        esmiClient.GetSMUFWMinorVersion,
                        logger.WithValues(logNameKey, "smu_firmware_minor_version"),
                ),
        )
}</span>

// Helpers with hardcoded e_smi lib functions parameters
var (
        supportedUMCNum  int = 12
        dimm0StartAddr   int = 0x80
        dimm1StartAddr   int = 0x90
        supportedNBIOIDs     = []int{0, 1, 2, 3}
        supportedIOLinks     = []string{
                "P0", "P1", "P2", "P3", "P4",
                "G0", "G1", "G2", "G3", "G4", "G5", "G6", "G7",
        }
)

// newPackageDimmCollector is generic factory of prometheus Collectors for metrics that are taking package
// and DIMM address as parameters.
// host is instance of power optimization library Host that exposes system topology.
// readFunc is generic function which signature corresponds to methods of southbound telemetry clients.
// log is Logger that should have all Names, KeysValues and other... already attached.
// return prometheus Collector that is ready for registration.
func newPackageDimmCollector[T, E number](metricName, metricDesc string, metricType prom.ValueType,
        host power.Host, readFunc func(power.Package, E) (T, error), log logr.Logger,
) prom.Collector <span class="cov8" title="1">{
        desc := prom.NewDesc(metricName,
                metricDesc,
                []string{"package", "umc", "dimm"},
                nil,
        )

        collectorFuncs := make([]func(ch chan&lt;- prom.Metric), 0)
        util.IterateOverPackages(host, func(pkg power.Package) </span><span class="cov8" title="1">{
                for umc := range supportedUMCNum </span><span class="cov8" title="1">{
                        for dimm, dimmAddr := range []int{dimm0StartAddr + umc, dimm1StartAddr + umc} </span><span class="cov8" title="1">{
                                if _, err := readFunc(pkg, E(dimmAddr)); errors.Is(err, metrics.ErrMetricMissing) </span><span class="cov8" title="1">{
                                        log.Info("Not registering collection, client will not be able to read this metric", "error",
                                                err.Error(), "package", pkg.GetID(), "DIMM address", dimmAddr, "DIMM", dimm, "UMC", umc)
                                }</span> else<span class="cov8" title="1"> {
                                        collectorFuncs = append(collectorFuncs, func(ch chan&lt;- prom.Metric) </span><span class="cov8" title="1">{
                                                log.V(5).Info("Collecting metrics for reporting", "package", pkg.GetID(),
                                                        "DIMM address", dimmAddr, "DIMM", dimm, "UMC", umc)
                                                if val, err := readFunc(pkg, E(dimmAddr)); err == nil </span><span class="cov8" title="1">{
                                                        ch &lt;- prom.MustNewConstMetric(
                                                                desc,
                                                                metricType,
                                                                float64(val),
                                                                strconv.Itoa(int(pkg.GetID())),
                                                                strconv.Itoa(umc),
                                                                strconv.Itoa(dimm),
                                                        )
                                                }</span> else<span class="cov0" title="0"> {
                                                        log.V(5).Info(fmt.Sprintf("error reading metric value, err: %v", err), "package",
                                                                pkg.GetID(), "DIMM address", dimmAddr, dimmAddr, "DIMM", dimm, "UMC", umc)
                                                }</span>
                                        })
                                }
                        }
                }
        })
        <span class="cov8" title="1">log.V(4).Info("New Package &amp; DIMM address prometheus Collector created")

        return collectorImpl{
                describeFunc: func(ch chan&lt;- *prom.Desc) </span><span class="cov8" title="1">{
                        ch &lt;- desc
                }</span>,
                collectFunc: func(ch chan&lt;- prom.Metric) <span class="cov8" title="1">{
                        for _, collectFunc := range collectorFuncs </span><span class="cov8" title="1">{
                                collectFunc(ch)
                        }</span>
                },
        }

}

// newPackageNBIOCollector is generic factory of prometheus Collectors for metrics that are taking package
// and NBIO as parameters.
// host is instance of power optimization library Host that exposes system topology.
// readFunc is generic function which signature corresponds to methods of southbound telemetry clients.
// log is Logger that should have all Names, KeysValues and other... already attached.
// return prometheus Collector that is ready for registration.
func newPackageNBIOCollector[T, E number](metricName, metricDesc string, metricType prom.ValueType,
        host power.Host, readFunc func(power.Package, E) (T, error), log logr.Logger,
) prom.Collector <span class="cov8" title="1">{
        desc := prom.NewDesc(metricName,
                metricDesc,
                []string{"package", "nbio"},
                nil,
        )

        collectorFuncs := make([]func(ch chan&lt;- prom.Metric), 0)
        util.IterateOverPackages(host, func(pkg power.Package) </span><span class="cov8" title="1">{
                for _, nbioID := range supportedNBIOIDs </span><span class="cov8" title="1">{
                        if _, err := readFunc(pkg, E(nbioID)); errors.Is(err, metrics.ErrMetricMissing) </span><span class="cov8" title="1">{
                                log.Info("Not registering collection, client will not be able to read this metric",
                                        "error", err.Error(), "package", pkg.GetID(), "NBIO ID", nbioID)
                        }</span> else<span class="cov8" title="1"> {
                                collectorFuncs = append(collectorFuncs, func(ch chan&lt;- prom.Metric) </span><span class="cov8" title="1">{
                                        log.V(5).Info("Collecting metrics for reporting", "package", pkg.GetID(), "NBIO ID", nbioID)
                                        if val, err := readFunc(pkg, E(nbioID)); err == nil </span><span class="cov8" title="1">{
                                                ch &lt;- prom.MustNewConstMetric(
                                                        desc,
                                                        metricType,
                                                        float64(val),
                                                        strconv.Itoa(int(pkg.GetID())),
                                                        strconv.Itoa(nbioID),
                                                )
                                        }</span> else<span class="cov0" title="0"> {
                                                log.V(5).Info(fmt.Sprintf("error reading metric value, err: %v", err), "package", pkg.GetID(),
                                                        "NBIO ID", nbioID)
                                        }</span>
                                })
                        }
                }
        })
        <span class="cov8" title="1">log.V(4).Info("New Package &amp; NBIO prometheus Collector created")

        return collectorImpl{
                describeFunc: func(ch chan&lt;- *prom.Desc) </span><span class="cov8" title="1">{
                        ch &lt;- desc
                }</span>,
                collectFunc: func(ch chan&lt;- prom.Metric) <span class="cov8" title="1">{
                        for _, collectFunc := range collectorFuncs </span><span class="cov8" title="1">{
                                collectFunc(ch)
                        }</span>
                },
        }
}

// newPackageIOLinkCollector is generic factory of prometheus Collectors for metrics
// that are taking package and IO link as parameters.
// host is instance of power optimization library Host that exposes system topology.
// readFunc is generic function which signature corresponds to methods of southbound telemetry clients.
// log is Logger that should have all Names, KeysValues and other... already attached.
// return prometheus Collector that is ready for registration.
func newPackageIOLinkCollector[T number](metricName, metricDesc string, metricType prom.ValueType,
        host power.Host, readFunc func(power.Package, string) (T, error), log logr.Logger,
) prom.Collector <span class="cov8" title="1">{
        desc := prom.NewDesc(metricName,
                metricDesc,
                []string{"package", "io_link"},
                nil,
        )

        collectorFuncs := make([]func(ch chan&lt;- prom.Metric), 0)
        util.IterateOverPackages(host, func(pkg power.Package) </span><span class="cov8" title="1">{
                for _, ioLink := range supportedIOLinks </span><span class="cov8" title="1">{
                        if _, err := readFunc(pkg, ioLink); errors.Is(err, metrics.ErrMetricMissing) </span><span class="cov8" title="1">{
                                log.Info("Not registering collection, client will not be able to read this metric",
                                        "error", err.Error(), "package", pkg.GetID(), "IO link", ioLink)
                        }</span> else<span class="cov8" title="1"> {
                                collectorFuncs = append(collectorFuncs, func(ch chan&lt;- prom.Metric) </span><span class="cov8" title="1">{
                                        log.V(5).Info("Collecting metrics for reporting", "package", pkg.GetID(), "IO link", ioLink)
                                        if val, err := readFunc(pkg, ioLink); err == nil </span><span class="cov8" title="1">{
                                                ch &lt;- prom.MustNewConstMetric(
                                                        desc,
                                                        metricType,
                                                        float64(val),
                                                        strconv.Itoa(int(pkg.GetID())),
                                                        ioLink,
                                                )
                                        }</span> else<span class="cov0" title="0"> {
                                                log.V(5).Info(fmt.Sprintf("error reading metric value, err: %v", err),
                                                        "package", pkg.GetID(), "IO link", ioLink)
                                        }</span>
                                })
                        }
                }
        })
        <span class="cov8" title="1">log.V(4).Info("New Package &amp; IO Link prometheus Collector created")

        return collectorImpl{
                describeFunc: func(ch chan&lt;- *prom.Desc) </span><span class="cov8" title="1">{
                        ch &lt;- desc
                }</span>,
                collectFunc: func(ch chan&lt;- prom.Metric) <span class="cov8" title="1">{
                        for _, collectFunc := range collectorFuncs </span><span class="cov8" title="1">{
                                collectFunc(ch)
                        }</span>
                },
        }
}

// newPerIOLinkCollector is generic factory of prometheus Collectors for metrics that are IO link bound.
// host is instance of power optimization library Host that exposes system topology.
// readFunc is generic function which signature corresponds to methods of southbound telemetry clients.
// log is Logger that should have all Names, KeysValues and other... already attached.
// return prometheus Collector that is ready for registration.
func newPerIOLinkCollector[T number](metricName, metricDesc string, metricType prom.ValueType,
        readFunc func(string) (T, error), log logr.Logger,
) prom.Collector <span class="cov8" title="1">{
        desc := prom.NewDesc(
                metricName,
                metricDesc,
                []string{"io_link"},
                nil,
        )

        collectorFuncs := make([]func(ch chan&lt;- prom.Metric), 0)
        for _, ioLink := range supportedIOLinks </span><span class="cov8" title="1">{
                if _, err := readFunc(ioLink); errors.Is(err, metrics.ErrMetricMissing) </span><span class="cov8" title="1">{
                        log.Info("Not registering collection, client will not be able to read this metric",
                                "error", err.Error(), "IO link", ioLink)
                }</span> else<span class="cov8" title="1"> {
                        collectorFuncs = append(collectorFuncs, func(ch chan&lt;- prom.Metric) </span><span class="cov8" title="1">{
                                log.V(5).Info("Collecting metrics for reporting", "IO link", ioLink)
                                if val, err := readFunc(ioLink); err == nil </span><span class="cov8" title="1">{
                                        ch &lt;- prom.MustNewConstMetric(
                                                desc,
                                                metricType,
                                                float64(val),
                                                ioLink,
                                        )
                                }</span> else<span class="cov0" title="0"> {
                                        log.V(5).Info(fmt.Sprintf("error reading metric value, err: %v", err), "IO link", ioLink)
                                }</span>
                        })
                }
        }
        <span class="cov8" title="1">log.V(4).Info("New perIOLink prometheus Collector created")

        return collectorImpl{
                describeFunc: func(ch chan&lt;- *prom.Desc) </span><span class="cov8" title="1">{
                        ch &lt;- desc
                }</span>,
                collectFunc: func(ch chan&lt;- prom.Metric) <span class="cov8" title="1">{
                        for _, collectFunc := range collectorFuncs </span><span class="cov8" title="1">{
                                collectFunc(ch)
                        }</span>
                },
        }
}
</pre>
		
		<pre class="file" id="file34" style="display: none">package monitoring

import (
        "github.com/intel/kubernetes-power-manager/internal/metrics"
        "github.com/intel/power-optimization-library/pkg/power"

        "github.com/go-logr/logr"
        prom "github.com/prometheus/client_golang/prometheus"
        ctrlMetrics "sigs.k8s.io/controller-runtime/pkg/metrics"
)

func RegisterMSRCollectors(msrClient *metrics.MSRClient, host power.Host, logger logr.Logger) <span class="cov0" title="0">{
        logger = logger.WithName(msrSubsystem)

        ctrlMetrics.Registry.MustRegister(
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, msrSubsystem, "c0_residency_percent"),
                        "Gauge of CPU residency in C0",
                        prom.GaugeValue,
                        host,
                        msrClient.GetC0ResidencyPercent,
                        logger.WithValues(logNameKey, "c0_residency_percent"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, msrSubsystem, "cx_residency_percent"),
                        "Gauge of CPU residency in C-states other than C0",
                        prom.GaugeValue,
                        host,
                        msrClient.GetCxResidencyPercent,
                        logger.WithValues(logNameKey, "cx_residency_percent"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, msrSubsystem, "package_energy_consumption_joules_total"),
                        "Counter of total package energy consumption in joules",
                        prom.CounterValue,
                        host,
                        msrClient.GetPackageEnergyConsumption,
                        logger.WithValues(logNameKey, "package_energy_consumption_joules_total"),
                ),
                newPerCoreCollector(
                        prom.BuildFQName(promNamespace, msrSubsystem, "core_energy_consumption_joules_total"),
                        "Counter of total core energy consumption in joules",
                        prom.CounterValue,
                        host,
                        msrClient.GetCoreEnergyConsumption,
                        logger.WithValues(logNameKey, "core_energy_consumption_joules_total"),
                ),
        )
}</span>
</pre>
		
		<pre class="file" id="file35" style="display: none">package monitoring

import (
        "github.com/intel/kubernetes-power-manager/internal/metrics"
        "github.com/intel/power-optimization-library/pkg/power"

        "github.com/go-logr/logr"
        prom "github.com/prometheus/client_golang/prometheus"
        ctrlMetrics "sigs.k8s.io/controller-runtime/pkg/metrics"
)

func RegisterPerfEventCollectors(perfEventClient *metrics.PerfEventClient, host power.Host, logger logr.Logger) <span class="cov0" title="0">{
        logger = logger.WithName(perfSubsystem)

        // Type hardware
        ctrlMetrics.Registry.MustRegister(
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cycles_total"),
                        "Counter of cycles on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetCycles,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "cycles_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "instructions_total"),
                        "Counter of retired instructions on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetInstructions,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "instructions_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_accesses_total"),
                        "Counter of cache accesses on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetCacheAccesses,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "cache_accesses_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_misses_total"),
                        "Counter of cache misses on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetCacheMisses,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "cache_misses_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "branch_instructions_total"),
                        "Counter of retired branch instructions on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBranchInstructions,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "branch_instructions_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "branch_misses_total"),
                        "Counter of mispredicted branch instructions on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBranchMisses,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "branch_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "bus_cycles_total"),
                        "Counter of bus cycles on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBusCycles,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "bus_cycles_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "stalled_cycles_frontend_total"),
                        "Counter of stalled cycles during issue on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetStalledCyclesFrontend,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "stalled_cycles_frontend_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "stalled_cycles_backend_total"),
                        "Counter of stalled cycles during retirement on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetStalledCyclesBackend,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "stalled_cycles_backend_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "ref_cycles_total"),
                        "Counter of cycles not affected by frequency scaling on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetRefCycles,
                        logger.WithValues(logTypeKey, logTypeHardware, logNameKey, "ref_cycles_total"),
                ),
                // Type software
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "bpf_output_total"),
                        "Counter of BPF outputs on specific CPU",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBPFOutput,
                        logger.WithValues(logTypeKey, logTypeSoftware, logNameKey, "bpf_output_total"),
                ),
                // Type cache
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1d_read_accesses_total"),
                        "Counter of level 1 data cache total read accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1DCacheReadAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1d_read_accesses_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1d_read_misses_total"),
                        "Counter of level 1 data cache total read misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1DCacheReadMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1d_read_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1d_write_accesses_total"),
                        "Counter of level 1 data cache total write accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1DCacheWriteAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1d_write_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1d_write_misses_total"),
                        "Counter of level 1 data cache total write misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1DCacheWriteMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1d_write_misses_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1d_prefetch_accesses_total"),
                        "Counter of level 1 data cache total prefetch accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1DCachePrefetchAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1d_prefetch_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1d_prefetch_misses_total"),
                        "Counter of level 1 data cache total prefetch misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1DCachePrefetchMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1d_prefetch_misses_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1i_read_accesses_total"),
                        "Counter of level 1 instruction cache total read accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1ICacheReadAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1i_read_accesses_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1i_read_misses_total"),
                        "Counter of level 1 instruction cache total read misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1ICacheReadMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1i_read_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1i_write_accesses_total"),
                        "Counter of level 1 instruction cache total write accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1ICacheWriteAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1i_write_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1i_write_misses_total"),
                        "Counter of level 1 instruction cache total write misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1ICacheWriteMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1i_write_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1i_prefetch_accesses_total"),
                        "Counter of level 1 instruction cache total prefetch accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1ICachePrefetchAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1i_prefetch_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_l1i_prefetch_misses_total"),
                        "Counter of level 1 instruction cache total prefetch misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetL1ICachePrefetchMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_l1i_prefetch_misses_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_bpu_read_accesses_total"),
                        "Counter of branch prediction unit cache total read accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBPUCacheReadAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_bpu_read_accesses_total"),
                ),
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_bpu_read_misses_total"),
                        "Counter of branch prediction unit cache total read misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBPUCacheReadMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_bpu_read_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_bpu_write_accesses_total"),
                        "Counter of branch prediction unit cache total write accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBPUCacheWriteAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_bpu_write_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_bpu_write_misses_total"),
                        "Counter of branch prediction unit cache total write misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBPUCacheWriteMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_bpu_write_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_bpu_prefetch_accesses_total"),
                        "Counter of branch prediction unit cache total prefetch accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBPUCachePrefetchAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_bpu_prefetch_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_bpu_prefetch_misses_total"),
                        "Counter of branch prediction unit cache total prefetch misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetBPUCachePrefetchMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_bpu_prefetch_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_node_read_accesses_total"),
                        "Counter of node cache total read accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetNodeCacheReadAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_node_read_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_node_read_misses_total"),
                        "Counter of node cache total read misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetNodeCacheReadMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_node_read_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_node_write_accesses_total"),
                        "Counter of node cache total write accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetNodeCacheWriteAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_node_write_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_node_write_misses_total"),
                        "Counter of node cache total write misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetNodeCacheWriteMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_node_write_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_node_prefetch_accesses_total"),
                        "Counter of node cache total prefetch accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetNodeCachePrefetchAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_node_prefetch_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerCPUCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_node_prefetch_misses_total"),
                        "Counter of node cache total prefetch misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetNodeCachePrefetchMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_node_prefetch_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerDieCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_ll_read_accesses_total"),
                        "Counter of last level cache total read accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetLLCacheReadAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_ll_read_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerDieCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_ll_read_misses_total"),
                        "Counter of last level cache total read misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetLLCacheReadMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_ll_read_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerDieCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_ll_write_accesses_total"),
                        "Counter of last level cache total write accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetLLCacheWriteAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_ll_write_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerDieCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_ll_write_misses_total"),
                        "Counter of last level cache total write misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetLLCacheWriteMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_ll_write_misses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerDieCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_ll_prefetch_accesses_total"),
                        "Counter of last level cache total prefetch accesses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetLLCachePrefetchAccesses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_ll_prefetch_accesses_total"),
                ),
                // not verified, not supported by linux kernel as of 2024/11
                newPerDieCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "cache_ll_prefetch_misses_total"),
                        "Counter of last level cache total prefetch misses",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetLLCachePrefetchMisses,
                        logger.WithValues(logTypeKey, logTypeCache, logNameKey, "cache_ll_prefetch_misses_total"),
                ),
                newPerPackageCollector(
                        prom.BuildFQName(promNamespace, perfSubsystem, "package_energy_consumption_joules_total"),
                        "Counter of total package energy consumption in joules",
                        prom.CounterValue,
                        host,
                        perfEventClient.GetPackageEnergyConsumption,
                        logger.WithValues(logTypeKey, logTypePower, logNameKey, "package_energy_consumption_joules_total"),
                ),
        )
}</span>
</pre>
		
		<pre class="file" id="file36" style="display: none">package scaling

import (
        "fmt"
        "os"
        "path/filepath"
        "strconv"
        "strings"
)

const (
        userspaceGovernor = "userspace"
        cpuFreqBasePath   = "/sys/devices/system/cpu/cpu%d/cpufreq"
)

func getCPUFreqPath(cpu uint, resource string) string <span class="cov0" title="0">{
        cpuFreqPath := fmt.Sprintf(cpuFreqBasePath, cpu)
        return filepath.Join(cpuFreqPath, resource)
}</span>

var getCPUFreqPathFunction = getCPUFreqPath

// get current governor
func getCurrentGovernor(cpu uint) (string, error) <span class="cov8" title="1">{
        governorPath := getCPUFreqPathFunction(cpu, "scaling_governor")

        currentGovernor, err := os.ReadFile(governorPath)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to read current governor for cpu %d: %w", cpu, err)
        }</span>
        <span class="cov8" title="1">return strings.TrimSpace(string(currentGovernor)), nil</span>
}

func isUserspaceGovernor(cpu uint) (bool, error) <span class="cov8" title="1">{
        governor, err := getCurrentGovernor(cpu)
        if err != nil </span><span class="cov0" title="0">{
                return false, fmt.Errorf("failed to read current governor for cpu %d: %w", cpu, err)
        }</span>
        <span class="cov8" title="1">return governor == userspaceGovernor, nil</span>
}

// setCPUFrequency sets the CPU frequency in kHz for the specified CPU using the userspace governor.
func setCPUFrequency(cpu uint, frequency uint) error <span class="cov8" title="1">{
        // check that the userspace governor is enabled
        isUserspace, err := isUserspaceGovernor(cpu)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get userspace governor for CPU %d: %w", cpu, err)
        }</span>

        <span class="cov8" title="1">if !isUserspace </span><span class="cov0" title="0">{
                return fmt.Errorf("userspace governor not set for CPU %d", cpu)
        }</span>

        <span class="cov8" title="1">scalingSetspeedPath := getCPUFreqPathFunction(cpu, "scaling_setspeed")
        // Set the desired frequency
        err = os.WriteFile(scalingSetspeedPath, []byte(fmt.Sprintf("%d", frequency)), 0644)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to set frequency for CPU %d: %w", cpu, err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// getCPUFrequency returns the CPU frequency in kHz for the specified CPU.
func getCPUFrequency(cpu uint) (uint, error) <span class="cov8" title="1">{
        scalingGetFreqPath := getCPUFreqPathFunction(cpu, "scaling_cur_freq")

        freqData, err := os.ReadFile(scalingGetFreqPath)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to read current frequency for CPU %d: %w", cpu, err)
        }</span>

        <span class="cov8" title="1">freqStr := strings.TrimSpace(string(freqData))
        freq, err := strconv.ParseUint(freqStr, 10, 64)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to convert frequency for CPU %d to uint: %w", cpu, err)
        }</span>

        <span class="cov8" title="1">return uint(freq), nil</span>
}
</pre>
		
		<pre class="file" id="file37" style="display: none">package scaling

import (
        "context"
        "os"
        "sync"

        "github.com/go-logr/logr"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/manager"

        "github.com/intel/power-optimization-library/pkg/power"
)

// Func definitions for unit testing
var (
        newCPUScalingWorkerFunc = NewCPUScalingWorker
)

type CPUScalingManager interface {
        manager.Runnable
        UpdateConfig(optList []CPUScalingOpts)
}

type cpuScalingManagerImpl struct {
        powerLibrary *power.Host
        workers      sync.Map
        logger       logr.Logger
}

func NewCPUScalingManager(powerLib *power.Host) CPUScalingManager <span class="cov0" title="0">{
        nodeName := os.Getenv("NODE_NAME")

        mgr := &amp;cpuScalingManagerImpl{
                powerLibrary: powerLib,
                logger:       ctrl.Log.WithName("CPUScalingManager").WithName(nodeName),
        }

        return mgr
}</span>

func (s *cpuScalingManagerImpl) Start(ctx context.Context) error <span class="cov8" title="1">{
        &lt;-ctx.Done()
        s.stop()
        return nil
}</span>

func (s *cpuScalingManagerImpl) stop() <span class="cov8" title="1">{
        s.logger.V(5).Info("stopping all workers")

        managedCPUs := s.getManagedCPUIDs()

        for _, cpuID := range managedCPUs </span><span class="cov8" title="1">{
                worker, found := s.getCPUScalingWorker(cpuID)
                if found </span><span class="cov8" title="1">{
                        worker.Stop()
                        s.workers.Delete(cpuID)
                        s.logger.V(5).Info("worker stopped successfully", "cpuID", cpuID)
                }</span>
        }

        <span class="cov8" title="1">s.logger.V(5).Info("successfully stopped all")</span>
}

func (s *cpuScalingManagerImpl) UpdateConfig(optsList []CPUScalingOpts) <span class="cov8" title="1">{
        incomingManagedCPUs := map[uint]struct{}{}
        currentManagedCPUs := s.getManagedCPUIDs()

        // create or update workers as per new config
        for _, opts := range optsList </span><span class="cov8" title="1">{
                incomingManagedCPUs[opts.CPUID] = struct{}{}

                worker, found := s.getCPUScalingWorker(opts.CPUID)
                if !found </span><span class="cov8" title="1">{
                        s.logger.V(5).Info("creating worker", "cpuID", opts.CPUID)

                        s.workers.Store(
                                opts.CPUID,
                                newCPUScalingWorkerFunc(
                                        opts.CPUID,
                                        s.powerLibrary,
                                        &amp;opts,
                                ),
                        )
                }</span> else<span class="cov8" title="1"> {
                        worker.UpdateOpts(&amp;opts)
                }</span>
        }

        // stop workers on cpus that are no longer managed
        <span class="cov8" title="1">for _, cpuID := range currentManagedCPUs </span><span class="cov8" title="1">{
                if _, contains := incomingManagedCPUs[cpuID]; !contains </span><span class="cov8" title="1">{
                        s.logger.V(5).Info("stopping  worker", "cpuID", cpuID)

                        worker, found := s.workers.LoadAndDelete(cpuID)
                        if !found </span><span class="cov0" title="0">{
                                s.logger.V(5).Info("worker already stopped", "cpuID", cpuID)
                        }</span> else<span class="cov8" title="1"> {
                                worker := worker.(CPUScalingWorker)
                                worker.Stop()
                                s.logger.V(5).Info("worker stopped successfully", "cpuID", cpuID)
                        }</span>
                }
        }
}

func (s *cpuScalingManagerImpl) getManagedCPUIDs() []uint <span class="cov8" title="1">{
        managedCPUs := make([]uint, 0)
        s.workers.Range(func(key, value any) bool </span><span class="cov8" title="1">{
                managedCPUs = append(managedCPUs, key.(uint))
                return true
        }</span>)

        <span class="cov8" title="1">return managedCPUs</span>
}

func (s *cpuScalingManagerImpl) getCPUScalingWorker(cpuID uint) (CPUScalingWorker, bool) <span class="cov8" title="1">{
        if value, found := s.workers.Load(cpuID); found </span><span class="cov8" title="1">{
                return value.(CPUScalingWorker), true
        }</span>

        <span class="cov8" title="1">return nil, false</span>
}
</pre>
		
		<pre class="file" id="file38" style="display: none">package scaling

import (
        "github.com/intel/power-optimization-library/pkg/power"
)

type CPUScalingUpdater interface {
        Update(opts *CPUScalingOpts)
}

type cpuScalingUpdaterImpl struct {
        powerLibrary *power.Host
}

func NewCPUScalingUpdater(powerLib *power.Host) CPUScalingUpdater <span class="cov0" title="0">{
        updater := &amp;cpuScalingUpdaterImpl{
                powerLibrary: powerLib,
        }

        return updater
}</span>

func (u *cpuScalingUpdaterImpl) Update(opts *CPUScalingOpts) {<span class="cov0" title="0">
        // TODO: implement perodic scaling actions
}</span>
</pre>
		
		<pre class="file" id="file39" style="display: none">package scaling

import (
        "context"
        "sync"
        "sync/atomic"
        "time"

        "github.com/intel/power-optimization-library/pkg/power"
)

type CPUScalingWorker interface {
        UpdateOpts(opts *CPUScalingOpts)
        Stop()
}

type cpuScalingWorkerImpl struct {
        cpuID      uint
        opts       atomic.Pointer[CPUScalingOpts]
        cancelFunc func()
        waitGroup  sync.WaitGroup
        updater    CPUScalingUpdater
}

func NewCPUScalingWorker(cpuID uint, powerLib *power.Host, opts *CPUScalingOpts) CPUScalingWorker <span class="cov0" title="0">{
        ctx, cancelFunc := context.WithCancel(context.Background())

        worker := &amp;cpuScalingWorkerImpl{
                cpuID:      cpuID,
                cancelFunc: cancelFunc,
                waitGroup:  sync.WaitGroup{},
        }

        worker.opts.Store(opts)
        worker.updater = NewCPUScalingUpdater(powerLib)
        worker.waitGroup.Add(1)

        go worker.runLoop(ctx)

        return worker
}</span>

func (w *cpuScalingWorkerImpl) UpdateOpts(opts *CPUScalingOpts) <span class="cov8" title="1">{
        w.opts.Store(opts)
}</span>

func (w *cpuScalingWorkerImpl) Stop() <span class="cov8" title="1">{
        w.cancelFunc()
        w.waitGroup.Wait()
}</span>

func (w *cpuScalingWorkerImpl) runLoop(ctx context.Context) <span class="cov8" title="1">{
        defer w.waitGroup.Done()

        for </span><span class="cov8" title="1">{
                opts := w.opts.Load()
                select </span>{
                case &lt;-ctx.Done():<span class="cov8" title="1">
                        return</span>
                case &lt;-time.After(opts.SamplePeriod):<span class="cov8" title="1">
                        w.updater.Update(opts)</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file40" style="display: none">/*
Copyright 2017 The Kubernetes Authors.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
    http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package cpuset

import (
        "bytes"
        "fmt"
        "reflect"
        "sort"
        "strconv"
        "strings"

        "k8s.io/klog/v2"
)

// Builder is a mutable builder for CPUSet. Functions that mutate instances
// of this type are not thread-safe.
type Builder struct {
        result CPUSet
        done   bool
}

// NewBuilder returns a mutable CPUSet builder.
func NewBuilder() Builder <span class="cov8" title="1">{
        return Builder{
                result: CPUSet{
                        elems: map[int]struct{}{},
                },
        }
}</span>

// Add adds the supplied elements to the result. Calling Add after calling
// Result has no effect.
func (b *Builder) Add(elems ...int) <span class="cov8" title="1">{
        if b.done </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">for _, elem := range elems </span><span class="cov8" title="1">{
                b.result.elems[elem] = struct{}{}
        }</span>
}

// Result returns the result CPUSet containing all elements that were
// previously added to this builder. Subsequent calls to Add have no effect.
func (b *Builder) Result() CPUSet <span class="cov8" title="1">{
        b.done = true
        return b.result
}</span>

// CPUSet is a thread-safe, immutable set-like data structure for CPU IDs.
type CPUSet struct {
        elems map[int]struct{}
}

// NewCPUSet returns a new CPUSet containing the supplied elements.
func NewCPUSet(cpus ...int) CPUSet <span class="cov8" title="1">{
        b := NewBuilder()
        for _, c := range cpus </span><span class="cov8" title="1">{
                b.Add(c)
        }</span>
        <span class="cov8" title="1">return b.Result()</span>
}

// Size returns the number of elements in this set.
func (s *CPUSet) Size() int <span class="cov8" title="1">{
        return len(s.elems)
}</span>

// IsEmpty returns true if there are zero elements in this set.
func (s *CPUSet) IsEmpty() bool <span class="cov8" title="1">{
        return s.Size() == 0
}</span>

// Contains returns true if the supplied element is present in this set.
func (s *CPUSet) Contains(cpu int) bool <span class="cov8" title="1">{
        _, found := s.elems[cpu]
        return found
}</span>

// Equals returns true if the supplied set contains exactly the same elements
// as this set (s IsSubsetOf s2 and s2 IsSubsetOf s).
func (s *CPUSet) Equals(s2 CPUSet) bool <span class="cov8" title="1">{
        return reflect.DeepEqual(s.elems, s2.elems)
}</span>

// Filter returns a new CPU set that contains all of the elements from this
// set that match the supplied predicate, without mutating the source set.
func (s *CPUSet) Filter(predicate func(int) bool) CPUSet <span class="cov8" title="1">{
        b := NewBuilder()
        for cpu := range s.elems </span><span class="cov8" title="1">{
                if predicate(cpu) </span><span class="cov8" title="1">{
                        b.Add(cpu)
                }</span>
        }
        <span class="cov8" title="1">return b.Result()</span>
}

// FilterNot returns a new CPU set that contains all of the elements from this
// set that do not match the supplied predicate, without mutating the source
// set.
func (s *CPUSet) FilterNot(predicate func(int) bool) CPUSet <span class="cov8" title="1">{
        b := NewBuilder()
        for cpu := range s.elems </span><span class="cov8" title="1">{
                if !predicate(cpu) </span><span class="cov8" title="1">{
                        b.Add(cpu)
                }</span>
        }
        <span class="cov8" title="1">return b.Result()</span>
}

// IsSubsetOf returns true if the supplied set contains all the elements
func (s *CPUSet) IsSubsetOf(s2 CPUSet) bool <span class="cov8" title="1">{
        result := true
        for cpu := range s.elems </span><span class="cov8" title="1">{
                if !s2.Contains(cpu) </span><span class="cov8" title="1">{
                        result = false
                        break</span>
                }
        }
        <span class="cov8" title="1">return result</span>
}

// Union returns a new CPU set that contains all of the elements from this
// set and all of the elements from the supplied set, without mutating
// either source set.
func (s *CPUSet) Union(s2 CPUSet) CPUSet <span class="cov8" title="1">{
        b := NewBuilder()
        for cpu := range s.elems </span><span class="cov0" title="0">{
                b.Add(cpu)
        }</span>
        <span class="cov8" title="1">for cpu := range s2.elems </span><span class="cov8" title="1">{
                b.Add(cpu)
        }</span>
        <span class="cov8" title="1">return b.Result()</span>
}

// UnionAll returns a new CPU set that contains all of the elements from this
// set and all of the elements from the supplied sets, without mutating
// either source set.
func (s *CPUSet) UnionAll(s2 []CPUSet) CPUSet <span class="cov8" title="1">{
        b := NewBuilder()
        for cpu := range s.elems </span><span class="cov8" title="1">{
                b.Add(cpu)
        }</span>
        <span class="cov8" title="1">for _, cs := range s2 </span><span class="cov8" title="1">{
                for cpu := range cs.elems </span><span class="cov8" title="1">{
                        b.Add(cpu)
                }</span>
        }
        <span class="cov8" title="1">return b.Result()</span>
}

// Intersection returns a new CPU set that contains all of the elements
// that are present in both this set and the supplied set, without mutating
// either source set.
func (s *CPUSet) Intersection(s2 CPUSet) CPUSet <span class="cov8" title="1">{
        return s.Filter(func(cpu int) bool </span><span class="cov8" title="1">{ return s2.Contains(cpu) }</span>)
}

// Difference returns a new CPU set that contains all of the elements that
// are present in this set and not the supplied set, without mutating either
// source set.
func (s *CPUSet) Difference(s2 CPUSet) CPUSet <span class="cov8" title="1">{
        return s.FilterNot(func(cpu int) bool </span><span class="cov8" title="1">{ return s2.Contains(cpu) }</span>)
}

// ToSlice returns a slice of integers that contains all elements from
// this set.
func (s *CPUSet) ToSlice() []int <span class="cov8" title="1">{
        result := []int{}
        for cpu := range s.elems </span><span class="cov8" title="1">{
                result = append(result, cpu)
        }</span>
        <span class="cov8" title="1">sort.Ints(result)
        return result</span>
}

// ToSliceNoSort returns a slice of integers that contains all elements from
// this set.
func (s *CPUSet) ToSliceNoSort() []int <span class="cov8" title="1">{
        result := []int{}
        for cpu := range s.elems </span><span class="cov8" title="1">{
                result = append(result, cpu)
        }</span>
        <span class="cov8" title="1">return result</span>
}

// ToSliceInt64 returns an ordered slice of int64 that contains all elements from
// this set
func (s *CPUSet) ToSliceInt64() []int64 <span class="cov8" title="1">{
        var result []int64
        for cpu := range s.elems </span><span class="cov8" title="1">{
                result = append(result, int64(cpu))
        }</span>
        <span class="cov8" title="1">sort.Slice(result, func(i, j int) bool </span><span class="cov8" title="1">{ return result[i] &lt; result[j] }</span>)
        <span class="cov8" title="1">return result</span>
}

// ToSliceNoSortInt64 returns a slice of int64 that contains all elements from
// this set.
func (s *CPUSet) ToSliceNoSortInt64() []int64 <span class="cov8" title="1">{
        var result []int64
        for cpu := range s.elems </span><span class="cov8" title="1">{
                result = append(result, int64(cpu))
        }</span>
        <span class="cov8" title="1">return result</span>
}

// String returns a new string representation of the elements in this CPU set
// in canonical linux CPU list format.
//
// See: http://man7.org/linux/man-pages/man7/cpuset.7.html#FORMATS
func (s *CPUSet) String() string <span class="cov8" title="1">{
        if s.IsEmpty() </span><span class="cov8" title="1">{
                return ""
        }</span>

        <span class="cov8" title="1">elems := s.ToSlice()

        type rng struct {
                start int
                end   int
        }

        ranges := []rng{{elems[0], elems[0]}}

        for i := 1; i &lt; len(elems); i++ </span><span class="cov8" title="1">{
                lastRange := &amp;ranges[len(ranges)-1]
                // if this element is adjacent to the high end of the last range
                if elems[i] == lastRange.end+1 </span><span class="cov8" title="1">{
                        // then extend the last range to include this element
                        lastRange.end = elems[i]
                        continue</span>
                }
                // otherwise, start a new range beginning with this element
                <span class="cov8" title="1">ranges = append(ranges, rng{elems[i], elems[i]})</span>
        }

        // construct string from ranges
        <span class="cov8" title="1">var result bytes.Buffer
        for _, r := range ranges </span><span class="cov8" title="1">{
                if r.start == r.end </span><span class="cov8" title="1">{
                        result.WriteString(strconv.Itoa(r.start))
                }</span> else<span class="cov8" title="1"> {
                        result.WriteString(fmt.Sprintf("%d-%d", r.start, r.end))
                }</span>
                <span class="cov8" title="1">result.WriteString(",")</span>
        }
        <span class="cov8" title="1">return strings.TrimRight(result.String(), ",")</span>
}

// MustParse CPUSet constructs a new CPU set from a Linux CPU list formatted
// string. Unlike Parse, it does not return an error but rather panics if the
// input cannot be used to construct a CPU set.
func MustParse(s string) CPUSet <span class="cov8" title="1">{
        res, err := Parse(s)
        if err != nil </span><span class="cov0" title="0">{
                klog.Fatalf("unable to parse [%s] as CPUSet: %v", s, err)
        }</span>
        <span class="cov8" title="1">return res</span>
}

// Parse CPUSet constructs a new CPU set from a Linux CPU list formatted string.
//
// See: http://man7.org/linux/man-pages/man7/cpuset.7.html#FORMATS
func Parse(s string) (CPUSet, error) <span class="cov8" title="1">{
        b := NewBuilder()

        // Handle empty string.
        if s == "" </span><span class="cov8" title="1">{
                return b.Result(), nil
        }</span>

        // Split CPU list string:
        // "0-5,34,46-48 =&gt; ["0-5", "34", "46-48"]
        <span class="cov8" title="1">ranges := strings.Split(s, ",")

        for _, r := range ranges </span><span class="cov8" title="1">{
                boundaries := strings.Split(r, "-")
                if len(boundaries) == 1 </span><span class="cov8" title="1">{
                        // Handle ranges that consist of only one element like "34".
                        elem, err := strconv.Atoi(boundaries[0])
                        if err != nil </span><span class="cov0" title="0">{
                                return NewCPUSet(), err
                        }</span>
                        <span class="cov8" title="1">b.Add(elem)</span>
                } else<span class="cov8" title="1"> if len(boundaries) == 2 </span><span class="cov8" title="1">{
                        // Handle multi-element ranges like "0-5".
                        start, err := strconv.Atoi(boundaries[0])
                        if err != nil </span><span class="cov0" title="0">{
                                return NewCPUSet(), err
                        }</span>
                        <span class="cov8" title="1">end, err := strconv.Atoi(boundaries[1])
                        if err != nil </span><span class="cov0" title="0">{
                                return NewCPUSet(), err
                        }</span>
                        // Add all elements to the result.
                        // e.g. "0-5", "46-48" =&gt; [0, 1, 2, 3, 4, 5, 46, 47, 48].
                        <span class="cov8" title="1">for e := start; e &lt;= end; e++ </span><span class="cov8" title="1">{
                                b.Add(e)
                        }</span>
                }
        }
        <span class="cov8" title="1">return b.Result(), nil</span>
}

// Clone returns a copy of this CPU set.
func (s *CPUSet) Clone() CPUSet <span class="cov8" title="1">{
        b := NewBuilder()
        for elem := range s.elems </span><span class="cov8" title="1">{
                b.Add(elem)
        }</span>
        <span class="cov8" title="1">return b.Result()</span>
}
</pre>
		
		<pre class="file" id="file41" style="display: none">package podresourcesclient

import (
        "context"
        "fmt"
        "time"

        "github.com/intel/kubernetes-power-manager/pkg/cpuset"
        "github.com/intel/kubernetes-power-manager/pkg/util"
        "google.golang.org/grpc"
        "google.golang.org/grpc/credentials/insecure"
        "k8s.io/apimachinery/pkg/api/errors"
        podresourcesapi "k8s.io/kubelet/pkg/apis/podresources/v1"
)

var maxMessage = 1024 * 1024 * 4 // size in bytes =&gt; 4MB
var socket = "unix:///var/lib/kubelet/pod-resources/kubelet.sock"
var cPlaneSocket = "unix:///var/lib/kubelet/pod-resources/cci-dra-driver-podrsc.sock"
var cPlaneRetries = 3
var timeout = 2 * time.Minute

// PodResourcesClient stores a client to the Kubelet PodResources API server
type PodResourcesClient struct {
        Client                podresourcesapi.PodResourcesListerClient
        CpuControlPlaneClient podresourcesapi.PodResourcesListerClient
}

// NewPodResourcesClient returns a new client to the Kubelet PodResources API server
func NewPodResourcesClient() (*PodResourcesClient, error) <span class="cov0" title="0">{
        return newClient(socket)
}</span>

// NewControlPlaneClient returns a new client to the CPU control plane socket
func NewControlPlaneClient() (*PodResourcesClient, error) <span class="cov0" title="0">{
        return newClient(cPlaneSocket)
}</span>

func NewDualSocketPodClient() (*PodResourcesClient, error) <span class="cov0" title="0">{
        client, err := NewPodResourcesClient()
        if err != nil </span><span class="cov0" title="0">{
                return client, err
        }</span>
        <span class="cov0" title="0">cPlane, err := NewControlPlaneClient()
        client.CpuControlPlaneClient = cPlane.Client
        return client, err</span>
}

func newClient(socket string) (*PodResourcesClient, error) <span class="cov0" title="0">{
        client, _, err := getV1Client(socket, timeout, maxMessage)
        if err != nil </span><span class="cov0" title="0">{
                return nil, errors.NewServiceUnavailable(fmt.Sprintf("failed to create podresources client: %v", err))
        }</span>
        <span class="cov0" title="0">return &amp;PodResourcesClient{Client: client}, nil</span>
}

// GetV1Client returns a client for the PodResourcesLister grpc service
// https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/podresources/client.go
func getV1Client(socket string, connectionTimeout time.Duration, maxMsgSize int) (podresourcesapi.PodResourcesListerClient, *grpc.ClientConn, error) <span class="cov0" title="0">{
        addr, dialer, err := util.GetAddressAndDialer(socket)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("error getting address and dialer for socket %s: %v", socket, err)
        }</span>
        <span class="cov0" title="0">ctx, cancel := context.WithTimeout(context.Background(), connectionTimeout)
        defer cancel()

        conn, err := grpc.DialContext(ctx, addr,
                grpc.WithTransportCredentials(insecure.NewCredentials()),
                grpc.WithContextDialer(dialer),
                grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(maxMsgSize)))
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("error dialing socket %s: %v", socket, err)
        }</span>
        <span class="cov0" title="0">return podresourcesapi.NewPodResourcesListerClient(conn), conn, nil</span>
}

func (p *PodResourcesClient) listResources(controlPlaneClient bool) (*podresourcesapi.ListPodResourcesResponse, error) <span class="cov8" title="1">{
        var client podresourcesapi.PodResourcesListerClient
        clientType := "default"
        if controlPlaneClient &amp;&amp; p.CpuControlPlaneClient != nil </span><span class="cov0" title="0">{
                client = p.CpuControlPlaneClient
                clientType = "cpuControlPlane"
        }</span> else<span class="cov8" title="1"> {
                client = p.Client
        }</span>

        <span class="cov8" title="1">req := podresourcesapi.ListPodResourcesRequest{}
        resp, err := client.List(context.TODO(), &amp;req)
        // only default client errs are logged as controlplane socket isn't guaranteed to be there
        // otherwise we'd be spamming the logs in static cpu policy deployments
        if err != nil &amp;&amp; clientType == "default" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("can't receive response from %s client: %v", clientType, err)
        }</span>
        <span class="cov8" title="1">return resp, nil</span>
}

// GetContainerCPUs returns a string in cpuset format of CPUs allocated to the container
func (p *PodResourcesClient) GetContainerCPUs(podName, containerName string) (string, error) <span class="cov8" title="1">{
        podresourcesResponse, err := p.listResources(false)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        <span class="cov8" title="1">cpuSetString, err := parseContainers(podresourcesResponse.PodResources, podName, containerName)
        if err != nil </span><span class="cov8" title="1">{
                return "", err
        }</span>
        <span class="cov8" title="1">if cpuSetString == "" </span><span class="cov0" title="0">{
                // if cplane socket responds but has no resources then retry
                // to ensure we get up to date info
                for i := 0; i &lt; cPlaneRetries; i++ </span><span class="cov0" title="0">{
                        podresourcesResponse, err = p.listResources(true)
                        if err != nil </span><span class="cov0" title="0">{
                                return "", err
                        }</span>
                        <span class="cov0" title="0">cpuSetString, err = parseContainers(podresourcesResponse.PodResources, podName, containerName)
                        if err == nil &amp;&amp; cpuSetString != "" </span><span class="cov0" title="0">{
                                return cpuSetString, err
                        }</span>
                }
        }
        <span class="cov8" title="1">return cpuSetString, err</span>
}

func parseContainers(resources []*podresourcesapi.PodResources, podName, containerName string) (string, error) <span class="cov8" title="1">{
        for _, podresource := range resources </span><span class="cov8" title="1">{
                if podresource.Name == podName </span><span class="cov8" title="1">{
                        for _, container := range podresource.Containers </span><span class="cov8" title="1">{
                                if container.Name == containerName </span><span class="cov8" title="1">{
                                        cpuSetString := cpuIDsToString(container.CpuIds)
                                        return cpuSetString, nil
                                }</span>
                        }
                }
        }
        <span class="cov8" title="1">return "", errors.NewServiceUnavailable(fmt.Sprintf("resources for Pod:%v Container:%v not found", podName, containerName))</span>
}

// cpuIDsToString returns a string in cpuset format
func cpuIDsToString(cpuIds []int64) string <span class="cov8" title="1">{
        intSlice := make([]int, 0)
        for _, num := range cpuIds </span><span class="cov8" title="1">{
                intSlice = append(intSlice, int(num))
        }</span>

        <span class="cov8" title="1">cpuSet := cpuset.NewCPUSet(intSlice...)
        cpuSetString := cpuSet.String()

        return cpuSetString</span>
}
</pre>
		
		<pre class="file" id="file42" style="display: none">package podstate

import (
        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
)

type State struct {
        GuaranteedPods []powerv1.GuaranteedPod
}

func NewState() (*State, error) <span class="cov8" title="1">{
        state := &amp;State{}
        guaranteedPods := make([]powerv1.GuaranteedPod, 0)
        state.GuaranteedPods = guaranteedPods

        return state, nil
}</span>

func (s *State) UpdateStateGuaranteedPods(guaranteedPod powerv1.GuaranteedPod) error <span class="cov8" title="1">{
        for i, existingPod := range s.GuaranteedPods </span><span class="cov8" title="1">{
                if existingPod.Name == guaranteedPod.Name &amp;&amp; existingPod.Namespace == guaranteedPod.Namespace </span><span class="cov8" title="1">{
                        s.GuaranteedPods[i] = guaranteedPod
                        return nil
                }</span>
        }

        <span class="cov8" title="1">s.GuaranteedPods = append(s.GuaranteedPods, guaranteedPod)
        return nil</span>
}

func (s *State) GetPodFromState(podName string, podNamespace string) powerv1.GuaranteedPod <span class="cov8" title="1">{
        for _, existingPod := range s.GuaranteedPods </span><span class="cov8" title="1">{
                if existingPod.Name == podName &amp;&amp; existingPod.Namespace == podNamespace </span><span class="cov8" title="1">{
                        return existingPod
                }</span>
        }

        <span class="cov8" title="1">return powerv1.GuaranteedPod{}</span>
}

func (s *State) GetCPUsFromPodState(podState powerv1.GuaranteedPod) []uint <span class="cov8" title="1">{
        cpus := make([]uint, 0)
        for _, container := range podState.Containers </span><span class="cov8" title="1">{
                cpus = append(cpus, container.ExclusiveCPUs...)
        }</span>

        <span class="cov8" title="1">return cpus</span>
}

func (s *State) DeletePodFromState(podName string, podNamespace string) error <span class="cov8" title="1">{
        for i, pod := range s.GuaranteedPods </span><span class="cov8" title="1">{
                if pod.Name == podName &amp;&amp; pod.Namespace == podNamespace </span><span class="cov8" title="1">{
                        s.GuaranteedPods = append(s.GuaranteedPods[:i], s.GuaranteedPods[i+1:]...)
                }</span>
        }

        <span class="cov8" title="1">return nil</span>
}
</pre>
		
		<pre class="file" id="file43" style="display: none">package state

import (
        powerv1 "github.com/intel/kubernetes-power-manager/api/v1"
)

type PowerNodeData struct {
        PowerNodeList []string
}

func NewPowerNodeData() *PowerNodeData <span class="cov8" title="1">{
        return &amp;PowerNodeData{
                PowerNodeList: []string{},
        }
}</span>

func (nd *PowerNodeData) UpdatePowerNodeData(nodeName string) <span class="cov8" title="1">{
        for _, node := range nd.PowerNodeList </span><span class="cov8" title="1">{
                if nodeName == node </span><span class="cov8" title="1">{
                        return
                }</span>
        }

        <span class="cov8" title="1">nd.PowerNodeList = append(nd.PowerNodeList, nodeName)</span>
}

func (nd *PowerNodeData) DeletePowerNodeData(nodeName string) <span class="cov8" title="1">{
        for index, node := range nd.PowerNodeList </span><span class="cov8" title="1">{
                if node == nodeName </span><span class="cov8" title="1">{
                        nd.PowerNodeList = append(nd.PowerNodeList[:index], nd.PowerNodeList[index+1:]...)
                }</span>
        }
}

func (nd *PowerNodeData) Difference(nodeInfo []powerv1.WorkloadNode) []string <span class="cov8" title="1">{
        difference := make([]string, 0)

        for _, node := range nd.PowerNodeList </span><span class="cov8" title="1">{
                if NodeNotInNodeInfo(node, nodeInfo) </span><span class="cov8" title="1">{
                        difference = append(difference, node)
                }</span>
        }

        <span class="cov8" title="1">return difference</span>
}

func NodeNotInNodeInfo(nodeName string, nodeInfo []powerv1.WorkloadNode) bool <span class="cov8" title="1">{
        for _, node := range nodeInfo </span><span class="cov8" title="1">{
                if nodeName == node.Name </span><span class="cov8" title="1">{
                        return false
                }</span>
        }

        <span class="cov8" title="1">return true</span>
}
</pre>
		
		<pre class="file" id="file44" style="display: none">package testutils

import (
        "fmt"
        "net/http"
        "os"
        "path/filepath"
        "strings"

        "context"

        "github.com/go-logr/logr"
        "github.com/intel/power-optimization-library/pkg/power"
        "github.com/stretchr/testify/mock"
        "k8s.io/apimachinery/pkg/runtime"
        "k8s.io/apimachinery/pkg/types"
        "sigs.k8s.io/controller-runtime/pkg/cache"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/config"
        "sigs.k8s.io/controller-runtime/pkg/healthz"
        "sigs.k8s.io/controller-runtime/pkg/manager"
        "sigs.k8s.io/controller-runtime/pkg/webhook"
)

type MockHost struct {
        mock.Mock
        power.Host
}

func (m *MockHost) Topology() power.Topology <span class="cov8" title="1">{
        return m.Called().Get(0).(power.Topology)
}</span>

func (m *MockHost) ValidateCStates(states power.CStates) error <span class="cov8" title="1">{
        return m.Called(states).Error(0)
}</span>

func (m *MockHost) AvailableCStates() []string <span class="cov0" title="0">{
        return m.Called().Get(0).([]string)
}</span>

func (m *MockHost) GetAllExclusivePools() *power.PoolList <span class="cov8" title="1">{
        return m.Called().Get(0).(*power.PoolList)
}</span>

func (m *MockHost) SetName(name string) <span class="cov0" title="0">{
        m.Called(name)
}</span>

func (m *MockHost) GetName() string <span class="cov0" title="0">{
        return m.Called().String(0)
}</span>

func (m *MockHost) GetFreqRanges() power.CoreTypeList <span class="cov8" title="1">{
        return m.Called().Get(0).(power.CoreTypeList)
}</span>

func (m *MockHost) GetFeaturesInfo() power.FeatureSet <span class="cov0" title="0">{
        ret := m.Called().Get(0)
        if ret == nil </span><span class="cov0" title="0">{
                return nil
        }</span> else<span class="cov0" title="0"> {
                return ret.(power.FeatureSet)
        }</span>
}

func (m *MockHost) GetReservedPool() power.Pool <span class="cov8" title="1">{
        ret := m.Called().Get(0)
        if ret == nil </span><span class="cov0" title="0">{
                return nil
        }</span> else<span class="cov8" title="1"> {
                return ret.(power.Pool)
        }</span>
}

func (m *MockHost) GetSharedPool() power.Pool <span class="cov8" title="1">{
        ret := m.Called().Get(0)
        if ret == nil </span><span class="cov0" title="0">{
                return nil
        }</span> else<span class="cov8" title="1"> {
                return ret.(power.Pool)
        }</span>
}
func (m *MockHost) AddExclusivePool(poolName string) (power.Pool, error) <span class="cov8" title="1">{
        args := m.Called(poolName)
        retPool := args.Get(0)
        if retPool == nil </span><span class="cov8" title="1">{
                return nil, args.Error(1)
        }</span> else<span class="cov8" title="1"> {
                return retPool.(power.Pool), args.Error(1)
        }</span>
}

func (m *MockHost) GetExclusivePool(poolName string) power.Pool <span class="cov8" title="1">{
        ret := m.Called(poolName).Get(0)
        if ret == nil </span><span class="cov8" title="1">{
                return nil
        }</span> else<span class="cov8" title="1"> {
                return ret.(power.Pool)
        }</span>
}

func (m *MockHost) GetAllCpus() *power.CpuList <span class="cov8" title="1">{
        ret := m.Called().Get(0)
        if ret == nil </span><span class="cov0" title="0">{
                return nil
        }</span> else<span class="cov8" title="1"> {
                return ret.(*power.CpuList)
        }</span>
}

type MockPool struct {
        mock.Mock
        power.Pool
}

func (m *MockPool) SetCStates(states power.CStates) error <span class="cov8" title="1">{
        return m.Called(states).Error(0)
}</span>

func (m *MockPool) Clear() error <span class="cov0" title="0">{
        return m.Called().Error(0)
}</span>

func (m *MockPool) Name() string <span class="cov8" title="1">{
        return m.Called().String(0)
}</span>

func (m *MockPool) Cpus() *power.CpuList <span class="cov8" title="1">{
        args := m.Called().Get(0)
        if args == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">return args.(*power.CpuList)</span>
}

func (m *MockPool) SetCpus(cores power.CpuList) error <span class="cov0" title="0">{
        return m.Called(cores).Error(0)
}</span>

func (m *MockPool) SetCpuIDs(cpuIDs []uint) error <span class="cov8" title="1">{
        return m.Called(cpuIDs).Error(0)
}</span>

func (m *MockPool) Remove() error <span class="cov8" title="1">{
        return m.Called().Error(0)
}</span>

func (m *MockPool) MoveCpuIDs(coreIDs []uint) error <span class="cov8" title="1">{
        return m.Called(coreIDs).Error(0)
}</span>

func (m *MockPool) MoveCpus(cores power.CpuList) error <span class="cov8" title="1">{
        return m.Called(cores).Error(0)
}</span>

func (m *MockPool) SetPowerProfile(profile power.Profile) error <span class="cov8" title="1">{
        args := m.Called(profile)
        return args.Error(0)
}</span>

func (m *MockPool) GetPowerProfile() power.Profile <span class="cov8" title="1">{
        args := m.Called().Get(0)
        if args == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">return args.(power.Profile)</span>
}

type MockProf struct {
        mock.Mock
        power.Profile
}

func (m *MockProf) Name() string <span class="cov8" title="1">{
        return m.Called().String(0)
}</span>

func (m *MockProf) Epp() string <span class="cov0" title="0">{
        return m.Called().String(0)
}</span>

func (m *MockProf) MaxFreq() uint <span class="cov0" title="0">{
        return uint(m.Called().Int(0))
}</span>

func (m *MockProf) MinFreq() uint <span class="cov0" title="0">{
        return uint(m.Called().Int(0))
}</span>

func (m *MockProf) Governor() string <span class="cov0" title="0">{
        return m.Called().String(0)
}</span>

type MockCPU struct {
        mock.Mock
        power.Cpu
}

func (m *MockCPU) SetCStates(cStates power.CStates) error <span class="cov8" title="1">{
        return m.Called(cStates).Error(0)
}</span>

func (m *MockCPU) GetID() uint <span class="cov8" title="1">{
        return m.Called().Get(0).(uint)
}</span>

func (m *MockCPU) SetPool(pool power.Pool) error <span class="cov0" title="0">{
        return m.Called(pool).Error(0)
}</span>

func MakeCPUList(mockedCPUs ...*MockCPU) power.CpuList <span class="cov8" title="1">{
        cpuList := power.CpuList{}
        for _, mockedCPU := range mockedCPUs </span><span class="cov8" title="1">{
                cpuList = append(cpuList, mockedCPU)
        }</span>

        <span class="cov8" title="1">return cpuList</span>
}

type MockCore struct {
        mock.Mock
        power.Core
}

func (m *MockCore) MakeList() []power.Core <span class="cov8" title="1">{
        return []power.Core{m}
}</span>

func (m *MockCore) CPUs() *power.CpuList <span class="cov8" title="1">{
        args := m.Called().Get(0)
        if args == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">return args.(*power.CpuList)</span>
}

func (m *MockCore) GetID() uint <span class="cov8" title="1">{
        args := m.Called()
        return args.Get(0).(uint)
}</span>

type MockTopology struct {
        mock.Mock
        power.Topology
}

func (m *MockTopology) GetID() uint <span class="cov0" title="0">{
        return m.Called().Get(0).(uint)
}</span>

func (m *MockTopology) SetUncore(uncore power.Uncore) error <span class="cov0" title="0">{
        return m.Called(uncore).Error(0)
}</span>

func (m *MockTopology) applyUncore() error <span class="cov0" title="0">{
        return m.Called().Error(0)
}</span>

func (m *MockTopology) getEffectiveUncore() power.Uncore <span class="cov0" title="0">{
        ret := m.Called()
        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                return ret.Get(0).(power.Uncore)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func (m *MockTopology) addCpu(u uint) (power.Cpu, error) <span class="cov0" title="0">{
        ret := m.Called(u)

        var r0 power.Cpu
        var r1 error

        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                r0 = ret.Get(0).(power.Cpu)
        }</span>
        <span class="cov0" title="0">r1 = ret.Error(1)

        return r0, r1</span>
}

func (m *MockTopology) CPUs() *power.CpuList <span class="cov0" title="0">{
        ret := m.Called()

        var r0 *power.CpuList
        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                r0 = ret.Get(0).(*power.CpuList)
        }</span>

        <span class="cov0" title="0">return r0</span>
}

func (m *MockTopology) Packages() *[]power.Package <span class="cov8" title="1">{
        ret := m.Called()

        var r0 *[]power.Package
        if ret.Get(0) != nil </span><span class="cov8" title="1">{
                r0 = ret.Get(0).(*[]power.Package)

        }</span>
        <span class="cov8" title="1">return r0</span>
}

func (m *MockTopology) Package(id uint) power.Package <span class="cov0" title="0">{
        ret := m.Called(id)

        var r0 power.Package
        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                r0 = ret.Get(0).(power.Package)
        }</span>

        <span class="cov0" title="0">return r0</span>
}

type MockPackage struct {
        mock.Mock
        power.Package
}
type MockPackageList struct {
        mock.Mock
}

func (m *MockPackage) MakeList() []power.Package <span class="cov8" title="1">{
        return []power.Package{m}
}</span>

func (m *MockPackage) GetID() uint <span class="cov8" title="1">{
        return m.Called().Get(0).(uint)
}</span>

func (m *MockPackage) SetUncore(uncore power.Uncore) error <span class="cov0" title="0">{
        return m.Called(uncore).Error(0)
}</span>

func (m *MockPackage) applyUncore() error <span class="cov0" title="0">{
        return m.Called().Error(0)
}</span>

func (m *MockPackage) getEffectiveUncore() power.Uncore <span class="cov0" title="0">{
        ret := m.Called()
        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                return ret.Get(0).(power.Uncore)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func (m *MockPackage) addCpu(u uint) (power.Cpu, error) <span class="cov0" title="0">{
        ret := m.Called(u)

        var r0 power.Cpu
        var r1 error

        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                r0 = ret.Get(0).(power.Cpu)
        }</span>
        <span class="cov0" title="0">r1 = ret.Error(1)

        return r0, r1</span>
}

func (m *MockPackage) CPUs() *power.CpuList <span class="cov8" title="1">{
        ret := m.Called()

        var r0 *power.CpuList
        if ret.Get(0) != nil </span><span class="cov8" title="1">{
                r0 = ret.Get(0).(*power.CpuList)
        }</span>

        <span class="cov8" title="1">return r0</span>
}

func (m *MockPackage) Dies() *[]power.Die <span class="cov8" title="1">{
        ret := m.Called()

        var r0 *[]power.Die
        if ret.Get(0) != nil </span><span class="cov8" title="1">{
                r0 = ret.Get(0).(*[]power.Die)

        }</span>
        <span class="cov8" title="1">return r0</span>
}

func (m *MockPackage) Die(id uint) power.Die <span class="cov0" title="0">{
        ret := m.Called(id)

        var r0 power.Die
        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                r0 = ret.Get(0).(power.Die)
        }</span>

        <span class="cov0" title="0">return r0</span>
}

type MockDie struct {
        mock.Mock
        power.Die
}

func (m *MockDie) MakeList() []power.Die <span class="cov8" title="1">{
        return []power.Die{m}
}</span>

func (m *MockDie) GetID() uint <span class="cov8" title="1">{
        return m.Called().Get(0).(uint)
}</span>

func (m *MockDie) SetUncore(uncore power.Uncore) error <span class="cov0" title="0">{
        return m.Called(uncore).Error(0)
}</span>

func (m *MockDie) applyUncore() error <span class="cov0" title="0">{
        return m.Called().Error(0)
}</span>

func (m *MockDie) getEffectiveUncore() power.Uncore <span class="cov0" title="0">{
        ret := m.Called()
        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                return ret.Get(0).(power.Uncore)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func (m *MockDie) addCpu(u uint) (power.Cpu, error) <span class="cov0" title="0">{
        ret := m.Called(u)

        var r0 power.Cpu
        var r1 error

        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                r0 = ret.Get(0).(power.Cpu)
        }</span>
        <span class="cov0" title="0">r1 = ret.Error(1)

        return r0, r1</span>
}

func (m *MockDie) CPUs() *power.CpuList <span class="cov8" title="1">{
        ret := m.Called()

        var r0 *power.CpuList
        if ret.Get(0) != nil </span><span class="cov8" title="1">{
                r0 = ret.Get(0).(*power.CpuList)
        }</span>

        <span class="cov8" title="1">return r0</span>
}

func (m *MockDie) Cores() *[]power.Core <span class="cov8" title="1">{
        ret := m.Called()

        var r0 *[]power.Core
        if ret.Get(0) != nil </span><span class="cov8" title="1">{
                r0 = ret.Get(0).(*[]power.Core)
        }</span>

        <span class="cov8" title="1">return r0</span>
}

func (m *MockDie) Core(id uint) power.Core <span class="cov0" title="0">{
        ret := m.Called(id)

        var r0 power.Core
        if ret.Get(0) != nil </span><span class="cov0" title="0">{
                r0 = ret.Get(0).(power.Core)
        }</span>

        <span class="cov0" title="0">return r0</span>
}

type FrequencySetMock struct {
        mock.Mock
        power.CpuFrequencySet
}

func (m *FrequencySetMock) GetMax() uint <span class="cov8" title="1">{
        return m.Called().Get(0).(uint)
}</span>

func (m *FrequencySetMock) GetMin() uint <span class="cov8" title="1">{
        return m.Called().Get(0).(uint)
}</span>

func SetupDummyFiles(cores int, packages int, diesPerPackage int, cpufiles map[string]string) (power.Host, func(), error) <span class="cov8" title="1">{
        //variables for various files
        path := "testing/cpus"
        pStatesDrvFile := "cpufreq/scaling_driver"

        cpuMaxFreqFile := "cpufreq/cpuinfo_max_freq"
        cpuMinFreqFile := "cpufreq/cpuinfo_min_freq"
        scalingMaxFile := "cpufreq/scaling_max_freq"
        scalingMinFile := "cpufreq/scaling_min_freq"
        scalingGovFile := "cpufreq/scaling_governor"
        availGovFile := "cpufreq/scaling_available_governors"
        eppFile := "cpufreq/energy_performance_preference"
        cpuTopologyDir := "topology/"
        packageIdFile := cpuTopologyDir + "physical_package_id"
        dieIdFile := cpuTopologyDir + "die_id"
        coreIdFile := cpuTopologyDir + "core_id"
        uncoreDir := path + "/intel_uncore_frequency/"
        uncoreInitMaxFreqFile := "initial_max_freq_khz"
        uncoreInitMinFreqFile := "initial_min_freq_khz"
        uncoreMaxFreqFile := "max_freq_khz"
        uncoreMinFreqFile := "min_freq_khz"
        cstates := []string{"C0", "C1", "C1E", "C2", "C3", "6"}
        // if we're setting uncore we need to spoof the module being loaded
        _, ok := cpufiles["uncore_max"]
        if ok </span><span class="cov8" title="1">{
                os.Mkdir("testing", os.ModePerm)
                os.WriteFile("testing/proc.modules", []byte("intel_uncore_frequency"+"\n"), 0644)
                os.MkdirAll(filepath.Join(uncoreDir, "package_00_die_00"), os.ModePerm)
        }</span>
        <span class="cov8" title="1">die := 0
        pkg := 0
        strPkg := "00"
        strDie := "00"
        pkgDir := "package_00_die_00/"
        increment := diesPerPackage * packages
        coresPerDie := cores / increment
        for i := 0; i &lt; cores; i++ </span><span class="cov8" title="1">{
                cpuName := "cpu" + fmt.Sprint(i)
                cpudir := filepath.Join(path, cpuName)
                os.MkdirAll(filepath.Join(cpudir, "cpufreq"), os.ModePerm)
                os.MkdirAll(filepath.Join(cpudir, "topology"), os.ModePerm)
                //used to divide cores between packages and dies
                if i%coresPerDie == 0 &amp;&amp; i != 0 &amp;&amp; packages != 0 </span><span class="cov8" title="1">{
                        if die == diesPerPackage-1 &amp;&amp; pkg != (packages-1) </span><span class="cov0" title="0">{
                                die = 0
                                pkg++
                        }</span> else<span class="cov8" title="1"> if die != (diesPerPackage - 1) </span><span class="cov8" title="1">{
                                die++
                        }</span>

                        <span class="cov8" title="1">if pkg &gt; 10 </span><span class="cov0" title="0">{
                                strPkg = fmt.Sprint(pkg)
                        }</span> else<span class="cov8" title="1"> {
                                strPkg = "0" + fmt.Sprint(pkg)
                        }</span>
                        <span class="cov8" title="1">if die &gt; 10 </span><span class="cov0" title="0">{
                                strDie = fmt.Sprint(die)
                        }</span> else<span class="cov8" title="1"> {
                                strDie = "0" + fmt.Sprint(die)
                        }</span>
                        <span class="cov8" title="1">pkgDir = "package_" + strPkg + "_die_" + strDie + "/"
                        os.MkdirAll(filepath.Join(uncoreDir, pkgDir), os.ModePerm)</span>
                }
                <span class="cov8" title="1">if packages != 0 </span><span class="cov8" title="1">{
                        os.WriteFile(filepath.Join(cpudir, packageIdFile), []byte(fmt.Sprint(pkg)+"\n"), 0664)
                        os.WriteFile(filepath.Join(cpudir, dieIdFile), []byte(fmt.Sprint(die)+"\n"), 0664)
                        os.WriteFile(filepath.Join(cpudir, coreIdFile), []byte(fmt.Sprint(i)+"\n"), 0664)
                }</span>
                <span class="cov8" title="1">for prop, value := range cpufiles </span><span class="cov8" title="1">{
                        switch prop </span>{
                        case "driver":<span class="cov8" title="1">
                                os.WriteFile(filepath.Join(cpudir, pStatesDrvFile), []byte(value+"\n"), 0664)</span>
                        case "max":<span class="cov8" title="1">
                                os.WriteFile(filepath.Join(cpudir, scalingMaxFile), []byte(value+"\n"), 0644)
                                os.WriteFile(filepath.Join(cpudir, cpuMaxFreqFile), []byte(value+"\n"), 0644)</span>
                        case "min":<span class="cov8" title="1">
                                os.WriteFile(filepath.Join(cpudir, scalingMinFile), []byte(value+"\n"), 0644)
                                os.WriteFile(filepath.Join(cpudir, cpuMinFreqFile), []byte(value+"\n"), 0644)</span>
                        case "epp":<span class="cov8" title="1">
                                os.WriteFile(filepath.Join(cpudir, eppFile), []byte(value+"\n"), 0644)</span>
                        case "governor":<span class="cov8" title="1">
                                os.WriteFile(filepath.Join(cpudir, scalingGovFile), []byte(value+"\n"), 0644)</span>
                        case "available_governors":<span class="cov8" title="1">
                                os.WriteFile(filepath.Join(cpudir, availGovFile), []byte(value+"\n"), 0644)</span>
                        case "uncore_max":<span class="cov8" title="1">
                                os.WriteFile(filepath.Join(uncoreDir, pkgDir, uncoreInitMaxFreqFile), []byte(value+"\n"), 0644)
                                os.WriteFile(filepath.Join(uncoreDir, pkgDir, uncoreMaxFreqFile), []byte(value+"\n"), 0644)</span>
                        case "uncore_min":<span class="cov8" title="1">
                                os.WriteFile(filepath.Join(uncoreDir, pkgDir, uncoreInitMinFreqFile), []byte(value+"\n"), 0644)
                                os.WriteFile(filepath.Join(uncoreDir, pkgDir, uncoreMinFreqFile), []byte(value+"\n"), 0644)</span>
                        case "cstates":<span class="cov8" title="1">
                                for i, state := range cstates </span><span class="cov8" title="1">{
                                        statedir := "cpuidle/state" + fmt.Sprint(i)
                                        os.MkdirAll(filepath.Join(cpudir, statedir), os.ModePerm)
                                        os.MkdirAll(filepath.Join(path, "cpuidle"), os.ModePerm)
                                        os.WriteFile(filepath.Join(path, "cpuidle", "current_driver"), []byte(value+"\n"), 0644)
                                        os.WriteFile(filepath.Join(cpudir, statedir, "name"), []byte(state+"\n"), 0644)
                                        os.WriteFile(filepath.Join(cpudir, statedir, "disable"), []byte("0\n"), 0644)
                                }</span>
                        }

                }
        }
        <span class="cov8" title="1">host, err := power.CreateInstanceWithConf("test-node", power.LibConfig{CpuPath: "testing/cpus", ModulePath: "testing/proc.modules", Cores: uint(cores)})
        // Ignore if error comes from ESMI initialization - we want to run unit tests on any hardware, not only AMD EPYCs
        if strings.Contains(err.Error(), "ESMI") </span><span class="cov8" title="1">{
                err = nil
        }</span>
        <span class="cov8" title="1">return host, func() </span><span class="cov8" title="1">{
                os.RemoveAll(strings.Split(path, "/")[0])
        }</span>, err
}

// default dummy file system to be used in standard tests
func FullDummySystem() (power.Host, func(), error) <span class="cov8" title="1">{
        return SetupDummyFiles(86, 1, 2, map[string]string{
                "driver": "intel_pstate", "max": "3700000", "min": "1000000",
                "epp": "performance", "governor": "performance",
                "available_governors": "powersave performance",
                "uncore_max":          "2400000", "uncore_min": "1200000",
                "cstates": "intel_idle"})
}</span>

// mock required for testing setupwithmanager
type ClientMock struct {
        mock.Mock
        client.Client
}

// mock required for testing client errs
type ErrClient struct {
        client.Client
        mock.Mock
}

func (e *ErrClient) Get(ctx context.Context, NamespacedName types.NamespacedName, obj client.Object, opts ...client.GetOption) error <span class="cov8" title="1">{
        if len(opts) != 0 </span><span class="cov0" title="0">{
                return e.Called(ctx, NamespacedName, obj, opts).Error(0)
        }</span>
        <span class="cov8" title="1">return e.Called(ctx, NamespacedName, obj).Error(0)</span>
}
func (e *ErrClient) List(ctx context.Context, list client.ObjectList, opts ...client.ListOption) error <span class="cov8" title="1">{
        if len(opts) != 0 </span><span class="cov8" title="1">{
                return e.Called(ctx, list, opts).Error(0)

        }</span>
        <span class="cov8" title="1">return e.Called(ctx, list).Error(0)</span>
}

func (e *ErrClient) Create(ctx context.Context, obj client.Object, opts ...client.CreateOption) error <span class="cov8" title="1">{
        if len(opts) != 0 </span><span class="cov0" title="0">{
                return e.Called(ctx, obj, opts).Error(0)
        }</span>
        <span class="cov8" title="1">return e.Called(ctx, obj).Error(0)</span>
}

func (e *ErrClient) Update(ctx context.Context, obj client.Object, opts ...client.UpdateOption) error <span class="cov8" title="1">{
        if len(opts) != 0 </span><span class="cov0" title="0">{
                return e.Called(ctx, obj, opts).Error(0)
        }</span>
        <span class="cov8" title="1">return e.Called(ctx, obj).Error(0)</span>
}

func (e *ErrClient) Delete(ctx context.Context, obj client.Object, opts ...client.DeleteOption) error <span class="cov8" title="1">{
        if len(opts) != 0 </span><span class="cov0" title="0">{
                return e.Called(ctx, obj, opts).Error(0)
        }</span>
        <span class="cov8" title="1">return e.Called(ctx, obj).Error(0)</span>
}

func (e *ErrClient) DeleteAllOf(ctx context.Context, obj client.Object, opts ...client.DeleteAllOfOption) error <span class="cov0" title="0">{
        if len(opts) != 0 </span><span class="cov0" title="0">{
                return e.Called(ctx, obj, opts).Error(0)
        }</span>
        <span class="cov0" title="0">return e.Called(ctx, obj).Error(0)</span>
}

func (e *ErrClient) Patch(ctx context.Context, obj client.Object, patch client.Patch, opts ...client.PatchOption) error <span class="cov0" title="0">{
        if len(opts) != 0 </span><span class="cov0" title="0">{
                return e.Called(ctx, obj, patch, opts).Error(0)
        }</span>
        <span class="cov0" title="0">return e.Called(ctx, obj, patch).Error(0)</span>
}

func (e *ErrClient) Status() client.SubResourceWriter <span class="cov8" title="1">{
        return e.Called().Get(0).(client.SubResourceWriter)
}</span>

type MockResourceWriter struct {
        mock.Mock
        client.SubResourceWriter
}

func (m *MockResourceWriter) Update(ctx context.Context, obj client.Object, opts ...client.SubResourceUpdateOption) error <span class="cov0" title="0">{
        if len(opts) != 0 </span><span class="cov0" title="0">{
                return m.Called(ctx, obj, opts).Error(0)
        }</span>
        <span class="cov0" title="0">return m.Called(ctx, obj).Error(0)</span>
}

type MgrMock struct {
        mock.Mock
        manager.Manager
}

func (m *MgrMock) Add(r manager.Runnable) error <span class="cov8" title="1">{
        return m.Called(r).Error(0)
}</span>

func (m *MgrMock) Elected() &lt;-chan struct{} <span class="cov0" title="0">{
        return m.Called().Get(0).(&lt;-chan struct{})
}</span>

func (m *MgrMock) AddMetricsExtraHandler(path string, handler http.Handler) error <span class="cov0" title="0">{
        return m.Called(path, handler).Get(0).(error)
}</span>

func (m *MgrMock) AddHealthzCheck(name string, check healthz.Checker) error <span class="cov0" title="0">{
        return m.Called(name, check).Get(0).(error)
}</span>

func (m *MgrMock) AddReadyzCheck(name string, check healthz.Checker) error <span class="cov0" title="0">{
        return m.Called(name, check).Get(0).(error)
}</span>

func (m *MgrMock) Start(ctx context.Context) error <span class="cov0" title="0">{
        return m.Called(ctx).Get(0).(error)
}</span>

func (m *MgrMock) GetWebhookServer() webhook.Server <span class="cov0" title="0">{
        return m.Called().Get(0).(webhook.Server)
}</span>

func (m *MgrMock) GetLogger() logr.Logger <span class="cov8" title="1">{
        return m.Called().Get(0).(logr.Logger)

}</span>

func (m *MgrMock) GetControllerOptions() config.Controller <span class="cov8" title="1">{
        return m.Called().Get(0).(config.Controller)
}</span>

func (m *MgrMock) GetScheme() *runtime.Scheme <span class="cov8" title="1">{
        return m.Called().Get(0).(*runtime.Scheme)
}</span>
func (m *MgrMock) SetFields(i interface{}) error <span class="cov0" title="0">{
        return m.Called(i).Error(0)
}</span>

func (m *MgrMock) GetCache() cache.Cache <span class="cov8" title="1">{
        return m.Called().Get(0).(cache.Cache)
}</span>

type CacheMk struct {
        cache.Cache
        mock.Mock
}
</pre>
		
		<pre class="file" id="file45" style="display: none">//go:build freebsd || linux || darwin
// +build freebsd linux darwin

/*
Copyright 2017 The Kubernetes Authors.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
    http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package util

import (
        "context"
        "fmt"
        corev1 "k8s.io/api/core/v1"
        "k8s.io/klog/v2"
        "net"
        "net/url"

        "github.com/intel/power-optimization-library/pkg/power"
)

const (
        // unixProtocol is the network protocol of unix socket.
        unixProtocol = "unix"
)

// GetAddressAndDialer returns the address parsed from the given endpoint and a context dialer.
func GetAddressAndDialer(endpoint string) (string, func(ctx context.Context, addr string) (net.Conn, error), error) <span class="cov8" title="1">{
        protocol, addr, err := parseEndpointWithFallbackProtocol(endpoint, unixProtocol)
        if err != nil </span><span class="cov8" title="1">{
                return "", nil, err
        }</span>
        <span class="cov8" title="1">if protocol != unixProtocol </span><span class="cov8" title="1">{
                return "", nil, fmt.Errorf("only support unix socket endpoint")
        }</span>

        <span class="cov8" title="1">return addr, dial, nil</span>
}

func dial(ctx context.Context, addr string) (net.Conn, error) <span class="cov8" title="1">{
        return (&amp;net.Dialer{}).DialContext(ctx, unixProtocol, addr)
}</span>

func parseEndpointWithFallbackProtocol(endpoint string, fallbackProtocol string) (protocol string, addr string, err error) <span class="cov8" title="1">{
        if protocol, addr, err = parseEndpoint(endpoint); err != nil &amp;&amp; protocol == "" </span><span class="cov8" title="1">{
                fallbackEndpoint := fallbackProtocol + "://" + endpoint
                protocol, addr, err = parseEndpoint(fallbackEndpoint)
                if err == nil </span><span class="cov8" title="1">{
                        klog.Warningf("Using %q as endpoint is deprecated, please consider using full url format %q.", endpoint, fallbackEndpoint)
                }</span>
        }
        <span class="cov8" title="1">return</span>
}

func parseEndpoint(endpoint string) (string, string, error) <span class="cov8" title="1">{
        u, err := url.Parse(endpoint)
        if err != nil </span><span class="cov0" title="0">{
                return "", "", err
        }</span>

        <span class="cov8" title="1">switch u.Scheme </span>{
        case "tcp":<span class="cov8" title="1">
                return "tcp", u.Host, nil</span>

        case "unix":<span class="cov8" title="1">
                return "unix", u.Path, nil</span>

        case "":<span class="cov8" title="1">
                return "", "", fmt.Errorf("using %q as endpoint is deprecated, please consider using full url format", endpoint)</span>

        default:<span class="cov8" title="1">
                return u.Scheme, "", fmt.Errorf("protocol %q not supported", u.Scheme)</span>
        }
}

func CPUInCPUList(cpu uint, cpuList []uint) bool <span class="cov8" title="1">{
        for _, cpuListID := range cpuList </span><span class="cov8" title="1">{
                if cpuListID == cpu </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov8" title="1">return false</span>
}

func NodeNameInNodeList(name string, nodeList []corev1.Node) bool <span class="cov8" title="1">{
        for _, node := range nodeList </span><span class="cov8" title="1">{
                if node.Name == name </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov8" title="1">return false</span>
}

func StringInStringList(item string, itemList []string) bool <span class="cov8" title="1">{
        for _, i := range itemList </span><span class="cov8" title="1">{
                if i == item </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov8" title="1">return false</span>
}

// UnpackErrsToStrings will try to unpack a multi-error to a list of strings, if possible, if not it will return string
// representation as a first element
func UnpackErrsToStrings(err error) *[]string <span class="cov8" title="1">{
        if err == nil </span><span class="cov8" title="1">{
                return &amp;[]string{}
        }</span>

        <span class="cov8" title="1">switch joinedErr := err.(type) </span>{
        case interface{ Unwrap() []error }:<span class="cov8" title="1">
                stringErrs := make([]string, len(joinedErr.Unwrap()))
                for i, individualErr := range joinedErr.Unwrap() </span><span class="cov8" title="1">{
                        stringErrs[i] = individualErr.Error()
                }</span>
                <span class="cov8" title="1">return &amp;stringErrs</span>
        default:<span class="cov8" title="1">
                return &amp;[]string{err.Error()}</span>
        }
}

func IterateOverCPUs(host power.Host, f func(cpu power.Cpu, core power.Core, die power.Die, pkg power.Package)) <span class="cov0" title="0">{
        topology := host.Topology()
        for _, pkg := range *topology.Packages() </span><span class="cov0" title="0">{
                for _, die := range *pkg.Dies() </span><span class="cov0" title="0">{
                        for _, core := range *die.Cores() </span><span class="cov0" title="0">{
                                for _, cpu := range *core.CPUs() </span><span class="cov0" title="0">{
                                        f(cpu, core, die, pkg)
                                }</span>
                        }
                }
        }
}

func IterateOverCores(host power.Host, f func(core power.Core, die power.Die, pkg power.Package)) <span class="cov0" title="0">{
        topology := host.Topology()
        for _, pkg := range *topology.Packages() </span><span class="cov0" title="0">{
                for _, die := range *pkg.Dies() </span><span class="cov0" title="0">{
                        for _, core := range *die.Cores() </span><span class="cov0" title="0">{
                                f(core, die, pkg)
                        }</span>
                }
        }
}

func IterateOverDies(host power.Host, f func(die power.Die, pkg power.Package)) <span class="cov0" title="0">{
        topology := host.Topology()
        for _, pkg := range *topology.Packages() </span><span class="cov0" title="0">{
                for _, die := range *pkg.Dies() </span><span class="cov0" title="0">{
                        f(die, pkg)
                }</span>
        }
}

func IterateOverPackages(host power.Host, f func(pkg power.Package)) <span class="cov0" title="0">{
        topology := host.Topology()
        for _, pkg := range *topology.Packages() </span><span class="cov0" title="0">{
                f(pkg)
        }</span>
}
</pre>
		
		</div>
	</body>
</html>
